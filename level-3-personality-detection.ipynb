{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8148690,"sourceType":"datasetVersion","datasetId":4819077},{"sourceId":8882386,"sourceType":"datasetVersion","datasetId":5345224}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-18T06:59:01.892838Z","iopub.execute_input":"2024-08-18T06:59:01.893137Z","iopub.status.idle":"2024-08-18T06:59:03.121191Z","shell.execute_reply.started":"2024-08-18T06:59:01.893111Z","shell.execute_reply":"2024-08-18T06:59:03.120067Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/microtext/Dataset - tachygraphy.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-08-18T06:59:12.428827Z","iopub.execute_input":"2024-08-18T06:59:12.429571Z","iopub.status.idle":"2024-08-18T06:59:16.386165Z","shell.execute_reply.started":"2024-08-18T06:59:12.429516Z","shell.execute_reply":"2024-08-18T06:59:16.385157Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"execution":{"iopub.status.busy":"2024-08-18T06:59:19.472073Z","iopub.execute_input":"2024-08-18T06:59:19.472630Z","iopub.status.idle":"2024-08-18T06:59:20.772753Z","shell.execute_reply.started":"2024-08-18T06:59:19.472600Z","shell.execute_reply":"2024-08-18T06:59:20.771975Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:00:58.987258Z","iopub.execute_input":"2024-08-18T07:00:58.987630Z","iopub.status.idle":"2024-08-18T07:00:58.994712Z","shell.execute_reply.started":"2024-08-18T07:00:58.987600Z","shell.execute_reply":"2024-08-18T07:00:58.993656Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/microtext/Dataset - tachygraphy.csv\")\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:56:15.017836Z","iopub.execute_input":"2024-08-18T07:56:15.018550Z","iopub.status.idle":"2024-08-18T07:56:15.058891Z","shell.execute_reply.started":"2024-08-18T07:56:15.018507Z","shell.execute_reply":"2024-08-18T07:56:15.057676Z"},"trusted":true},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(4958, 3)"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:56:16.800718Z","iopub.execute_input":"2024-08-18T07:56:16.801068Z","iopub.status.idle":"2024-08-18T07:56:16.811008Z","shell.execute_reply.started":"2024-08-18T07:56:16.801042Z","shell.execute_reply":"2024-08-18T07:56:16.809967Z"},"trusted":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                Text  \\\n0   Last session of the day http://twitpic.com/67ezh   \n1  Shanghai is also really exciting (precisely --...   \n2                            submit the report ASAP!   \n3                                        happy bday!   \n4                              The OGs - I like it!!   \n\n                                             Meaning Sentiment  \n0   Last session of the day http://twitpic.com/67ezh   neutral  \n1  Shanghai is also really exciting (precisely --...  positive  \n2              submit the report as soon as possilbe  negative  \n3                                    Happy Birthday!  positive  \n4                The original gangsters - i like it!  positive  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Meaning</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Last session of the day http://twitpic.com/67ezh</td>\n      <td>Last session of the day http://twitpic.com/67ezh</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Shanghai is also really exciting (precisely --...</td>\n      <td>Shanghai is also really exciting (precisely --...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>submit the report ASAP!</td>\n      <td>submit the report as soon as possilbe</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy bday!</td>\n      <td>Happy Birthday!</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The OGs - I like it!!</td>\n      <td>The original gangsters - i like it!</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"df=df.drop('Meaning',axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:01:45.738311Z","iopub.execute_input":"2024-08-18T07:01:45.738764Z","iopub.status.idle":"2024-08-18T07:01:45.748351Z","shell.execute_reply.started":"2024-08-18T07:01:45.738731Z","shell.execute_reply":"2024-08-18T07:01:45.747272Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:56:20.197942Z","iopub.execute_input":"2024-08-18T07:56:20.199047Z","iopub.status.idle":"2024-08-18T07:56:20.204807Z","shell.execute_reply.started":"2024-08-18T07:56:20.199014Z","shell.execute_reply":"2024-08-18T07:56:20.203800Z"},"trusted":true},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(4958, 3)"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"df = df.rename(columns={'Text': 'tweet'})","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:01:52.297824Z","iopub.execute_input":"2024-08-18T07:01:52.298455Z","iopub.status.idle":"2024-08-18T07:01:52.303188Z","shell.execute_reply.started":"2024-08-18T07:01:52.298428Z","shell.execute_reply":"2024-08-18T07:01:52.302288Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df = df.rename(columns={'Sentiment': 'class'})","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:01:54.267139Z","iopub.execute_input":"2024-08-18T07:01:54.267836Z","iopub.status.idle":"2024-08-18T07:01:54.272499Z","shell.execute_reply.started":"2024-08-18T07:01:54.267805Z","shell.execute_reply":"2024-08-18T07:01:54.271588Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df['class'] = df['class'].str.lower()\nsentiment_counts = df['class'].value_counts()\nsentiment_counts","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:01:56.810503Z","iopub.execute_input":"2024-08-18T07:01:56.810851Z","iopub.status.idle":"2024-08-18T07:01:56.829474Z","shell.execute_reply.started":"2024-08-18T07:01:56.810823Z","shell.execute_reply":"2024-08-18T07:01:56.828592Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"class\nneutral     1743\npositive    1643\nnegative    1572\nName: count, dtype: int64"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(df['class'])\nencoded_labels = label_encoder.transform(df['class'])\ndf['class'] = encoded_labels","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:01:59.197034Z","iopub.execute_input":"2024-08-18T07:01:59.197420Z","iopub.status.idle":"2024-08-18T07:01:59.205062Z","shell.execute_reply.started":"2024-08-18T07:01:59.197390Z","shell.execute_reply":"2024-08-18T07:01:59.204093Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:56:27.610469Z","iopub.execute_input":"2024-08-18T07:56:27.611201Z","iopub.status.idle":"2024-08-18T07:56:27.621322Z","shell.execute_reply.started":"2024-08-18T07:56:27.611166Z","shell.execute_reply":"2024-08-18T07:56:27.620232Z"},"trusted":true},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"Text         1\nMeaning      1\nSentiment    0\ndtype: int64"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"df=df.fillna('')","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:56:31.481328Z","iopub.execute_input":"2024-08-18T07:56:31.482193Z","iopub.status.idle":"2024-08-18T07:56:31.490263Z","shell.execute_reply.started":"2024-08-18T07:56:31.482155Z","shell.execute_reply":"2024-08-18T07:56:31.489422Z"},"trusted":true},"outputs":[],"execution_count":34},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:56:34.020609Z","iopub.execute_input":"2024-08-18T07:56:34.021321Z","iopub.status.idle":"2024-08-18T07:56:34.034398Z","shell.execute_reply.started":"2024-08-18T07:56:34.021290Z","shell.execute_reply":"2024-08-18T07:56:34.033408Z"},"trusted":true},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"                                                Text  \\\n0   Last session of the day http://twitpic.com/67ezh   \n1  Shanghai is also really exciting (precisely --...   \n2                            submit the report ASAP!   \n3                                        happy bday!   \n4                              The OGs - I like it!!   \n\n                                             Meaning Sentiment  \n0   Last session of the day http://twitpic.com/67ezh   neutral  \n1  Shanghai is also really exciting (precisely --...  positive  \n2              submit the report as soon as possilbe  negative  \n3                                    Happy Birthday!  positive  \n4                The original gangsters - i like it!  positive  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Meaning</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Last session of the day http://twitpic.com/67ezh</td>\n      <td>Last session of the day http://twitpic.com/67ezh</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Shanghai is also really exciting (precisely --...</td>\n      <td>Shanghai is also really exciting (precisely --...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>submit the report ASAP!</td>\n      <td>submit the report as soon as possilbe</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy bday!</td>\n      <td>Happy Birthday!</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The OGs - I like it!!</td>\n      <td>The original gangsters - i like it!</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\n\ndef text_cleaning(text):\n    text = str(text)\n    soup = BeautifulSoup(text, \"html.parser\")    ###removing html tages\n    text = re.sub(r'\\[[^]]*\\]', '', soup.get_text())      ##removing text within square brackets\n    pattern = r\"[^a-zA-Z0-9\\s,']\"                  # Removing unwanted characters\n    text = re.sub(pattern, '', text)\n    url_pattern = r'http\\S+|www\\S+'            ###removing urls\n    text = re.sub(url_pattern, '', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:56:37.500748Z","iopub.execute_input":"2024-08-18T07:56:37.501109Z","iopub.status.idle":"2024-08-18T07:56:37.507309Z","shell.execute_reply.started":"2024-08-18T07:56:37.501082Z","shell.execute_reply":"2024-08-18T07:56:37.506370Z"},"trusted":true},"outputs":[],"execution_count":36},{"cell_type":"code","source":"df['Text'] = df['Text'].apply(text_cleaning).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:56:59.158373Z","iopub.execute_input":"2024-08-18T07:56:59.159096Z","iopub.status.idle":"2024-08-18T07:56:59.440011Z","shell.execute_reply.started":"2024-08-18T07:56:59.159064Z","shell.execute_reply":"2024-08-18T07:56:59.439127Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2827669698.py:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  soup = BeautifulSoup(text, \"html.parser\")    ###removing html tages\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"df['Meaning'] = df['Meaning'].apply(text_cleaning).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:57:15.261465Z","iopub.execute_input":"2024-08-18T07:57:15.261906Z","iopub.status.idle":"2024-08-18T07:57:15.550224Z","shell.execute_reply.started":"2024-08-18T07:57:15.261874Z","shell.execute_reply":"2024-08-18T07:57:15.549335Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/2827669698.py:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  soup = BeautifulSoup(text, \"html.parser\")    ###removing html tages\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:02:17.631738Z","iopub.execute_input":"2024-08-18T07:02:17.632060Z","iopub.status.idle":"2024-08-18T07:02:17.641898Z","shell.execute_reply.started":"2024-08-18T07:02:17.632036Z","shell.execute_reply":"2024-08-18T07:02:17.640997Z"},"trusted":true},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                               tweet  class\n0                           Last session of the day       1\n1  Shanghai is also really exciting precisely  sk...      2\n2                             submit the report ASAP      0\n3                                         happy bday      2\n4                                 The OGs  I like it      2\n5                          thats great weee visitors      2\n6              I THINK EVERYONE HATES ME ON HERE lol      0\n7  soooooo wish i could, but im in school and mys...      0\n8  and within a short time of the last clue all o...      1\n9  What did you get My day is alright havent done...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Last session of the day</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Shanghai is also really exciting precisely  sk...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>submit the report ASAP</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>happy bday</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The OGs  I like it</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>thats great weee visitors</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>I THINK EVERYONE HATES ME ON HERE lol</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>soooooo wish i could, but im in school and mys...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>and within a short time of the last clue all o...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>What did you get My day is alright havent done...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"def remove_URL(sample):\n    return re.sub(r\"http\\S+\", \"\", sample)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:57:20.415962Z","iopub.execute_input":"2024-08-18T07:57:20.416653Z","iopub.status.idle":"2024-08-18T07:57:20.420731Z","shell.execute_reply.started":"2024-08-18T07:57:20.416624Z","shell.execute_reply":"2024-08-18T07:57:20.419685Z"},"trusted":true},"outputs":[],"execution_count":40},{"cell_type":"code","source":"df['Meaning'] = df['Meaning'].apply(remove_URL).tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:57:33.156394Z","iopub.execute_input":"2024-08-18T07:57:33.157160Z","iopub.status.idle":"2024-08-18T07:57:33.170393Z","shell.execute_reply.started":"2024-08-18T07:57:33.157127Z","shell.execute_reply":"2024-08-18T07:57:33.169554Z"},"trusted":true},"outputs":[],"execution_count":41},{"cell_type":"code","source":"lens=[len(i.split()) for i in df['tweet']]","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:02:31.683264Z","iopub.execute_input":"2024-08-18T07:02:31.683826Z","iopub.status.idle":"2024-08-18T07:02:31.697923Z","shell.execute_reply.started":"2024-08-18T07:02:31.683784Z","shell.execute_reply":"2024-08-18T07:02:31.696915Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nimport pandas as pd\n\n# Load the pre-trained model and tokenizer\nmodel_name = \"bhadresh-savani/distilbert-base-uncased-emotion\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\n\n# Emotion labels corresponding to the GoEmotions dataset\nemotions = [\"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \n            \"caring\", \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \n            \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \n            \"fear\", \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \n            \"optimism\", \"pride\", \"realization\", \"relief\", \"remorse\", \n            \"sadness\", \"surprise\"]\n\n# Define a function to classify a text input\ndef classify_emotion(text):\n    # Tokenize the input text\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n    \n    # Get model predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    # Convert logits to probabilities\n    probabilities = torch.softmax(outputs.logits, dim=-1)\n    \n    # Get the predicted emotion\n    predicted_emotion = emotions[torch.argmax(probabilities)]\n    \n    return predicted_emotion\n\n# Apply the model to each text in the dataset\ndf['predicted_emotion'] = df['tweet'].apply(classify_emotion)\n\n# Save the dataset with the new column\ndf.to_csv('dataset_with_emotions.csv', index=False)\n\n# Preview the dataset with the new column\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:18:50.325493Z","iopub.execute_input":"2024-08-18T07:18:50.326224Z","iopub.status.idle":"2024-08-18T07:21:33.560235Z","shell.execute_reply.started":"2024-08-18T07:18:50.326190Z","shell.execute_reply":"2024-08-18T07:21:33.559291Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/291 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec4e61e28945409ea3343b7aad60b5ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/768 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a44a6c44280c4c3484c20732bc5c741c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33cd0ec6744544ae9647307981fe5659"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80d2776dd6654f70ad81b405d7aa8e7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f7414a928c347079d750b784c096dfe"}},"metadata":{}},{"name":"stdout","text":"                                               tweet  class predicted_emotion\n0                           Last session of the day       1         annoyance\n1  Shanghai is also really exciting precisely  sk...      2         amusement\n2                             submit the report ASAP      0         amusement\n3                                         happy bday      2         amusement\n4                                 The OGs  I like it      2         amusement\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"from senticnet.senticnet import SenticNet\nimport pandas as pd\n\n# Initialize SenticNet\nsn = SenticNet()\n\n# Define a function to extract emotions from text using SenticNet\ndef classify_emotion_with_senticnet(text):\n    words = text.split()\n    emotions_detected = []\n\n    for word in words:\n        try:\n            # Get the sentic concepts associated with the word\n            sentic_info = sn.concept(word)\n            primary_emotion = sentic_info['primary_mood']\n            secondary_emotion = sentic_info['secondary_mood']\n            \n            # Add the detected emotions to the list\n            emotions_detected.append(primary_emotion)\n            emotions_detected.append(secondary_emotion)\n        except KeyError:\n            # Skip words that are not in SenticNet\n            continue\n    \n    # Return the most common emotion or emotions detected in the text\n    if emotions_detected:\n        return max(set(emotions_detected), key=emotions_detected.count)\n    else:\n        return \"neutral\"  # Default to neutral if no emotion is detected\n\n# Apply the function to classify emotions in the dataset\ndf['emotion_senticnet'] = df['Meaning'].apply(classify_emotion_with_senticnet)\n\n# Save the updated dataset to a new CSV file\ndf.to_csv('dataset_with_emotions_senticnet.csv', index=False)\n\n# Preview the dataset with the new column\nprint(df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:57:59.959641Z","iopub.execute_input":"2024-08-18T07:57:59.959989Z","iopub.status.idle":"2024-08-18T07:58:00.115166Z","shell.execute_reply.started":"2024-08-18T07:57:59.959962Z","shell.execute_reply":"2024-08-18T07:58:00.114299Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                                Text  \\\n0                           Last session of the day    \n1  Shanghai is also really exciting precisely  sk...   \n2                             submit the report ASAP   \n3                                         happy bday   \n4                                 The OGs  I like it   \n\n                                             Meaning Sentiment  \\\n0                           Last session of the day    neutral   \n1  Shanghai is also really exciting precisely  sk...  positive   \n2              submit the report as soon as possilbe  negative   \n3                                     Happy Birthday  positive   \n4                  The original gangsters  i like it  positive   \n\n  emotion_senticnet  \n0           neutral  \n1           neutral  \n2           neutral  \n3           neutral  \n4           neutral  \n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"from senticnet.senticnet import SenticNet\nimport pandas as pd\nimport re\nfrom itertools import islice\n\n# Initialize SenticNet\nsn = SenticNet()\n\n# Preprocessing function to clean text\ndef preprocess_text(text):\n    # Remove punctuation and convert to lowercase\n    text = re.sub(r'[^\\w\\s]', '', text.lower())\n    return text\n\n# Function to extract n-grams from text\ndef extract_ngrams(text, n):\n    words = text.split()\n    return [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n\n# Function to classify emotion using SenticNet with improved concept extraction\ndef classify_emotion_with_senticnet(text):\n    # Preprocess the text\n    text = preprocess_text(text)\n    \n    # Check for multi-word concepts (up to 4-grams)\n    max_n = 4\n    emotions_detected = []\n\n    for n in range(max_n, 0, -1):  # Start with the largest n-grams\n        ngrams = extract_ngrams(text, n)\n        for ngram in ngrams:\n            try:\n                # Get the sentic concepts associated with the n-gram\n                sentic_info = sn.concept(ngram)\n                primary_emotion = sentic_info['primary_mood']\n                secondary_emotion = sentic_info['secondary_mood']\n                \n                # Add the detected emotions to the list\n                emotions_detected.append(primary_emotion)\n                emotions_detected.append(secondary_emotion)\n                \n                # If an emotion is detected, stop further searching\n                break\n            except KeyError:\n                continue\n\n        if emotions_detected:\n            break\n\n    # Return the most common emotion detected, or neutral if none found\n    if emotions_detected:\n        return max(set(emotions_detected), key=emotions_detected.count)\n    else:\n        return \"neutral\"\n\n# Apply the function to classify emotions in the dataset\ndf['emotion_senticnet'] = df['Meaning'].apply(classify_emotion_with_senticnet)\n\n# Save the updated dataset to a new CSV file\ndf.to_csv('dataset_with_emotions_senticnet.csv', index=False)\n\n# Preview the dataset with the new column\nprint(df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T08:00:00.744414Z","iopub.execute_input":"2024-08-18T08:00:00.745109Z","iopub.status.idle":"2024-08-18T08:00:01.281938Z","shell.execute_reply.started":"2024-08-18T08:00:00.745079Z","shell.execute_reply":"2024-08-18T08:00:01.280813Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                                Text  \\\n0                           Last session of the day    \n1  Shanghai is also really exciting precisely  sk...   \n2                             submit the report ASAP   \n3                                         happy bday   \n4                                 The OGs  I like it   \n\n                                             Meaning Sentiment  \\\n0                           Last session of the day    neutral   \n1  Shanghai is also really exciting precisely  sk...  positive   \n2              submit the report as soon as possilbe  negative   \n3                                     Happy Birthday  positive   \n4                  The original gangsters  i like it  positive   \n\n  emotion_senticnet  \n0           neutral  \n1           neutral  \n2           neutral  \n3           neutral  \n4           neutral  \n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import pandas as pd\nfrom senticnet.senticnet import SenticNet\nfrom nltk.tokenize import word_tokenize\nimport nltk\nfrom nltk.corpus import stopwords\nsw_nltk = stopwords.words('english')\nimport re\n\nsn = SenticNet()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T08:03:41.323661Z","iopub.execute_input":"2024-08-18T08:03:41.324105Z","iopub.status.idle":"2024-08-18T08:03:41.330593Z","shell.execute_reply.started":"2024-08-18T08:03:41.324068Z","shell.execute_reply":"2024-08-18T08:03:41.329562Z"},"trusted":true},"outputs":[],"execution_count":53},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nsw_nltk = stopwords.words('english')\nfrom stop_words import get_stop_words\n\ndef remove_stopwords(text1):\n    stop_words = list(get_stop_words('en'))         #About 900 stopwords\n    nltk_words = list(stopwords.words('english')) #About 150 stopwords\n    stop_words.extend(nltk_words)\n    \n    output = [w for w in text1 if not w in stop_words]","metadata":{"execution":{"iopub.status.busy":"2024-08-18T08:01:40.097006Z","iopub.execute_input":"2024-08-18T08:01:40.097804Z","iopub.status.idle":"2024-08-18T08:01:40.117624Z","shell.execute_reply.started":"2024-08-18T08:01:40.097774Z","shell.execute_reply":"2024-08-18T08:01:40.116590Z"},"trusted":true},"outputs":[],"execution_count":46},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\n\ndef tokenize(text):\n    tokenized_text = word_tokenize(text)\n    return tokenized_text","metadata":{"execution":{"iopub.status.busy":"2024-08-18T08:01:49.887674Z","iopub.execute_input":"2024-08-18T08:01:49.888496Z","iopub.status.idle":"2024-08-18T08:01:49.892748Z","shell.execute_reply.started":"2024-08-18T08:01:49.888463Z","shell.execute_reply":"2024-08-18T08:01:49.891892Z"},"trusted":true},"outputs":[],"execution_count":47},{"cell_type":"code","source":"def get_moodtags(text1):\n    emotion_list = []\n\n    for word in text1:\n        try:\n            emotion_list.append(sn.moodtags(word))\n        except: continue\n        \n    print(emotion_list)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T08:03:04.344028Z","iopub.execute_input":"2024-08-18T08:03:04.344387Z","iopub.status.idle":"2024-08-18T08:03:04.349741Z","shell.execute_reply.started":"2024-08-18T08:03:04.344358Z","shell.execute_reply":"2024-08-18T08:03:04.348514Z"},"trusted":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":"txtc = df['Text'][0]\nprint(txtc)\ntxct = text_cleaning(txtc)\ntxtc = tokenize(txtc)\nprint(txtc)\ntxtc = remove_stopwords(txtc)\nprint(txtc)\nget_moodtags(txtc)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T08:03:45.949912Z","iopub.execute_input":"2024-08-18T08:03:45.950651Z","iopub.status.idle":"2024-08-18T08:03:46.002060Z","shell.execute_reply.started":"2024-08-18T08:03:45.950620Z","shell.execute_reply":"2024-08-18T08:03:46.000889Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Last session of the day \n['Last', 'session', 'of', 'the', 'day']\nNone\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[54], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m txtc \u001b[38;5;241m=\u001b[39m remove_stopwords(txtc)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(txtc)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mget_moodtags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxtc\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[51], line 4\u001b[0m, in \u001b[0;36mget_moodtags\u001b[0;34m(text1)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_moodtags\u001b[39m(text1):\n\u001b[1;32m      2\u001b[0m     emotion_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text1:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m             emotion_list\u001b[38;5;241m.\u001b[39mappend(sn\u001b[38;5;241m.\u001b[39mmoodtags(word))\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"],"ename":"TypeError","evalue":"'NoneType' object is not iterable","output_type":"error"}],"execution_count":54},{"cell_type":"code","source":"!pip install senticnet","metadata":{"execution":{"iopub.status.busy":"2024-08-18T07:37:43.414109Z","iopub.execute_input":"2024-08-18T07:37:43.414917Z","iopub.status.idle":"2024-08-18T07:38:49.684347Z","shell.execute_reply.started":"2024-08-18T07:37:43.414873Z","shell.execute_reply":"2024-08-18T07:38:49.682964Z"},"trusted":true},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting senticnet\n  Downloading senticnet-1.6-py3-none-any.whl.metadata (2.6 kB)\nDownloading senticnet-1.6-py3-none-any.whl (51.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: senticnet\nSuccessfully installed senticnet-1.6\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(lens)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:33:48.079879Z","iopub.execute_input":"2024-08-06T18:33:48.080223Z","iopub.status.idle":"2024-08-06T18:33:48.314234Z","shell.execute_reply.started":"2024-08-06T18:33:48.080195Z","shell.execute_reply":"2024-08-06T18:33:48.313311Z"},"trusted":true},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(array([ 267.,  805.,  991., 1078.,  570.,  465.,  489.,  215.,   67.,\n          11.]),\n array([ 0. ,  3.3,  6.6,  9.9, 13.2, 16.5, 19.8, 23.1, 26.4, 29.7, 33. ]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:34:16.349944Z","iopub.execute_input":"2024-08-06T18:34:16.350318Z","iopub.status.idle":"2024-08-06T18:34:17.270456Z","shell.execute_reply.started":"2024-08-06T18:34:16.350289Z","shell.execute_reply":"2024-08-06T18:34:17.269673Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# split into train, validation and test sets in the ration 70 : 15 : 15\nfrom sklearn.model_selection import train_test_split\n\ntrain_text, temp_text, train_labels, temp_labels = train_test_split(df['tweet'], df['class'], \n                                                                    random_state=2021, \n                                                                    test_size=0.3, \n                                                                    stratify=df['class'])\n\n\nval_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n                                                                random_state=2021, \n                                                                test_size=0.5, \n                                                                stratify=temp_labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:34:20.027761Z","iopub.execute_input":"2024-08-06T18:34:20.028108Z","iopub.status.idle":"2024-08-06T18:34:20.043570Z","shell.execute_reply.started":"2024-08-06T18:34:20.028083Z","shell.execute_reply":"2024-08-06T18:34:20.042675Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"bert = AutoModel.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:34:24.267699Z","iopub.execute_input":"2024-08-06T18:34:24.268415Z","iopub.status.idle":"2024-08-06T18:34:27.295703Z","shell.execute_reply.started":"2024-08-06T18:34:24.268373Z","shell.execute_reply":"2024-08-06T18:34:27.294911Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59130aa372514302ad12f00a11cff0ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2d422fc8f8e46be9d108d1be0bc0d69"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:34:29.543381Z","iopub.execute_input":"2024-08-06T18:34:29.543942Z","iopub.status.idle":"2024-08-06T18:34:30.681118Z","shell.execute_reply.started":"2024-08-06T18:34:29.543910Z","shell.execute_reply":"2024-08-06T18:34:30.680159Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2113fce7411b47b7827f7f5b963708e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b51c2649efe54885b822c3e38e35d16b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90ffbb0517a1484e84fe5ed636b55b41"}},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:34:33.112552Z","iopub.execute_input":"2024-08-06T18:34:33.113425Z","iopub.status.idle":"2024-08-06T18:34:33.118089Z","shell.execute_reply.started":"2024-08-06T18:34:33.113389Z","shell.execute_reply":"2024-08-06T18:34:33.116529Z"},"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"train_lens=[len(i.split()) for i in train_text]\nplt.hist(train_lens)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:34:36.994271Z","iopub.execute_input":"2024-08-06T18:34:36.995008Z","iopub.status.idle":"2024-08-06T18:34:37.284048Z","shell.execute_reply.started":"2024-08-06T18:34:36.994965Z","shell.execute_reply":"2024-08-06T18:34:37.283198Z"},"trusted":true},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"(array([192., 555., 679., 745., 409., 339., 340., 158.,  46.,   7.]),\n array([ 0. ,  3.3,  6.6,  9.9, 13.2, 16.5, 19.8, 23.1, 26.4, 29.7, 33. ]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"pad_len=18        #higher padding length means longer sentences will not be truncated ","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:34:40.519385Z","iopub.execute_input":"2024-08-06T18:34:40.520235Z","iopub.status.idle":"2024-08-06T18:34:40.526922Z","shell.execute_reply.started":"2024-08-06T18:34:40.520196Z","shell.execute_reply":"2024-08-06T18:34:40.525922Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import pandas as pd\n\nsequence_lengths = df['tweet'].apply(lambda x: len(x.split()))\nprint(sequence_lengths.describe())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:34:43.739515Z","iopub.execute_input":"2024-08-06T18:34:43.740198Z","iopub.status.idle":"2024-08-06T18:34:43.757331Z","shell.execute_reply.started":"2024-08-06T18:34:43.740151Z","shell.execute_reply":"2024-08-06T18:34:43.756349Z"},"trusted":true},"outputs":[{"name":"stdout","text":"count    4958.000000\nmean       12.075635\nstd         6.410801\nmin         0.000000\n25%         7.000000\n50%        11.000000\n75%        17.000000\nmax        33.000000\nName: tweet, dtype: float64\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"pd_len = sequence_lengths.quantile(0.80)\nprint(f\"Padding length: {pd_len}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:34:46.959972Z","iopub.execute_input":"2024-08-06T18:34:46.960330Z","iopub.status.idle":"2024-08-06T18:34:46.967020Z","shell.execute_reply.started":"2024-08-06T18:34:46.960302Z","shell.execute_reply":"2024-08-06T18:34:46.966082Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Padding length: 18.0\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# tokenize and encode sequences \ntokens_train = tokenizer.batch_encode_plus(\n    train_text.tolist(),\n    max_length = pad_len,\n    pad_to_max_length=True,\n    truncation=True\n)\n\ntokens_val = tokenizer.batch_encode_plus(\n    val_text.tolist(),\n    max_length = pad_len,\n    pad_to_max_length=True,\n    truncation=True\n)\n\ntokens_test = tokenizer.batch_encode_plus(\n    test_text.tolist(),\n    max_length = pad_len,\n    pad_to_max_length=True,\n    truncation=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T16:33:11.146454Z","iopub.execute_input":"2024-08-06T16:33:11.146779Z","iopub.status.idle":"2024-08-06T16:33:11.333581Z","shell.execute_reply.started":"2024-08-06T16:33:11.146755Z","shell.execute_reply":"2024-08-06T16:33:11.332591Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"train_seq = torch.tensor(tokens_train['input_ids'])\ntrain_mask = torch.tensor(tokens_train['attention_mask'])\ntrain_y = torch.tensor(train_labels.tolist())\n\nval_seq = torch.tensor(tokens_val['input_ids'])\nval_mask = torch.tensor(tokens_val['attention_mask'])\nval_y = torch.tensor(val_labels.tolist())\n\ntest_seq = torch.tensor(tokens_test['input_ids'])\ntest_mask = torch.tensor(tokens_test['attention_mask'])\ntest_y = torch.tensor(test_labels.tolist())","metadata":{"execution":{"iopub.status.busy":"2024-08-06T16:33:12.042109Z","iopub.execute_input":"2024-08-06T16:33:12.042743Z","iopub.status.idle":"2024-08-06T16:33:12.113539Z","shell.execute_reply.started":"2024-08-06T16:33:12.042710Z","shell.execute_reply":"2024-08-06T16:33:12.112712Z"},"trusted":true},"outputs":[],"execution_count":43},{"cell_type":"code","source":"\nfor param in bert.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:35:06.107560Z","iopub.execute_input":"2024-08-06T18:35:06.107930Z","iopub.status.idle":"2024-08-06T18:35:06.113310Z","shell.execute_reply.started":"2024-08-06T18:35:06.107901Z","shell.execute_reply":"2024-08-06T18:35:06.112399Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"\n\ndef personality_detection(text):\n    tokenizer = BertTokenizer.from_pretrained(\"Minej/bert-base-personality\")\n    model = BertForSequenceClassification.from_pretrained(\"Minej/bert-base-personality\")\n\n    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n    outputs = model(**inputs)\n    predictions = outputs.logits.squeeze().detach().numpy()\n\n    label_names = ['Extroversion', 'Neuroticism', 'Agreeableness', 'Conscientiousness', 'Openness']\n    result = {label_names[i]: predictions[i] for i in range(len(label_names))}\n\n    return result\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:35:02.073885Z","iopub.execute_input":"2024-08-06T18:35:02.074497Z","iopub.status.idle":"2024-08-06T18:35:02.080652Z","shell.execute_reply.started":"2024-08-06T18:35:02.074467Z","shell.execute_reply":"2024-08-06T18:35:02.079703Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, BertTokenizer\nimport torch\n\n# Initialization of the model values\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n\nmodel.config.label2id = {\n    \"Extroversion\": 0,\n    \"Neuroticism\": 1,\n    \"Agreeableness\": 2,\n    \"Conscientiousness\": 3,\n    \"Openness\": 4,\n}\nmodel.config.id2label = {\n    \"0\": \"Extroversion\",\n    \"1\": \"Neuroticism\",\n    \"2\": \"Agreeableness\",\n    \"3\": \"Conscientiousness\",\n    \"4\": \"Openness\",\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:36:39.359780Z","iopub.execute_input":"2024-08-06T18:36:39.360148Z","iopub.status.idle":"2024-08-06T18:36:40.021066Z","shell.execute_reply.started":"2024-08-06T18:36:39.360119Z","shell.execute_reply":"2024-08-06T18:36:40.020054Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"\n\ndef personality_detection_cust(model_input: str) -> dict:\n    '''\n    Performs personality prediction on the given input text\n\n    Args: \n        model_input (str): The text conversation \n\n    Returns:\n        dict: A dictionary where keys are speaker labels and values are their personality predictions\n    '''\n\n    if len(model_input) == 0:\n        ret = {\n            \"Extroversion\": float(0),\n            \"Neuroticism\": float(0),\n            \"Agreeableness\": float(0),\n            \"Conscientiousness\": float(0),\n            \"Openness\": float(0),\n        }\n        return ret\n    else:\n        dict_custom = {}\n        preprocess_part1 = model_input[:len(model_input)]\n        dict1 = tokenizer.encode_plus(preprocess_part1, max_length=1024, padding=True, truncation=True)\n        dict_custom['input_ids'] = [dict1['input_ids'], dict1['input_ids']]\n        dict_custom['token_type_ids'] = [dict1['token_type_ids'], dict1['token_type_ids']]\n        dict_custom['attention_mask'] = [dict1['attention_mask'], dict1['attention_mask']]\n        outs = model(torch.tensor(dict_custom['input_ids']), token_type_ids=None, attention_mask=torch.tensor(dict_custom['attention_mask']))\n        b_logit_pred = outs[0]\n        pred_label = torch.sigmoid(b_logit_pred)\n        ret = {\n            \"Extroversion\": float(pred_label[0][0]),\n            \"Neuroticism\": float(pred_label[0][1]),\n            \"Agreeableness\": float(pred_label[0][2]),\n            \"Conscientiousness\": float(pred_label[0][3]),\n            \"Openness\": float(pred_label[0][4]),\n        }\n        return ret\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:36:55.580964Z","iopub.execute_input":"2024-08-06T18:36:55.581333Z","iopub.status.idle":"2024-08-06T18:36:55.591325Z","shell.execute_reply.started":"2024-08-06T18:36:55.581304Z","shell.execute_reply":"2024-08-06T18:36:55.590506Z"},"trusted":true},"outputs":[],"execution_count":42},{"cell_type":"code","source":"text_input = df['tweet'][78] + df['tweet'][18]\nprint(text_input)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:37:00.934202Z","iopub.execute_input":"2024-08-06T18:37:00.934564Z","iopub.status.idle":"2024-08-06T18:37:00.939839Z","shell.execute_reply.started":"2024-08-06T18:37:00.934536Z","shell.execute_reply":"2024-08-06T18:37:00.938921Z"},"trusted":true},"outputs":[{"name":"stdout","text":"yep, i wish they were all playing dubilnyou guys didnt say hi or answer my questions yesterday but nice songs\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport plotly.express as px\n\npersonality_prediction = personality_detection_cust(text_input)\nprint(\"predicted personality:\", personality_prediction)\n\npersonality_approx_polar_plot_arr = []\nfor items in personality_prediction.values():\n#     if (items>0.5) :\n#         personality_approx_polar_plot_arr.append(1)\n#     else:\n#         personality_approx_polar_plot_arr.append(0)\n    personality_approx_polar_plot_arr.append(items)\n\nbig5 = pd.DataFrame(dict(r=personality_approx_polar_plot_arr, theta=['EXT','NEU','AGR', 'CON', 'OPN']))\nfig = px.line_polar(big5, r='r', theta='theta', line_close=True)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-06T18:37:03.311048Z","iopub.execute_input":"2024-08-06T18:37:03.311393Z","iopub.status.idle":"2024-08-06T18:37:03.474183Z","shell.execute_reply.started":"2024-08-06T18:37:03.311367Z","shell.execute_reply":"2024-08-06T18:37:03.473334Z"},"trusted":true},"outputs":[{"name":"stdout","text":"predicted personality: {'Extroversion': 0.4440465569496155, 'Neuroticism': 0.46614181995391846, 'Agreeableness': 0.4107775390148163, 'Conscientiousness': 0.689095675945282, 'Openness': 0.5329949259757996}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"ccb5656d-1e97-4cb3-b2be-f72e15c78a8d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ccb5656d-1e97-4cb3-b2be-f72e15c78a8d\")) {                    Plotly.newPlot(                        \"ccb5656d-1e97-4cb3-b2be-f72e15c78a8d\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.4440465569496155,0.46614181995391846,0.4107775390148163,0.689095675945282,0.5329949259757996,0.4440465569496155],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"EXT\",\"NEU\",\"AGR\",\"CON\",\"OPN\",\"EXT\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('ccb5656d-1e97-4cb3-b2be-f72e15c78a8d');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"predicted personality: {'Extroversion': 0.43206363916397095, 'Neuroticism': 0.5866072177886963, 'Agreeableness': 0.503466010093689, 'Conscientiousness': 0.37973764538764954, 'Openness': 0.5661113262176514}","metadata":{}},{"cell_type":"markdown","source":"{'Extroversion': 0.5065577626228333, 'Neuroticism': 0.5044019818305969, 'Agreeableness': 0.35140562057495117, 'Conscientiousness': 0.49903252720832825, 'Openness': 0.5363879799842834}","metadata":{}},{"cell_type":"markdown","source":"Extroversion': 0.4429108798503876, 'Neuroticism': 0.39871129393577576, 'Agreeableness': 0.6117495894432068, 'Conscientiousness': 0.3219671845436096, 'Openness': 0.6419437527656555","metadata":{}},{"cell_type":"markdown","source":"Extroversion': 0.5761680603027344, 'Neuroticism': 0.5096978545188904, 'Agreeableness': 0.41535818576812744, 'Conscientiousness': 0.3439335525035858, 'Openness': 0.5803135633468628","metadata":{}},{"cell_type":"markdown","source":"Extroversion': 0.5504656434059143, 'Neuroticism': 0.43145114183425903, 'Agreeableness': 0.46714869141578674, 'Conscientiousness': 0.41587862372398376, 'Openness': 0.4456329047679901","metadata":{}},{"cell_type":"code","source":"data_df_big5_traits = pd.DataFrame()\n\nfor items in df['tweet']:\n    temp = pd.DataFrame([personality_detection_cust(items)])\n    data_df_big5_traits = pd.concat([data_df_big5_traits , temp])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# conda create -n mvenv python=3.10\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118","metadata":{"execution":{"iopub.status.busy":"2024-07-19T15:19:11.912328Z","iopub.execute_input":"2024-07-19T15:19:11.913033Z","iopub.status.idle":"2024-07-19T15:19:27.647161Z","shell.execute_reply.started":"2024-07-19T15:19:11.913001Z","shell.execute_reply":"2024-07-19T15:19:27.646031Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.32.3)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n#defining a batch size\nbatch_size = 64\n\n# wrap tensors\ntrain_data = TensorDataset(train_seq, train_mask, train_y)\n\n# sampler for sampling the data during training\ntrain_sampler = RandomSampler(train_data)\n\n# dataLoader for train set\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# wrap tensors\nval_data = TensorDataset(val_seq, val_mask, val_y)\n\n# sampler for sampling the data during training\nval_sampler = SequentialSampler(val_data)\n\n# dataLoader for validation set\nval_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:30:59.082423Z","iopub.execute_input":"2024-07-08T07:30:59.083171Z","iopub.status.idle":"2024-07-08T07:30:59.089386Z","shell.execute_reply.started":"2024-07-08T07:30:59.083140Z","shell.execute_reply":"2024-07-08T07:30:59.088369Z"},"trusted":true},"outputs":[],"execution_count":49},{"cell_type":"code","source":"import torch.nn as nn\n\nclass BERT_architecture(nn.Module):\n\n    def __init__(self, bert):\n        super(BERT_architecture, self).__init__()\n\n        self.bert = bert \n        \n        # dropout layer - randomly selecting nodes to be dropped out with a given probability (e.g., 20%) while in the training loop\n        self.dropout = nn.Dropout(0.2) ##needs adjusment\n        \n        # ReLU activation function\n        self.relu = nn.ReLU()\n\n        # Dense layer 1\n        self.fc1 = nn.Linear(768, 512)\n        \n        # Dense layer 2 (Output layer)\n        self.fc2 = nn.Linear(512, 3)  #3 classes\n\n        # Softmax activation function\n        self.softmax = nn.LogSoftmax(dim=1)  # Ensure dim is set correctly\n\n    # Define the forward pass\n    def forward(self, sent_id, mask):\n        # Pass the inputs to the model  \n        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n        \n        x = self.fc1(cls_hs)\n        x = self.relu(x)\n        x = self.dropout(x)\n\n        # Output layer\n        x = self.fc2(x)\n        \n        # Apply softmax activation\n        x = self.softmax(x)\n\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:31:05.043955Z","iopub.execute_input":"2024-07-08T07:31:05.044810Z","iopub.status.idle":"2024-07-08T07:31:05.052683Z","shell.execute_reply.started":"2024-07-08T07:31:05.044772Z","shell.execute_reply":"2024-07-08T07:31:05.051699Z"},"trusted":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":"model = BERT_architecture(bert)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:31:08.914270Z","iopub.execute_input":"2024-07-08T07:31:08.915036Z","iopub.status.idle":"2024-07-08T07:31:08.922791Z","shell.execute_reply.started":"2024-07-08T07:31:08.914994Z","shell.execute_reply":"2024-07-08T07:31:08.921845Z"},"trusted":true},"outputs":[],"execution_count":52},{"cell_type":"code","source":"test_seq = test_seq.to(device)\ntest_mask = test_mask.to(device)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:31:10.874641Z","iopub.execute_input":"2024-07-08T07:31:10.875233Z","iopub.status.idle":"2024-07-08T07:31:10.888518Z","shell.execute_reply.started":"2024-07-08T07:31:10.875200Z","shell.execute_reply":"2024-07-08T07:31:10.887640Z"},"trusted":true},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"BERT_architecture(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.2, inplace=False)\n  (relu): ReLU()\n  (fc1): Linear(in_features=768, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=3, bias=True)\n  (softmax): LogSoftmax(dim=1)\n)"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"from transformers import AdamW\n\n# define the optimizer #can use different optimizers\noptimizer = AdamW(model.parameters(),lr = 1e-3)  ## learning rate needs to be adjusted.","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:31:14.069215Z","iopub.execute_input":"2024-07-08T07:31:14.069594Z","iopub.status.idle":"2024-07-08T07:31:14.079282Z","shell.execute_reply.started":"2024-07-08T07:31:14.069564Z","shell.execute_reply":"2024-07-08T07:31:14.078300Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nimport torch\nimport torch.nn as nn\n\n# Compute the class weights for three classes\nclass_weights = compute_class_weight(class_weight=\"balanced\",\n                                     classes=np.unique(train_labels),\n                                     y=train_labels)\nprint(\"Class weights are {} for {}\".format(class_weights, np.unique(train_labels)))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:31:16.943083Z","iopub.execute_input":"2024-07-08T07:31:16.943450Z","iopub.status.idle":"2024-07-08T07:31:16.952135Z","shell.execute_reply.started":"2024-07-08T07:31:16.943409Z","shell.execute_reply":"2024-07-08T07:31:16.951222Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Class weights are [1.05151515 0.94808743 1.0057971 ] for [0 1 2]\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"pd.value_counts(train_labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:31:19.298155Z","iopub.execute_input":"2024-07-08T07:31:19.298876Z","iopub.status.idle":"2024-07-08T07:31:19.306604Z","shell.execute_reply.started":"2024-07-08T07:31:19.298842Z","shell.execute_reply":"2024-07-08T07:31:19.305695Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/883685092.py:1: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n  pd.value_counts(train_labels)\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"1    1220\n2    1150\n0    1100\nName: count, dtype: int64"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"weights = torch.tensor(class_weights, dtype=torch.float)\n\nweights = weights.to(device)\n\n# Define loss function\n# Use nn.CrossEntropyLoss without specifying weights for class imbalance\ncross_entropy = nn.CrossEntropyLoss()\n\n# Number of training epochs\nepochs = 50 ##increase the no of epochs for better accuracy \n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:31:22.332680Z","iopub.execute_input":"2024-07-08T07:31:22.333033Z","iopub.status.idle":"2024-07-08T07:31:22.338547Z","shell.execute_reply.started":"2024-07-08T07:31:22.333004Z","shell.execute_reply":"2024-07-08T07:31:22.337709Z"},"trusted":true},"outputs":[],"execution_count":57},{"cell_type":"code","source":"def train():\n    model.train()\n    total_loss, total_accuracy = 0, 0\n    total_preds, total_labels = [], []\n\n    for step, batch in enumerate(train_dataloader):\n        if step % 50 == 0 and not step == 0:\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n\n        batch = [r.to(device) for r in batch]\n        sent_id, mask, labels = batch\n        model.zero_grad()\n        preds = model(sent_id, mask)\n        loss = cross_entropy(preds, labels)\n        total_loss = total_loss + loss.item()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n        preds = preds.detach().cpu().numpy()\n        total_preds.append(preds)\n        total_labels.append(labels.detach().cpu().numpy())\n\n    avg_loss = total_loss / len(train_dataloader)\n    total_preds = np.concatenate(total_preds, axis=0)\n    total_labels = np.concatenate(total_labels, axis=0)\n    return avg_loss, total_preds, total_labels\n\ndef evaluate():\n    print(\"\\nEvaluating after the test: \")\n    model.eval()\n    total_loss, total_accuracy = 0, 0\n    total_preds, total_labels = [], []\n\n    for step, batch in enumerate(val_dataloader):\n        if step % 50 == 0 and not step == 0:\n            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n\n        batch = [t.to(device) for t in batch]\n        sent_id, mask, labels = batch\n\n        with torch.no_grad():\n            preds = model(sent_id, mask)\n            loss = cross_entropy(preds, labels)\n            total_loss = total_loss + loss.item()\n            preds = preds.detach().cpu().numpy()\n            total_preds.append(preds)\n            total_labels.append(labels.detach().cpu().numpy())\n\n    avg_loss = total_loss / len(val_dataloader)\n    total_preds = np.concatenate(total_preds, axis=0)\n    total_labels = np.concatenate(total_labels, axis=0)\n    return avg_loss, total_preds, total_labels\ndef calculate_accuracy(preds, labels):\n\n    preds_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    accuracy = np.sum(preds_flat == labels_flat) / len(labels_flat)\n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:31:27.236455Z","iopub.execute_input":"2024-07-08T07:31:27.237270Z","iopub.status.idle":"2024-07-08T07:31:27.252016Z","shell.execute_reply.started":"2024-07-08T07:31:27.237234Z","shell.execute_reply":"2024-07-08T07:31:27.251117Z"},"trusted":true},"outputs":[],"execution_count":58},{"cell_type":"code","source":"best_valid_loss = float('inf')\ntrain_losses = []\nvalid_losses = []\ntrain_accuracies = []\nvalid_accuracies = []\n\nfor epoch in range(epochs):\n    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n    \n    train_loss, train_preds, train_labels = train()\n    valid_loss, valid_preds, valid_labels = evaluate()\n    \n    # Calculate accuracy\n    train_accuracy = calculate_accuracy(train_preds, train_labels)\n    valid_accuracy = calculate_accuracy(valid_preds, valid_labels)\n    \n    # Save the best model\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), 'saved_weights.pt')\n    \n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    train_accuracies.append(train_accuracy)\n    valid_accuracies.append(valid_accuracy)\n    \n    print('\\nTraining Loss: {}'.format(train_loss))\n    print('Validation Loss: {}'.format(valid_loss))\n    print('Training Accuracy: {:.2f}%'.format(train_accuracy * 100))\n    print('Validation Accuracy: {:.2f}%'.format(valid_accuracy * 100))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:31:31.904281Z","iopub.execute_input":"2024-07-08T07:31:31.904638Z","iopub.status.idle":"2024-07-08T07:35:48.125722Z","shell.execute_reply.started":"2024-07-08T07:31:31.904605Z","shell.execute_reply":"2024-07-08T07:35:48.124657Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n Epoch 1 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 1.1068848111412741\nValidation Loss: 1.0848006308078766\nTraining Accuracy: 36.54%\nValidation Accuracy: 35.75%\n\n Epoch 2 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 1.0751390067013826\nValidation Loss: 1.054021532336871\nTraining Accuracy: 40.12%\nValidation Accuracy: 40.73%\n\n Epoch 3 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 1.0408122344450517\nValidation Loss: 1.0037956684827805\nTraining Accuracy: 45.39%\nValidation Accuracy: 51.08%\n\n Epoch 4 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 1.0388141371987083\nValidation Loss: 1.003834918141365\nTraining Accuracy: 45.36%\nValidation Accuracy: 51.34%\n\n Epoch 5 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 1.0002127333120867\nValidation Loss: 0.961539293328921\nTraining Accuracy: 49.68%\nValidation Accuracy: 53.23%\n\n Epoch 6 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9967556541616266\nValidation Loss: 0.9962784796953201\nTraining Accuracy: 51.07%\nValidation Accuracy: 47.85%\n\n Epoch 7 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.992771006714214\nValidation Loss: 0.9456219474474589\nTraining Accuracy: 50.63%\nValidation Accuracy: 57.12%\n\n Epoch 8 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9762379949743097\nValidation Loss: 1.0006627589464188\nTraining Accuracy: 50.98%\nValidation Accuracy: 44.76%\n\n Epoch 9 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9865609624169089\nValidation Loss: 0.9372522334257761\nTraining Accuracy: 51.18%\nValidation Accuracy: 54.57%\n\n Epoch 10 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9821112578565424\nValidation Loss: 0.9858292490243912\nTraining Accuracy: 52.48%\nValidation Accuracy: 49.73%\n\n Epoch 11 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9680230422453446\nValidation Loss: 0.9887260049581528\nTraining Accuracy: 52.28%\nValidation Accuracy: 48.39%\n\n Epoch 12 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9661131772128019\nValidation Loss: 0.929031083981196\nTraining Accuracy: 52.51%\nValidation Accuracy: 57.12%\n\n Epoch 13 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9660014878619801\nValidation Loss: 1.0294723361730576\nTraining Accuracy: 52.74%\nValidation Accuracy: 47.98%\n\n Epoch 14 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9514394630085338\nValidation Loss: 0.9433248440424601\nTraining Accuracy: 52.88%\nValidation Accuracy: 52.28%\n\n Epoch 15 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9554556196386164\nValidation Loss: 0.9133795003096262\nTraining Accuracy: 54.58%\nValidation Accuracy: 57.93%\n\n Epoch 16 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9616851969198748\nValidation Loss: 0.9167327284812927\nTraining Accuracy: 53.08%\nValidation Accuracy: 56.99%\n\n Epoch 17 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9462943976575678\nValidation Loss: 0.9112464735905329\nTraining Accuracy: 54.24%\nValidation Accuracy: 59.41%\n\n Epoch 18 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9524969046766107\nValidation Loss: 0.9603416621685028\nTraining Accuracy: 53.26%\nValidation Accuracy: 50.40%\n\n Epoch 19 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9401651685888117\nValidation Loss: 0.9076036612192789\nTraining Accuracy: 53.92%\nValidation Accuracy: 57.12%\n\n Epoch 20 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9460642088543285\nValidation Loss: 0.8971356004476547\nTraining Accuracy: 53.98%\nValidation Accuracy: 58.47%\n\n Epoch 21 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9419134703549472\nValidation Loss: 0.9044451763232549\nTraining Accuracy: 54.61%\nValidation Accuracy: 56.05%\n\n Epoch 22 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9447234869003296\nValidation Loss: 0.9052562812964121\nTraining Accuracy: 55.01%\nValidation Accuracy: 56.99%\n\n Epoch 23 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9439086523923007\nValidation Loss: 0.9401308099428812\nTraining Accuracy: 53.63%\nValidation Accuracy: 56.72%\n\n Epoch 24 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9282935261726379\nValidation Loss: 0.8894729614257812\nTraining Accuracy: 56.05%\nValidation Accuracy: 59.54%\n\n Epoch 25 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9341204372319308\nValidation Loss: 0.9663440634806951\nTraining Accuracy: 55.76%\nValidation Accuracy: 50.27%\n\n Epoch 26 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9316809860142794\nValidation Loss: 0.8995329687992731\nTraining Accuracy: 54.87%\nValidation Accuracy: 56.59%\n\n Epoch 27 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9361341086300936\nValidation Loss: 0.9093635727961858\nTraining Accuracy: 54.67%\nValidation Accuracy: 56.85%\n\n Epoch 28 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9350157336755233\nValidation Loss: 0.9000119864940643\nTraining Accuracy: 55.53%\nValidation Accuracy: 57.93%\n\n Epoch 29 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9310506408864802\nValidation Loss: 0.9385498960812887\nTraining Accuracy: 55.01%\nValidation Accuracy: 51.21%\n\n Epoch 30 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9400346159934998\nValidation Loss: 0.9001085460186005\nTraining Accuracy: 54.18%\nValidation Accuracy: 58.06%\n\n Epoch 31 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9346739996563305\nValidation Loss: 0.8890985498825709\nTraining Accuracy: 54.93%\nValidation Accuracy: 58.60%\n\n Epoch 32 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9300778410651467\nValidation Loss: 0.9323558906714121\nTraining Accuracy: 55.07%\nValidation Accuracy: 55.11%\n\n Epoch 33 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9311577926982533\nValidation Loss: 0.8963373651107153\nTraining Accuracy: 55.24%\nValidation Accuracy: 57.93%\n\n Epoch 34 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9159694151444868\nValidation Loss: 0.8904697100321451\nTraining Accuracy: 56.69%\nValidation Accuracy: 57.93%\n\n Epoch 35 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.925933156230233\nValidation Loss: 0.922886480887731\nTraining Accuracy: 55.68%\nValidation Accuracy: 54.30%\n\n Epoch 36 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.923971875147386\nValidation Loss: 0.8915365437666575\nTraining Accuracy: 56.28%\nValidation Accuracy: 58.87%\n\n Epoch 37 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9291906519369646\nValidation Loss: 0.9084712415933609\nTraining Accuracy: 55.79%\nValidation Accuracy: 58.06%\n\n Epoch 38 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9254200913689353\nValidation Loss: 0.9575798263152441\nTraining Accuracy: 56.14%\nValidation Accuracy: 52.55%\n\n Epoch 39 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9216063889590177\nValidation Loss: 0.897030254205068\nTraining Accuracy: 55.82%\nValidation Accuracy: 57.93%\n\n Epoch 40 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9231466618451205\nValidation Loss: 0.9146785537401835\nTraining Accuracy: 55.73%\nValidation Accuracy: 56.85%\n\n Epoch 41 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9342692180113359\nValidation Loss: 0.8877789427836736\nTraining Accuracy: 55.36%\nValidation Accuracy: 58.47%\n\n Epoch 42 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9168627164580605\nValidation Loss: 0.9406052430470785\nTraining Accuracy: 57.18%\nValidation Accuracy: 54.17%\n\n Epoch 43 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.929890496080572\nValidation Loss: 0.876637468735377\nTraining Accuracy: 55.36%\nValidation Accuracy: 59.14%\n\n Epoch 44 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.922939618067308\nValidation Loss: 0.8927535762389501\nTraining Accuracy: 55.36%\nValidation Accuracy: 58.60%\n\n Epoch 45 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9246167811480436\nValidation Loss: 0.8857861856619517\nTraining Accuracy: 56.25%\nValidation Accuracy: 59.54%\n\n Epoch 46 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9184528405016119\nValidation Loss: 0.9760101934274038\nTraining Accuracy: 55.56%\nValidation Accuracy: 51.21%\n\n Epoch 47 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9263698946345936\nValidation Loss: 0.8785034120082855\nTraining Accuracy: 55.68%\nValidation Accuracy: 59.54%\n\n Epoch 48 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9029344992204146\nValidation Loss: 0.8817175229390463\nTraining Accuracy: 57.49%\nValidation Accuracy: 58.33%\n\n Epoch 49 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9085855819962242\nValidation Loss: 0.884246955315272\nTraining Accuracy: 57.29%\nValidation Accuracy: 58.06%\n\n Epoch 50 / 50\n  Batch    50  of     55.\n\nEvaluating...\n\nTraining Loss: 0.9047296209768816\nValidation Loss: 0.8769303460915884\nTraining Accuracy: 56.95%\nValidation Accuracy: 59.81%\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nwith torch.no_grad():\n  preds = model(test_seq.to(device), test_mask.to(device))\n  preds = preds.detach().cpu().numpy()\npred = np.argmax(preds, axis = 1)\nprint(classification_report(test_y, pred))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:35:51.773500Z","iopub.execute_input":"2024-07-08T07:35:51.773859Z","iopub.status.idle":"2024-07-08T07:35:52.542756Z","shell.execute_reply.started":"2024-07-08T07:35:51.773831Z","shell.execute_reply":"2024-07-08T07:35:52.541794Z"},"trusted":true},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.58      0.58      0.58       236\n           1       0.50      0.60      0.55       262\n           2       0.61      0.48      0.54       246\n\n    accuracy                           0.56       744\n   macro avg       0.57      0.56      0.56       744\nweighted avg       0.56      0.56      0.56       744\n\n","output_type":"stream"}],"execution_count":60}]}