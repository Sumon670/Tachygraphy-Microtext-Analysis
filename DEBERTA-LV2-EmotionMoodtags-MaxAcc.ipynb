{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da0d7c7e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:03.894640Z",
     "iopub.status.busy": "2024-08-29T18:12:03.894272Z",
     "iopub.status.idle": "2024-08-29T18:12:04.765808Z",
     "shell.execute_reply": "2024-08-29T18:12:04.764687Z"
    },
    "papermill": {
     "duration": 0.910985,
     "end_time": "2024-08-29T18:12:04.767975",
     "exception": false,
     "start_time": "2024-08-29T18:12:03.856990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_EmotionMoodtags_Dataset.csv\n",
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_dataset_main.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3cf465",
   "metadata": {
    "papermill": {
     "duration": 0.034318,
     "end_time": "2024-08-29T18:12:04.838570",
     "exception": false,
     "start_time": "2024-08-29T18:12:04.804252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET & PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da05dabe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:04.909079Z",
     "iopub.status.busy": "2024-08-29T18:12:04.908565Z",
     "iopub.status.idle": "2024-08-29T18:12:05.153804Z",
     "shell.execute_reply": "2024-08-29T18:12:05.152924Z"
    },
    "papermill": {
     "duration": 0.283199,
     "end_time": "2024-08-29T18:12:05.155952",
     "exception": false,
     "start_time": "2024-08-29T18:12:04.872753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For emoji cleaning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "'''For emoji cleaning'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cb74fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:05.227392Z",
     "iopub.status.busy": "2024-08-29T18:12:05.226882Z",
     "iopub.status.idle": "2024-08-29T18:12:05.268129Z",
     "shell.execute_reply": "2024-08-29T18:12:05.267324Z"
    },
    "papermill": {
     "duration": 0.079655,
     "end_time": "2024-08-29T18:12:05.270584",
     "exception": false,
     "start_time": "2024-08-29T18:12:05.190929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/kaggle/input/dataset-tachygraphy/Tachygraphy_EmotionMoodtags_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a21fce7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:05.344175Z",
     "iopub.status.busy": "2024-08-29T18:12:05.343543Z",
     "iopub.status.idle": "2024-08-29T18:12:05.347988Z",
     "shell.execute_reply": "2024-08-29T18:12:05.346928Z"
    },
    "papermill": {
     "duration": 0.042698,
     "end_time": "2024-08-29T18:12:05.350060",
     "exception": false,
     "start_time": "2024-08-29T18:12:05.307362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "392ec51c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:05.422821Z",
     "iopub.status.busy": "2024-08-29T18:12:05.422490Z",
     "iopub.status.idle": "2024-08-29T18:12:05.445568Z",
     "shell.execute_reply": "2024-08-29T18:12:05.444803Z"
    },
    "papermill": {
     "duration": 0.062784,
     "end_time": "2024-08-29T18:12:05.447569",
     "exception": false,
     "start_time": "2024-08-29T18:12:05.384785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
    "                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n",
    "                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n",
    "                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n",
    "                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
    "                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
    "                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n",
    "                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
    "                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n",
    "                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
    "                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n",
    "\n",
    "punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n",
    "                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n",
    "                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '}\n",
    "\n",
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n",
    "                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n",
    "                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n",
    "                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n",
    "                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n",
    "                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n",
    "                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n",
    "                'demonetisation': 'demonetization'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad9f1e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:05.520101Z",
     "iopub.status.busy": "2024-08-29T18:12:05.519295Z",
     "iopub.status.idle": "2024-08-29T18:12:05.532491Z",
     "shell.execute_reply": "2024-08-29T18:12:05.531708Z"
    },
    "papermill": {
     "duration": 0.051997,
     "end_time": "2024-08-29T18:12:05.534418",
     "exception": false,
     "start_time": "2024-08-29T18:12:05.482421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean emoji, Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\:(.*?)\\:','',text)\n",
    "    text = str(text).lower()    #Making Text Lowercase\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    #The next 2 lines remove html text\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    '''Clean contraction using contraction mapping'''    \n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    for word in mapping.keys():\n",
    "        if \"\"+word+\"\" in text:\n",
    "            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n",
    "    #Remove Punctuations\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    '''Cleans special characters present(if any)'''   \n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def correct_spelling(x, dic):\n",
    "    '''Corrects common spelling errors'''   \n",
    "    for word in dic.keys():\n",
    "        x = x.replace(word, dic[word])\n",
    "    return x\n",
    "\n",
    "def remove_space(text):\n",
    "    '''Removes awkward spaces'''   \n",
    "    #Removes awkward spaces \n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ca58cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:05.605056Z",
     "iopub.status.busy": "2024-08-29T18:12:05.604692Z",
     "iopub.status.idle": "2024-08-29T18:12:05.609848Z",
     "shell.execute_reply": "2024-08-29T18:12:05.608967Z"
    },
    "papermill": {
     "duration": 0.042857,
     "end_time": "2024-08-29T18:12:05.611820",
     "exception": false,
     "start_time": "2024-08-29T18:12:05.568963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing_pipeline(text):\n",
    "    '''Cleaning and parsing the text.'''\n",
    "    text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_text(text)\n",
    "    text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_special_chars(text, punct, punct_mapping)\n",
    "#     text = correct_spelling(text, mispell_dict)\n",
    "    text = remove_space(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792baf1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:05.682358Z",
     "iopub.status.busy": "2024-08-29T18:12:05.681971Z",
     "iopub.status.idle": "2024-08-29T18:12:05.695246Z",
     "shell.execute_reply": "2024-08-29T18:12:05.694329Z"
    },
    "papermill": {
     "duration": 0.050778,
     "end_time": "2024-08-29T18:12:05.697132",
     "exception": false,
     "start_time": "2024-08-29T18:12:05.646354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                last session of the day \n",
       "1       shanghai is also really exciting precisely  sk...\n",
       "2                                  submit the report asap\n",
       "3                                              happy bday\n",
       "4                                      the ogs  i like it\n",
       "                              ...                        \n",
       "4953      make a pet face  wtf wrong with me tonight haha\n",
       "4954         i dnt care anymore  boyz aint worth d drama \n",
       "4955    no relationship is perfect tho me bae goo from...\n",
       "4956    over here tryna get my nail polishes and shit lol\n",
       "4957                       no one was loved d way i luv u\n",
       "Name: text, Length: 4958, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710b2464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:05.768342Z",
     "iopub.status.busy": "2024-08-29T18:12:05.767696Z",
     "iopub.status.idle": "2024-08-29T18:12:05.780211Z",
     "shell.execute_reply": "2024-08-29T18:12:05.779453Z"
    },
    "papermill": {
     "duration": 0.050375,
     "end_time": "2024-08-29T18:12:05.782147",
     "exception": false,
     "start_time": "2024-08-29T18:12:05.731772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_columns = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
    "df[emotion_columns] = df[emotion_columns].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38ce5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:05.853970Z",
     "iopub.status.busy": "2024-08-29T18:12:05.853294Z",
     "iopub.status.idle": "2024-08-29T18:12:05.858514Z",
     "shell.execute_reply": "2024-08-29T18:12:05.857628Z"
    },
    "papermill": {
     "duration": 0.04284,
     "end_time": "2024-08-29T18:12:05.860388",
     "exception": false,
     "start_time": "2024-08-29T18:12:05.817548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str)\n",
    "# df['anger'] = df['anger'].astype(float)\n",
    "# df['disgust'] = df['disgust'].astype(float)\n",
    "# df['fear'] = df['fear'].astype(float)\n",
    "# df['joy'] = df['joy'].astype(float)\n",
    "# df['neutral'] = df['neutral'].astype(float)\n",
    "# df['sadness'] = df['sadness'].astype(float)\n",
    "# df['surprise'] = df['surprise'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a0514b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:05.932175Z",
     "iopub.status.busy": "2024-08-29T18:12:05.931385Z",
     "iopub.status.idle": "2024-08-29T18:12:08.346193Z",
     "shell.execute_reply": "2024-08-29T18:12:08.345294Z"
    },
    "papermill": {
     "duration": 2.453432,
     "end_time": "2024-08-29T18:12:08.348795",
     "exception": false,
     "start_time": "2024-08-29T18:12:05.895363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: text_preprocessing_pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "847c95b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:08.422709Z",
     "iopub.status.busy": "2024-08-29T18:12:08.421897Z",
     "iopub.status.idle": "2024-08-29T18:12:08.429658Z",
     "shell.execute_reply": "2024-08-29T18:12:08.428800Z"
    },
    "papermill": {
     "duration": 0.046895,
     "end_time": "2024-08-29T18:12:08.431580",
     "exception": false,
     "start_time": "2024-08-29T18:12:08.384685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 last session of the day\n",
       "1       shanghai is also really exciting precisely sky...\n",
       "2                                  submit the report asap\n",
       "3                                              happy bday\n",
       "4                                       the ogs i like it\n",
       "                              ...                        \n",
       "4953       make a pet face wtf wrong with me tonight haha\n",
       "4954           i dnt care anymore boyz aint worth d drama\n",
       "4955    no relationship is perfect tho me bae goo from...\n",
       "4956    over here tryna get my nail polishes and shit lol\n",
       "4957                       no one was loved d way i luv u\n",
       "Name: text, Length: 4958, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ea0fe6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:08.508401Z",
     "iopub.status.busy": "2024-08-29T18:12:08.508066Z",
     "iopub.status.idle": "2024-08-29T18:12:08.515300Z",
     "shell.execute_reply": "2024-08-29T18:12:08.514570Z"
    },
    "papermill": {
     "duration": 0.050297,
     "end_time": "2024-08-29T18:12:08.517472",
     "exception": false,
     "start_time": "2024-08-29T18:12:08.467175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['serial', 'pred', 'label', 'score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5092b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:08.591602Z",
     "iopub.status.busy": "2024-08-29T18:12:08.591281Z",
     "iopub.status.idle": "2024-08-29T18:12:08.595890Z",
     "shell.execute_reply": "2024-08-29T18:12:08.595003Z"
    },
    "papermill": {
     "duration": 0.042607,
     "end_time": "2024-08-29T18:12:08.597769",
     "exception": false,
     "start_time": "2024-08-29T18:12:08.555162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_label_mapping = {\n",
    "    0: \"anger\", 1: \"disgust\", 2: \"fear\", 3: \"joy\", 4: \"neutral\",\n",
    "    5: \"sadness\", 6: \"surprise\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3302eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:08.708639Z",
     "iopub.status.busy": "2024-08-29T18:12:08.707934Z",
     "iopub.status.idle": "2024-08-29T18:12:08.712320Z",
     "shell.execute_reply": "2024-08-29T18:12:08.711488Z"
    },
    "papermill": {
     "duration": 0.081327,
     "end_time": "2024-08-29T18:12:08.714179",
     "exception": false,
     "start_time": "2024-08-29T18:12:08.632852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMOTION_LABELS = [\n",
    "    \"anger\", \"disgust\", \"fear\", \"joy\", \"neutral\",\n",
    "    \"sadness\", \"surprise\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "504fe8e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:08.785368Z",
     "iopub.status.busy": "2024-08-29T18:12:08.785042Z",
     "iopub.status.idle": "2024-08-29T18:12:08.789765Z",
     "shell.execute_reply": "2024-08-29T18:12:08.788917Z"
    },
    "papermill": {
     "duration": 0.042691,
     "end_time": "2024-08-29T18:12:08.791671",
     "exception": false,
     "start_time": "2024-08-29T18:12:08.748980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_train_split(dataset, test_ratio=0.1):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cb1e1c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:08.862946Z",
     "iopub.status.busy": "2024-08-29T18:12:08.862642Z",
     "iopub.status.idle": "2024-08-29T18:12:08.871603Z",
     "shell.execute_reply": "2024-08-29T18:12:08.870640Z"
    },
    "papermill": {
     "duration": 0.046773,
     "end_time": "2024-08-29T18:12:08.873546",
     "exception": false,
     "start_time": "2024-08-29T18:12:08.826773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4466 examples in training, 492 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "train_ds_pd, validation_ds_pd = test_train_split(df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_ds_pd), len(validation_ds_pd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd95debb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:08.945748Z",
     "iopub.status.busy": "2024-08-29T18:12:08.945093Z",
     "iopub.status.idle": "2024-08-29T18:12:08.951199Z",
     "shell.execute_reply": "2024-08-29T18:12:08.950485Z"
    },
    "papermill": {
     "duration": 0.043888,
     "end_time": "2024-08-29T18:12:08.952979",
     "exception": false,
     "start_time": "2024-08-29T18:12:08.909091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd = train_ds_pd.reset_index(drop=True)\n",
    "validation_ds_pd = validation_ds_pd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "030a841d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:09.026541Z",
     "iopub.status.busy": "2024-08-29T18:12:09.026214Z",
     "iopub.status.idle": "2024-08-29T18:12:12.700680Z",
     "shell.execute_reply": "2024-08-29T18:12:12.699884Z"
    },
    "papermill": {
     "duration": 3.714389,
     "end_time": "2024-08-29T18:12:12.702955",
     "exception": false,
     "start_time": "2024-08-29T18:12:08.988566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dabf961",
   "metadata": {
    "papermill": {
     "duration": 0.034658,
     "end_time": "2024-08-29T18:12:12.772946",
     "exception": false,
     "start_time": "2024-08-29T18:12:12.738288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SETTING CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfca6056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:12.845217Z",
     "iopub.status.busy": "2024-08-29T18:12:12.844400Z",
     "iopub.status.idle": "2024-08-29T18:12:12.935666Z",
     "shell.execute_reply": "2024-08-29T18:12:12.934687Z"
    },
    "papermill": {
     "duration": 0.129794,
     "end_time": "2024-08-29T18:12:12.937598",
     "exception": false,
     "start_time": "2024-08-29T18:12:12.807804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0a8978b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:13.009736Z",
     "iopub.status.busy": "2024-08-29T18:12:13.008913Z",
     "iopub.status.idle": "2024-08-29T18:12:13.013386Z",
     "shell.execute_reply": "2024-08-29T18:12:13.012554Z"
    },
    "papermill": {
     "duration": 0.042542,
     "end_time": "2024-08-29T18:12:13.015348",
     "exception": false,
     "start_time": "2024-08-29T18:12:12.972806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ff8d604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:13.086995Z",
     "iopub.status.busy": "2024-08-29T18:12:13.086639Z",
     "iopub.status.idle": "2024-08-29T18:12:15.429359Z",
     "shell.execute_reply": "2024-08-29T18:12:15.427831Z"
    },
    "papermill": {
     "duration": 2.381748,
     "end_time": "2024-08-29T18:12:15.432172",
     "exception": false,
     "start_time": "2024-08-29T18:12:13.050424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import DebertaV2Model, DebertaV2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec4b1e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:15.504152Z",
     "iopub.status.busy": "2024-08-29T18:12:15.503627Z",
     "iopub.status.idle": "2024-08-29T18:12:18.293455Z",
     "shell.execute_reply": "2024-08-29T18:12:18.292499Z"
    },
    "papermill": {
     "duration": 2.827961,
     "end_time": "2024-08-29T18:12:18.295626",
     "exception": false,
     "start_time": "2024-08-29T18:12:15.467665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67eaf6295fe40828e8f2677510ffbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cc1a243a644fb782cc784af7338edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbd67ecc0b945a8b106dbacec0524bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2d64c96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:18.368350Z",
     "iopub.status.busy": "2024-08-29T18:12:18.367485Z",
     "iopub.status.idle": "2024-08-29T18:12:18.371552Z",
     "shell.execute_reply": "2024-08-29T18:12:18.370705Z"
    },
    "papermill": {
     "duration": 0.042142,
     "end_time": "2024-08-29T18:12:18.373485",
     "exception": false,
     "start_time": "2024-08-29T18:12:18.331343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e5fef",
   "metadata": {
    "papermill": {
     "duration": 0.036242,
     "end_time": "2024-08-29T18:12:18.444920",
     "exception": false,
     "start_time": "2024-08-29T18:12:18.408678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TORCH IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe1224d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:18.517855Z",
     "iopub.status.busy": "2024-08-29T18:12:18.516882Z",
     "iopub.status.idle": "2024-08-29T18:12:36.001766Z",
     "shell.execute_reply": "2024-08-29T18:12:36.000837Z"
    },
    "papermill": {
     "duration": 17.523983,
     "end_time": "2024-08-29T18:12:36.004129",
     "exception": false,
     "start_time": "2024-08-29T18:12:18.480146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 18:12:20,687\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-08-29 18:12:21,219\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "# from optuna.integration import PyTorchLightningPruner\n",
    "from ray import tune\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from ray.tune.integration.pytorch import TuneReportCallback\n",
    "from torch.amp import GradScaler, autocast\n",
    "# from ray.tune.integration.optuna import OptunaSearch\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from torch import autocast\n",
    "# from ray import tune\n",
    "# from ray.tune.integration.tensorboard import TensorBoardReporter\n",
    "from ray.tune.logger import TBXLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ray.train import report\n",
    "# from ray.tune.integration.jupyter import JupyterNotebookReporter\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from ray.tune.schedulers import HyperBandScheduler, AsyncHyperBandScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c42891",
   "metadata": {
    "papermill": {
     "duration": 0.035296,
     "end_time": "2024-08-29T18:12:36.075855",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.040559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET CONFIG & ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62b2f884",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:36.149114Z",
     "iopub.status.busy": "2024-08-29T18:12:36.147893Z",
     "iopub.status.idle": "2024-08-29T18:12:36.156888Z",
     "shell.execute_reply": "2024-08-29T18:12:36.156059Z"
    },
    "papermill": {
     "duration": 0.04764,
     "end_time": "2024-08-29T18:12:36.158824",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.111184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         text = self.data.iloc[index, 0]\n",
    "#         labels = self.data.iloc[index, 1:].values.astype(float)\n",
    "        text = str(self.data.iloc[index]['text'])\n",
    "        labels = self.data.iloc[index][['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']].values.astype(np.float32)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613d230",
   "metadata": {
    "papermill": {
     "duration": 0.035488,
     "end_time": "2024-08-29T18:12:36.230105",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.194617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b12d31f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:36.303493Z",
     "iopub.status.busy": "2024-08-29T18:12:36.302755Z",
     "iopub.status.idle": "2024-08-29T18:12:36.310931Z",
     "shell.execute_reply": "2024-08-29T18:12:36.310078Z"
    },
    "papermill": {
     "duration": 0.047241,
     "end_time": "2024-08-29T18:12:36.312898",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.265657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class EmotionModel(nn.Module):\n",
    "    def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "        super(EmotionModel, self).__init__()\n",
    "        self.roberta = roberta_model\n",
    "        self.drop = nn.Dropout(p=dropout_rate)\n",
    "        self.fc1 = nn.Linear(self.roberta.config.hidden_size, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.out = nn.Linear(256, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         hidden_states = output.last_hidden_state\n",
    "        \n",
    "        # Extract the [CLS] token representation (first token in the sequence)\n",
    "        cls_token_state = output.last_hidden_state[:, 0, :]\n",
    "        output = self.drop(cls_token_state)\n",
    "        output = self.relu(self.fc1(output))\n",
    "        output = self.drop(output)\n",
    "        output = self.relu(self.fc2(output))\n",
    "#         output = self.drop(output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44011a49",
   "metadata": {
    "papermill": {
     "duration": 0.035397,
     "end_time": "2024-08-29T18:12:36.384093",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.348696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Other Models to try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f40b9068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:36.457216Z",
     "iopub.status.busy": "2024-08-29T18:12:36.456476Z",
     "iopub.status.idle": "2024-08-29T18:12:36.460979Z",
     "shell.execute_reply": "2024-08-29T18:12:36.460055Z"
    },
    "papermill": {
     "duration": 0.043053,
     "end_time": "2024-08-29T18:12:36.462949",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.419896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class EmotionModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(EmotionModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.out = nn.Linear(self.roberta.config.hidden_size, n_classes)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         output = self.drop(output.pooler_output)\n",
    "#         return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e4f6a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:36.536598Z",
     "iopub.status.busy": "2024-08-29T18:12:36.536070Z",
     "iopub.status.idle": "2024-08-29T18:12:36.541003Z",
     "shell.execute_reply": "2024-08-29T18:12:36.540198Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.044678,
     "end_time": "2024-08-29T18:12:36.543077",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.498399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class EmotionModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(EmotionModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size, 512)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.out = nn.Linear(256, n_classes)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         # Get the RoBERTa output\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         # Use the pooled output for classification tasks\n",
    "#         pooled_output = output.pooler_output\n",
    "#         # Pass through the custom layers\n",
    "#         output = self.drop(pooled_output)\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "#         output = self.drop(output)\n",
    "#         return self.out(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c8a13ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:36.630692Z",
     "iopub.status.busy": "2024-08-29T18:12:36.629819Z",
     "iopub.status.idle": "2024-08-29T18:12:36.634793Z",
     "shell.execute_reply": "2024-08-29T18:12:36.633930Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.045059,
     "end_time": "2024-08-29T18:12:36.636873",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.591814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class EmotionModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate, hidden_size):\n",
    "#         super(EmotionModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size, hidden_size)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "#         self.out = nn.Linear(hidden_size // 2, n_classes)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         # Get the RoBERTa output\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         # Use the pooled output for classification tasks\n",
    "#         pooled_output = output.pooler_output\n",
    "#         # Pass through the custom layers\n",
    "#         output = self.drop(pooled_output)\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "#         output = self.drop(output)\n",
    "#         return self.out(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d47f1c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:36.711486Z",
     "iopub.status.busy": "2024-08-29T18:12:36.711144Z",
     "iopub.status.idle": "2024-08-29T18:12:36.715494Z",
     "shell.execute_reply": "2024-08-29T18:12:36.714582Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.042778,
     "end_time": "2024-08-29T18:12:36.717435",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.674657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class RoBERTaEmotionModel(nn.Module):\n",
    "#     def __init__(self, roberta_model_name, num_emotions=7):\n",
    "#         super(RoBERTaEmotionModel, self).__init__()\n",
    "#         self.roberta = RobertaModel.from_pretrained(roberta_model_name)\n",
    "#         self.drop = nn.Dropout(p=0.3)\n",
    "#         self.out = nn.Linear(self.roberta.config.hidden_size, num_emotions)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         outputs = self.roberta(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask\n",
    "#         )\n",
    "#         pooled_output = outputs[1]  # CLS token\n",
    "#         output = self.drop(pooled_output)\n",
    "#         return self.out(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ed8a9",
   "metadata": {
    "papermill": {
     "duration": 0.035352,
     "end_time": "2024-08-29T18:12:36.788301",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.752949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN & VALIDATION \n",
    "### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0e11212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:36.861736Z",
     "iopub.status.busy": "2024-08-29T18:12:36.861396Z",
     "iopub.status.idle": "2024-08-29T18:12:36.866785Z",
     "shell.execute_reply": "2024-08-29T18:12:36.865857Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.044615,
     "end_time": "2024-08-29T18:12:36.868779",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.824164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_model(model, train_loader, val_loader, loss_fn, optimizer, device, scheduler, scaler, n_epochs):\n",
    "#     for epoch in range(n_epochs):\n",
    "#         model.train()\n",
    "#         train_loss = 0\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "\n",
    "#         for data in train_loader:\n",
    "#             input_ids = data['input_ids'].to(device)\n",
    "#             attention_mask = data['attention_mask'].to(device)\n",
    "#             labels = data['labels'].to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             with autocast(device_type=device.type):\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = loss_fn(outputs, labels)\n",
    "\n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "#             if scheduler:\n",
    "#                 scheduler.step()\n",
    "\n",
    "#             train_loss += loss.item()\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "#         train_accuracy = correct / total\n",
    "#         val_loss, val_accuracy = eval_model(model, val_loader, loss_fn, device)\n",
    "\n",
    "#         print(f'Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c9870a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:36.942207Z",
     "iopub.status.busy": "2024-08-29T18:12:36.941471Z",
     "iopub.status.idle": "2024-08-29T18:12:36.946227Z",
     "shell.execute_reply": "2024-08-29T18:12:36.945330Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.043679,
     "end_time": "2024-08-29T18:12:36.948159",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.904480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def eval_model(model, val_loader, loss_fn, device):\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for data in val_loader:\n",
    "#             input_ids = data['input_ids'].to(device)\n",
    "#             attention_mask = data['attention_mask'].to(device)\n",
    "#             labels = data['labels'].to(device)\n",
    "\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = loss_fn(outputs, labels)\n",
    "#             val_loss += loss.item()\n",
    "\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "#     val_accuracy = correct / total\n",
    "#     return val_loss / len(val_loader), val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b5f14e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:37.020286Z",
     "iopub.status.busy": "2024-08-29T18:12:37.019941Z",
     "iopub.status.idle": "2024-08-29T18:12:37.025356Z",
     "shell.execute_reply": "2024-08-29T18:12:37.024518Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.04357,
     "end_time": "2024-08-29T18:12:37.027209",
     "exception": false,
     "start_time": "2024-08-29T18:12:36.983639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     hidden_size = trial.suggest_int('hidden_size', 64, 256)\n",
    "#     dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
    "#     batch_size = trial.suggest_categorical('batch_size', [2, 4, 8, 16])\n",
    "#     learning_rate = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "#     epochs = 5  # Adjust as needed\n",
    "\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    \n",
    "#     # Load your data here\n",
    "# #     data = df  # Replace with your data loading logic\n",
    "# #     train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "# #         data.iloc[:, 0],  # Assuming text is in the first column\n",
    "# #         data.iloc[:, 1:],  # Labels are in the remaining columns\n",
    "# #         test_size=0.2\n",
    "# #     )\n",
    "\n",
    "\n",
    "# #     train_dataset = EmotionDataset(pd.DataFrame({'text': train_texts, **pd.DataFrame(train_labels)}), tokenizer, max_len=128)\n",
    "# #     val_dataset = EmotionDataset(pd.DataFrame({'text': val_texts, **pd.DataFrame(val_labels)}), tokenizer, max_len=128)\n",
    "    \n",
    "    \n",
    "#     train_dataset = EmotionDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "#     val_dataset = EmotionDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     model = EmotionClassifier(hidden_size=hidden_size, dropout_rate=dropout_rate).to(device)\n",
    "#     loss_fn = nn.BCEWithLogitsLoss()\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "#     scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "#     scaler = GradScaler()\n",
    "\n",
    "#     train_model(model, train_loader, val_loader, loss_fn, optimizer, device, scheduler, scaler, epochs)\n",
    "#     val_loss, val_accuracy = eval_model(model, val_loader, loss_fn, device)\n",
    "    \n",
    "#     return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70c80451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:37.099691Z",
     "iopub.status.busy": "2024-08-29T18:12:37.099352Z",
     "iopub.status.idle": "2024-08-29T18:12:37.104721Z",
     "shell.execute_reply": "2024-08-29T18:12:37.103870Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.043985,
     "end_time": "2024-08-29T18:12:37.106567",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.062582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_fn(config):\n",
    "#     try:\n",
    "#         hidden_size = config['hidden_size']\n",
    "#         dropout_rate = config['dropout_rate']\n",
    "#         batch_size = config['batch_size']\n",
    "#         learning_rate = config['lr']\n",
    "#         epochs = 5\n",
    "\n",
    "#         tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "#         # Load your data here\n",
    "# #         data = pd.read_csv('path_to_your_data.csv')  # Replace with your data loading logic\n",
    "# #         train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "# #             data.iloc[:, 0],  # Assuming text is in the first column\n",
    "# #             data.iloc[:, 1:],  # Labels are in the remaining columns\n",
    "# #             test_size=0.2\n",
    "# #         )\n",
    "\n",
    "#         train_dataset = EmotionDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "#         val_dataset = EmotionDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "#         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#         val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#         model = EmotionClassifier(hidden_size=hidden_size, dropout_rate=dropout_rate).to(device)\n",
    "#         loss_fn = nn.BCEWithLogitsLoss()\n",
    "#         optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "#         scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=epochs)\n",
    "#         scaler = GradScaler()\n",
    "\n",
    "#         for epoch in range(epochs):\n",
    "#             train_model(model, train_loader, val_loader, loss_fn, optimizer, device, scheduler, scaler, epochs)\n",
    "#             val_loss, val_accuracy = eval_model(model, val_loader, loss_fn, device)\n",
    "#             tune.report(loss=val_loss, accuracy=val_accuracy)\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fa9ad1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:37.179159Z",
     "iopub.status.busy": "2024-08-29T18:12:37.178778Z",
     "iopub.status.idle": "2024-08-29T18:12:37.183630Z",
     "shell.execute_reply": "2024-08-29T18:12:37.182842Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.043411,
     "end_time": "2024-08-29T18:12:37.185547",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.142136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def tune_model(config):\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "#     train_df, val_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "#     train_dataset = EmotionDataset(train_df, tokenizer, config['max_len'])\n",
    "#     val_dataset = EmotionDataset(val_df, tokenizer, config['max_len'])\n",
    "\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=config['batch_size'])\n",
    "\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     model = RoBERTaEmotionModel('roberta-base').to(device)\n",
    "\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "#     loss_fn = nn.MSELoss().to(device)\n",
    "#     scaler = GradScaler()\n",
    "\n",
    "#     scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=config['lr'], steps_per_epoch=len(train_loader), epochs=config['epochs'])\n",
    "\n",
    "#     train_model(model, train_loader, val_loader, loss_fn, optimizer, device, scheduler, scaler, config['epochs'])\n",
    "\n",
    "#     val_loss = eval_model(model, val_loader, loss_fn, device)\n",
    "#     tune.report(val_loss=val_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43b01cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:37.257890Z",
     "iopub.status.busy": "2024-08-29T18:12:37.257571Z",
     "iopub.status.idle": "2024-08-29T18:12:37.262097Z",
     "shell.execute_reply": "2024-08-29T18:12:37.261240Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.042691,
     "end_time": "2024-08-29T18:12:37.263919",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.221228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     'max_len': tune.choice([128, 192, 256]),\n",
    "#     'batch_size': tune.choice([8, 16, 32]),\n",
    "#     'lr': tune.loguniform(1e-5, 5e-5),\n",
    "#     'epochs': tune.choice([3, 5, 7])\n",
    "# }\n",
    "\n",
    "# scheduler = ASHAScheduler(\n",
    "#     metric='val_loss',\n",
    "#     mode='min',\n",
    "#     max_t=10,\n",
    "#     grace_period=1,\n",
    "#     reduction_factor=2\n",
    "# )\n",
    "\n",
    "# reporter = CLIReporter(\n",
    "#     metric_columns=['val_loss', 'training_iteration']\n",
    "# )\n",
    "\n",
    "# analysis = tune.run(\n",
    "#     tune_model,\n",
    "#     resources_per_trial={'cpu': 2, 'gpu': 1},\n",
    "#     config=config,\n",
    "#     num_samples=20,\n",
    "#     scheduler=scheduler,\n",
    "#     progress_reporter=reporter\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1c87bdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:37.336972Z",
     "iopub.status.busy": "2024-08-29T18:12:37.336658Z",
     "iopub.status.idle": "2024-08-29T18:12:37.343301Z",
     "shell.execute_reply": "2024-08-29T18:12:37.342400Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.045031,
     "end_time": "2024-08-29T18:12:37.345191",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.300160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_model(config, train_dataset, val_dataset, device):\n",
    "#     model = EmotionModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=7,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "#     model = model.to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "#     train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "#     model.train()\n",
    "#     for epoch in range(config[\"epochs\"]):\n",
    "#         total_train_loss = 0.0\n",
    "#         correct_train_preds = 0\n",
    "#         total_train_preds = 0\n",
    "        \n",
    "#         for batch in train_loader:\n",
    "#             input_ids = batch[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#             labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "        \n",
    "#         avg_train_loss = total_train_loss / len(train_loader)\n",
    "#         train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         total_val_loss = 0.0\n",
    "#         correct_val_preds = 0\n",
    "#         total_val_preds = 0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 input_ids = batch[\"input_ids\"].to(device)\n",
    "#                 attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#                 labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "                \n",
    "#                 total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "\n",
    "#         avg_val_loss = total_val_loss / len(val_loader)\n",
    "#         val_accuracy = correct_val_preds / total_val_preds\n",
    "\n",
    "#         tune.report(loss=avg_val_loss, accuracy=val_accuracy, train_loss=avg_train_loss, train_accuracy=train_accuracy)\n",
    "#         model_save_path = os.path.join(tune.get_trial_dir(), \"checkpoint.pt\")\n",
    "#         torch.save(model.state_dict(), model_save_path)\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# def train_fn(config):\n",
    "#     # Load your data here\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "#     train_dataset = EmotionDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "#     val_dataset = EmotionDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     train_model(config, train_dataset, val_dataset, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec430e",
   "metadata": {
    "papermill": {
     "duration": 0.035885,
     "end_time": "2024-08-29T18:12:37.420636",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.384751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## NEW TRAIN & VALIDATION 2.0\n",
    "### Custom metric is a metric for determining the best model free from any overfitting, underfitting. ```custom_metric = (avg_val_loss−val_accuracy) + α × ∣avg_train_loss−avg_val_loss∣ + β × ∣val_accuracy-train_accuracy∣``` This metric balances between low validation loss, high validation accuracy, and penalizing large discrepancies between training and validation loss. Note that, in the model selection we have used ```α = β = 0.5```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbed244",
   "metadata": {
    "papermill": {
     "duration": 0.035354,
     "end_time": "2024-08-29T18:12:37.491781",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.456427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### But since, we have probabilistic values as input and output we cannot directly calculate the accuracy, infact we need to rely on loss only. ```custom_metric = avg_val_loss + α × ∣avg_train_loss−avg_val_loss∣```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72105ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:37.582681Z",
     "iopub.status.busy": "2024-08-29T18:12:37.582198Z",
     "iopub.status.idle": "2024-08-29T18:12:37.589667Z",
     "shell.execute_reply": "2024-08-29T18:12:37.587073Z"
    },
    "papermill": {
     "duration": 0.060686,
     "end_time": "2024-08-29T18:12:37.591975",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.531289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom metric calculation function\n",
    "def calculate_custom_metric(avg_val_loss, avg_train_loss, alpha=0.5):\n",
    "    loss_diff = abs(avg_train_loss - avg_val_loss)\n",
    "    custom_metric = avg_val_loss + alpha * loss_diff\n",
    "    return custom_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53ef8e69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:37.665472Z",
     "iopub.status.busy": "2024-08-29T18:12:37.665107Z",
     "iopub.status.idle": "2024-08-29T18:12:37.669218Z",
     "shell.execute_reply": "2024-08-29T18:12:37.668332Z"
    },
    "papermill": {
     "duration": 0.042774,
     "end_time": "2024-08-29T18:12:37.671049",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.628275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Custom metric calculation function\n",
    "# def calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy, alpha=0.5, beta=0.5):\n",
    "#     loss_diff = abs(avg_train_loss - avg_val_loss)\n",
    "#     accuracy_diff = abs(train_accuracy - val_accuracy)\n",
    "#     custom_metric = avg_val_loss - val_accuracy + alpha * loss_diff + beta * accuracy_diff\n",
    "#     return custom_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa95fdf",
   "metadata": {
    "papermill": {
     "duration": 0.035385,
     "end_time": "2024-08-29T18:12:37.742005",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.706620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f236c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:37.815182Z",
     "iopub.status.busy": "2024-08-29T18:12:37.814793Z",
     "iopub.status.idle": "2024-08-29T18:12:37.821958Z",
     "shell.execute_reply": "2024-08-29T18:12:37.821090Z"
    },
    "papermill": {
     "duration": 0.046354,
     "end_time": "2024-08-29T18:12:37.823938",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.777584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        EarlyStopping to stop training when a metric has stopped improving.\n",
    "\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "            delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss improved to {val_loss:.4f}')\n",
    "#             torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss did not improve. Patience: {self.patience}, Counter: {self.counter}')\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23d52916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:37.898241Z",
     "iopub.status.busy": "2024-08-29T18:12:37.897861Z",
     "iopub.status.idle": "2024-08-29T18:12:37.919647Z",
     "shell.execute_reply": "2024-08-29T18:12:37.918748Z"
    },
    "papermill": {
     "duration": 0.061582,
     "end_time": "2024-08-29T18:12:37.921770",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.860188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training function with variable parameters\n",
    "def train_model(config, train_dataset, val_dataset, device):\n",
    "#     model = EmotionModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=7,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    model = EmotionModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=7,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = nn.MSELoss()\n",
    "    scaler = GradScaler()  # Initialize GradScaler\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):  # Ensure epochs are passed from config\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):  # Mixed precision\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "            correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "                \n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    outputs = torch.sigmoid(outputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "                correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "#         custom_metric = avg_val_loss - val_accuracy\n",
    "#         custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, avg_train_loss)\n",
    "\n",
    "        # Report metrics using ray.train.report\n",
    "        report({\n",
    "            \"loss\": avg_val_loss,\n",
    "            \"accuracy\": val_accuracy,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"custom_metric\": custom_metric,\n",
    "            \"early_stopping_epoch\": epoch + 1,\n",
    "        })\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "#         trial_dir = os.path.join(os.environ[\"TUNE_TRIAL_DIR\"], \"checkpoint.pt\")\n",
    "#         torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "#         checkpoint_path = f\"/kaggle/working/checkpoint_epoch_{epoch}.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_fn(config):\n",
    "    # Load your data here\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "    train_dataset = EmotionDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = EmotionDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(config, train_dataset, val_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03064f99",
   "metadata": {
    "papermill": {
     "duration": 0.035326,
     "end_time": "2024-08-29T18:12:37.992614",
     "exception": false,
     "start_time": "2024-08-29T18:12:37.957288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6cf5027d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.065487Z",
     "iopub.status.busy": "2024-08-29T18:12:38.065106Z",
     "iopub.status.idle": "2024-08-29T18:12:38.071785Z",
     "shell.execute_reply": "2024-08-29T18:12:38.070906Z"
    },
    "papermill": {
     "duration": 0.045727,
     "end_time": "2024-08-29T18:12:38.073786",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.028059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'dropout_rate': tune.choice([0.2, 0.25, 0.27, 0.3, 0.35, 0.4]),\n",
    "    'batch_size': tune.choice([32, 64]),\n",
    "    'weight_decay': tune.choice([1e-6, 2e-6, 1e-5, 2e-5, 1e-4, 2e-4, 5e-5, 5e-6, 1e-2, 1e-3]),\n",
    "    'lr': tune.choice([1e-6, 1e-5, 2e-5, 1e-4, 2e-4, 2e-6, 3e-6, 5e-6, 3e-5, 5e-5, 2e-7, 1e-7, 5e-7, 1e-3]),\n",
    "    'epochs': tune.choice([5, 7, 10, 12, 15, 20])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bcc2e36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.145987Z",
     "iopub.status.busy": "2024-08-29T18:12:38.145660Z",
     "iopub.status.idle": "2024-08-29T18:12:38.150078Z",
     "shell.execute_reply": "2024-08-29T18:12:38.149069Z"
    },
    "papermill": {
     "duration": 0.042744,
     "end_time": "2024-08-29T18:12:38.151943",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.109199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     'hidden_size': tune.choice([32, 64, 128, 256]),\n",
    "#     'dropout_rate': tune.uniform(0.1, 0.5),\n",
    "#     'batch_size': tune.choice([16, 32, 64]),\n",
    "#     'weight_decay': tune.loguniform(1e-6, 1e-1),\n",
    "#     'lr': tune.loguniform(1e-6, 1e-1),\n",
    "#     'epochs': tune.choice([3, 5, 7, 10, 12, 15, 20])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51c56d91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.224260Z",
     "iopub.status.busy": "2024-08-29T18:12:38.223768Z",
     "iopub.status.idle": "2024-08-29T18:12:38.227797Z",
     "shell.execute_reply": "2024-08-29T18:12:38.226913Z"
    },
    "papermill": {
     "duration": 0.04238,
     "end_time": "2024-08-29T18:12:38.229781",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.187401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     'dropout_rate': tune.uniform(0.1, 0.5),\n",
    "#     'batch_size': tune.choice([16, 32, 64]),\n",
    "#     'weight_decay': tune.loguniform(1e-6, 1e-1),\n",
    "#     'lr': tune.loguniform(1e-6, 1e-1),\n",
    "#     'epochs': tune.choice([3, 5, 7, 10, 12, 15, 20])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee8c3879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.302466Z",
     "iopub.status.busy": "2024-08-29T18:12:38.302146Z",
     "iopub.status.idle": "2024-08-29T18:12:38.306159Z",
     "shell.execute_reply": "2024-08-29T18:12:38.305255Z"
    },
    "papermill": {
     "duration": 0.043021,
     "end_time": "2024-08-29T18:12:38.308151",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.265130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     'hidden_size': tune.choice([32, 64, 128, 256]),\n",
    "#     'dropout_rate': tune.uniform(0.1, 0.5),\n",
    "#     'batch_size': tune.choice([16, 32, 64]),\n",
    "#     'weight_decay': tune.loguniform(1e-6, 1e-1),\n",
    "#     'lr': tune.loguniform(1e-6, 1e-1),\n",
    "#     'epochs': tune.randint(3, 21)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b2a7b62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.380666Z",
     "iopub.status.busy": "2024-08-29T18:12:38.380331Z",
     "iopub.status.idle": "2024-08-29T18:12:38.384352Z",
     "shell.execute_reply": "2024-08-29T18:12:38.383471Z"
    },
    "papermill": {
     "duration": 0.042433,
     "end_time": "2024-08-29T18:12:38.386248",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.343815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     'hidden_size': tune.choice([256, 512]),\n",
    "#     'dropout_rate': tune.uniform(0.1, 0.5),\n",
    "#     'batch_size': tune.choice([4, 8, 16]),\n",
    "#     'lr': tune.loguniform(1e-5, 1e-2)\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f30b147",
   "metadata": {
    "papermill": {
     "duration": 0.035203,
     "end_time": "2024-08-29T18:12:38.456760",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.421557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "394452b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.530893Z",
     "iopub.status.busy": "2024-08-29T18:12:38.530210Z",
     "iopub.status.idle": "2024-08-29T18:12:38.534684Z",
     "shell.execute_reply": "2024-08-29T18:12:38.533756Z"
    },
    "papermill": {
     "duration": 0.044608,
     "end_time": "2024-08-29T18:12:38.536735",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.492127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna_search = OptunaSearch(\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9cd2ee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.609617Z",
     "iopub.status.busy": "2024-08-29T18:12:38.609269Z",
     "iopub.status.idle": "2024-08-29T18:12:38.613523Z",
     "shell.execute_reply": "2024-08-29T18:12:38.612736Z"
    },
    "papermill": {
     "duration": 0.042967,
     "end_time": "2024-08-29T18:12:38.615440",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.572473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optuna_search = OptunaSearch(\n",
    "#     metric=[\n",
    "#         tune.MultiObjective(\"loss\", \"min\"),\n",
    "#         tune.MultiObjective(\"custom_metric\", \"min\"),\n",
    "#         tune.MultiObjective(\"accuracy\", \"max\")\n",
    "#     ],\n",
    "#     mode=[\n",
    "#         \"min\",  # for loss\n",
    "#         \"min\",  # for custom metric\n",
    "#         \"max\"   # for accuracy\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5986e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.687511Z",
     "iopub.status.busy": "2024-08-29T18:12:38.687201Z",
     "iopub.status.idle": "2024-08-29T18:12:38.690853Z",
     "shell.execute_reply": "2024-08-29T18:12:38.690038Z"
    },
    "papermill": {
     "duration": 0.04221,
     "end_time": "2024-08-29T18:12:38.692762",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.650552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optuna_search = OptunaSearch(\n",
    "#     metric=\"custom_metric\",\n",
    "#     mode=\"min\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb49bbd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.782255Z",
     "iopub.status.busy": "2024-08-29T18:12:38.781799Z",
     "iopub.status.idle": "2024-08-29T18:12:38.785913Z",
     "shell.execute_reply": "2024-08-29T18:12:38.785040Z"
    },
    "papermill": {
     "duration": 0.056478,
     "end_time": "2024-08-29T18:12:38.787949",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.731471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Setup Optuna for hyperparameter optimization\n",
    "# optuna_search = OptunaSearch(\n",
    "#     metric=\"loss\",\n",
    "#     mode=\"min\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36bc227e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.860603Z",
     "iopub.status.busy": "2024-08-29T18:12:38.860276Z",
     "iopub.status.idle": "2024-08-29T18:12:38.865466Z",
     "shell.execute_reply": "2024-08-29T18:12:38.864586Z"
    },
    "papermill": {
     "duration": 0.043952,
     "end_time": "2024-08-29T18:12:38.867467",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.823515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scheduler = ASHAScheduler(\n",
    "#     metric=\"loss\",\n",
    "#     mode=\"min\",\n",
    "#     max_t=15,\n",
    "#     grace_period=1,\n",
    "#     reduction_factor=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbaecec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:38.939607Z",
     "iopub.status.busy": "2024-08-29T18:12:38.939284Z",
     "iopub.status.idle": "2024-08-29T18:12:38.943213Z",
     "shell.execute_reply": "2024-08-29T18:12:38.942374Z"
    },
    "papermill": {
     "duration": 0.042213,
     "end_time": "2024-08-29T18:12:38.945077",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.902864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scheduler = ASHAScheduler(\n",
    "#     metric=\"accuracy\",\n",
    "#     mode=\"max\",\n",
    "#     max_t=15,\n",
    "#     grace_period=1,\n",
    "#     reduction_factor=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8b2b1",
   "metadata": {
    "papermill": {
     "duration": 0.035052,
     "end_time": "2024-08-29T18:12:39.015640",
     "exception": false,
     "start_time": "2024-08-29T18:12:38.980588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SCHEDULER ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b63ff78e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:39.088298Z",
     "iopub.status.busy": "2024-08-29T18:12:39.087893Z",
     "iopub.status.idle": "2024-08-29T18:12:39.092656Z",
     "shell.execute_reply": "2024-08-29T18:12:39.091814Z"
    },
    "papermill": {
     "duration": 0.043526,
     "end_time": "2024-08-29T18:12:39.094563",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.051037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric='accuracy',\n",
    "    mode='max',\n",
    "    max_t=22,\n",
    "    grace_period=3,\n",
    "    reduction_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bf8e6bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:39.168170Z",
     "iopub.status.busy": "2024-08-29T18:12:39.167321Z",
     "iopub.status.idle": "2024-08-29T18:12:39.171504Z",
     "shell.execute_reply": "2024-08-29T18:12:39.170619Z"
    },
    "papermill": {
     "duration": 0.042889,
     "end_time": "2024-08-29T18:12:39.173362",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.130473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scheduler = AsyncHyperBandScheduler(\n",
    "#     metric='accuracy',\n",
    "#     mode='max',\n",
    "#     max_t=22,\n",
    "#     grace_period=3,\n",
    "#     reduction_factor=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92b53a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:39.247784Z",
     "iopub.status.busy": "2024-08-29T18:12:39.246825Z",
     "iopub.status.idle": "2024-08-29T18:12:39.251589Z",
     "shell.execute_reply": "2024-08-29T18:12:39.250691Z"
    },
    "papermill": {
     "duration": 0.044325,
     "end_time": "2024-08-29T18:12:39.253661",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.209336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scheduler = ASHAScheduler(\n",
    "#     metric=[\n",
    "#         tune.MultiObjective(\"loss\", \"min\"),\n",
    "#         tune.MultiObjective(\"custom_metric\", \"min\"),\n",
    "#         tune.MultiObjective(\"accuracy\", \"max\")\n",
    "#     ],\n",
    "#     mode=[\n",
    "#         \"min\",  # for loss\n",
    "#         \"min\",  # for custom metric\n",
    "#         \"max\"   # for accuracy\n",
    "#     ],\n",
    "#     max_t=22,\n",
    "#     grace_period=3,\n",
    "#     reduction_factor=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72e86321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:39.326134Z",
     "iopub.status.busy": "2024-08-29T18:12:39.325808Z",
     "iopub.status.idle": "2024-08-29T18:12:39.329778Z",
     "shell.execute_reply": "2024-08-29T18:12:39.328974Z"
    },
    "papermill": {
     "duration": 0.042265,
     "end_time": "2024-08-29T18:12:39.331647",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.289382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scheduler = ASHAScheduler(\n",
    "#     metric=\"custom_metric\",\n",
    "#     mode=\"min\",\n",
    "#     max_t=22,\n",
    "#     grace_period=3,\n",
    "#     reduction_factor=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91d50789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:39.404627Z",
     "iopub.status.busy": "2024-08-29T18:12:39.404322Z",
     "iopub.status.idle": "2024-08-29T18:12:39.408475Z",
     "shell.execute_reply": "2024-08-29T18:12:39.407604Z"
    },
    "papermill": {
     "duration": 0.043057,
     "end_time": "2024-08-29T18:12:39.410334",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.367277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scheduler = HyperBandScheduler(\n",
    "#     time_attr='training_iteration',  # The attribute to use for the time dimension (similar to ASHA's `max_t`)\n",
    "#     metric='custom_metric',          # The metric to optimize (similar to ASHA's `metric`)\n",
    "#     mode='min',                      # Optimization mode (minimize `custom_metric`)\n",
    "#     max_t=22,                        # Maximum number of iterations per trial (similar to ASHA's `max_t`)\n",
    "#     reduction_factor=2               # Reduction factor (similar to ASHA)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a308a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:39.482342Z",
     "iopub.status.busy": "2024-08-29T18:12:39.481993Z",
     "iopub.status.idle": "2024-08-29T18:12:39.486671Z",
     "shell.execute_reply": "2024-08-29T18:12:39.485758Z"
    },
    "papermill": {
     "duration": 0.042934,
     "end_time": "2024-08-29T18:12:39.488664",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.445730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reporter = CLIReporter(\n",
    "    metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "    print_intermediate_tables=False\n",
    ")\n",
    "reporter.verbosity = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e1746",
   "metadata": {
    "papermill": {
     "duration": 0.035974,
     "end_time": "2024-08-29T18:12:39.561257",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.525283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom CLI Reporter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b916c899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:39.633934Z",
     "iopub.status.busy": "2024-08-29T18:12:39.633037Z",
     "iopub.status.idle": "2024-08-29T18:12:39.638330Z",
     "shell.execute_reply": "2024-08-29T18:12:39.637466Z"
    },
    "papermill": {
     "duration": 0.0436,
     "end_time": "2024-08-29T18:12:39.640206",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.596606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class FinalTableCLIReporter(CLIReporter):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.results = []\n",
    "\n",
    "#     def _update(self, *args, **kwargs):\n",
    "#         # Collect results without printing intermediate updates\n",
    "#         self.results.append(kwargs)\n",
    "\n",
    "#     def print_table(self):\n",
    "#         # Print only the final results\n",
    "#         if self.results:\n",
    "#             final_results = [result for result in self.results]\n",
    "#             headers = list(final_results[0].keys()) if final_results else []\n",
    "#             table = [headers] + [list(result.values()) for result in final_results]\n",
    "#             for row in table:\n",
    "#                 print(\" | \".join(str(cell) for cell in row))\n",
    "\n",
    "#     def _report(self, *args, **kwargs):\n",
    "#         # Override this to prevent intermediate print\n",
    "#         self._update(*args, **kwargs)\n",
    "\n",
    "#     def _finalize(self):\n",
    "#         # Call this to print the final table\n",
    "#         self.print_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe583543",
   "metadata": {
    "papermill": {
     "duration": 0.035159,
     "end_time": "2024-08-29T18:12:39.710849",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.675690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee97dd9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:39.783230Z",
     "iopub.status.busy": "2024-08-29T18:12:39.782679Z",
     "iopub.status.idle": "2024-08-29T18:12:39.786938Z",
     "shell.execute_reply": "2024-08-29T18:12:39.786130Z"
    },
    "papermill": {
     "duration": 0.042733,
     "end_time": "2024-08-29T18:12:39.788802",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.746069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To ignore warinings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e71d787e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T18:12:39.860885Z",
     "iopub.status.busy": "2024-08-29T18:12:39.860555Z",
     "iopub.status.idle": "2024-08-29T23:41:53.295592Z",
     "shell.execute_reply": "2024-08-29T23:41:53.294781Z"
    },
    "papermill": {
     "duration": 19753.473513,
     "end_time": "2024-08-29T23:41:53.297714",
     "exception": false,
     "start_time": "2024-08-29T18:12:39.824201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-08-29 23:41:53</td></tr>\n",
       "<tr><td>Running for: </td><td>05:28:56.74        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.2/31.4 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=49<br>Bracket: Iter 12.000: 0.9263937282229966 | Iter 6.000: 0.9207317073170732 | Iter 3.000: 0.9101335656213705<br>Logical resource usage: 2.0/4 CPUs, 1.0/2 GPUs (0.0/1.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  early_stopping_epoch</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_74e1235b</td><td>TERMINATED</td><td>172.19.2.2:340 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.0546616</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0549307</td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">  0.0541233 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_393cddc8</td><td>TERMINATED</td><td>172.19.2.2:376 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.054192 </td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0542331</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">  0.0541099 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_d8aa3878</td><td>TERMINATED</td><td>172.19.2.2:483 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.0333584</td><td style=\"text-align: right;\">  0.917828</td><td style=\"text-align: right;\">      0.0412064</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">  0.0176624 </td><td style=\"text-align: right;\">        0.954641</td><td style=\"text-align: right;\">                    13</td></tr>\n",
       "<tr><td>train_fn_7e0568dc</td><td>TERMINATED</td><td>172.19.2.2:573 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.0450784</td><td style=\"text-align: right;\">  0.895761</td><td style=\"text-align: right;\">      0.0477495</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0504207 </td><td style=\"text-align: right;\">        0.890698</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_90c8d9ba</td><td>TERMINATED</td><td>172.19.2.2:678 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.0268234</td><td style=\"text-align: right;\">  0.926829</td><td style=\"text-align: right;\">      0.0360044</td><td style=\"text-align: right;\">                  12</td><td style=\"text-align: right;\">  0.00846155</td><td style=\"text-align: right;\">        0.973514</td><td style=\"text-align: right;\">                    12</td></tr>\n",
       "<tr><td>train_fn_1ff8a192</td><td>TERMINATED</td><td>172.19.2.2:759 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.095339 </td><td style=\"text-align: right;\">  0.889082</td><td style=\"text-align: right;\">      0.105833 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.116328  </td><td style=\"text-align: right;\">        0.883181</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f64cae7c</td><td>TERMINATED</td><td>172.19.2.2:848 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.182334 </td><td style=\"text-align: right;\">  0.676249</td><td style=\"text-align: right;\">      0.183867 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.185401  </td><td style=\"text-align: right;\">        0.563336</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_2b17105f</td><td>TERMINATED</td><td>172.19.2.2:934 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.0305297</td><td style=\"text-align: right;\">  0.921893</td><td style=\"text-align: right;\">      0.0356395</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">  0.02031   </td><td style=\"text-align: right;\">        0.947156</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_3fc17697</td><td>TERMINATED</td><td>172.19.2.2:1028</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.0345609</td><td style=\"text-align: right;\">  0.920151</td><td style=\"text-align: right;\">      0.0366122</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">  0.0304584 </td><td style=\"text-align: right;\">        0.928156</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_5fbaa364</td><td>TERMINATED</td><td>172.19.2.2:1103</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.0540203</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0540257</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0540093 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_ba74eb45</td><td>TERMINATED</td><td>172.19.2.2:1204</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.0527208</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.053252 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0537831 </td><td style=\"text-align: right;\">        0.888779</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_0cd05ae1</td><td>TERMINATED</td><td>172.19.2.2:1270</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0261782</td><td style=\"text-align: right;\">  0.928571</td><td style=\"text-align: right;\">      0.0340638</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0104071 </td><td style=\"text-align: right;\">        0.967277</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_b6d7a778</td><td>TERMINATED</td><td>172.19.2.2:1376</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0305016</td><td style=\"text-align: right;\">  0.91957 </td><td style=\"text-align: right;\">      0.0394588</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0125873 </td><td style=\"text-align: right;\">        0.964366</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_12eb906a</td><td>TERMINATED</td><td>172.19.2.2:1474</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.0319682</td><td style=\"text-align: right;\">  0.914344</td><td style=\"text-align: right;\">      0.0377519</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">  0.0204008 </td><td style=\"text-align: right;\">        0.945589</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_6fb14e84</td><td>TERMINATED</td><td>172.19.2.2:1573</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0268659</td><td style=\"text-align: right;\">  0.924216</td><td style=\"text-align: right;\">      0.0348247</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0109482 </td><td style=\"text-align: right;\">        0.967085</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_5866b754</td><td>TERMINATED</td><td>172.19.2.2:1637</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0257922</td><td style=\"text-align: right;\">  0.92712 </td><td style=\"text-align: right;\">      0.033005 </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0113664 </td><td style=\"text-align: right;\">        0.967341</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_558a49aa</td><td>TERMINATED</td><td>172.19.2.2:1770</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0289212</td><td style=\"text-align: right;\">  0.927991</td><td style=\"text-align: right;\">      0.0370972</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0125692 </td><td style=\"text-align: right;\">        0.964046</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_6fd1942f</td><td>TERMINATED</td><td>172.19.2.2:1835</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0586483</td><td style=\"text-align: right;\">  0.889082</td><td style=\"text-align: right;\">      0.0646622</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0706761 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_1a9af771</td><td>TERMINATED</td><td>172.19.2.2:1930</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0271437</td><td style=\"text-align: right;\">  0.927991</td><td style=\"text-align: right;\">      0.0365611</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0083088 </td><td style=\"text-align: right;\">        0.970731</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_24a37924</td><td>TERMINATED</td><td>172.19.2.2:2038</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.027673 </td><td style=\"text-align: right;\">  0.924216</td><td style=\"text-align: right;\">      0.0372064</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0086063 </td><td style=\"text-align: right;\">        0.971787</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_d69d1057</td><td>TERMINATED</td><td>172.19.2.2:2127</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.0319305</td><td style=\"text-align: right;\">  0.91899 </td><td style=\"text-align: right;\">      0.0394349</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0169216 </td><td style=\"text-align: right;\">        0.953554</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_da6d62b1</td><td>TERMINATED</td><td>172.19.2.2:2232</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.0527615</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0545259</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0562904 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_9d1a2145</td><td>TERMINATED</td><td>172.19.2.2:2306</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.0481916</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.051457 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0547223 </td><td style=\"text-align: right;\">        0.889323</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_2000499c</td><td>TERMINATED</td><td>172.19.2.2:2391</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.182922 </td><td style=\"text-align: right;\">  0.694251</td><td style=\"text-align: right;\">      0.182979 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.183035  </td><td style=\"text-align: right;\">        0.636875</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_540286d0</td><td>TERMINATED</td><td>172.19.2.2:2465</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.183323 </td><td style=\"text-align: right;\">  0.577526</td><td style=\"text-align: right;\">      0.183712 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.1841    </td><td style=\"text-align: right;\">        0.58352 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_0f77054f</td><td>TERMINATED</td><td>172.19.2.2:2550</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0871905</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0943399</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.101489  </td><td style=\"text-align: right;\">        0.888811</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_75d8ffb3</td><td>TERMINATED</td><td>172.19.2.2:2624</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0932546</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.100568 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.107882  </td><td style=\"text-align: right;\">        0.88654 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_f767dbb7</td><td>TERMINATED</td><td>172.19.2.2:2726</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0316796</td><td style=\"text-align: right;\">  0.916667</td><td style=\"text-align: right;\">      0.0360066</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0230258 </td><td style=\"text-align: right;\">        0.940951</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_1c04c123</td><td>TERMINATED</td><td>172.19.2.2:2802</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0284404</td><td style=\"text-align: right;\">  0.924216</td><td style=\"text-align: right;\">      0.0379767</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0093679 </td><td style=\"text-align: right;\">        0.968492</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_cb80e71d</td><td>TERMINATED</td><td>172.19.2.2:2902</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0321448</td><td style=\"text-align: right;\">  0.917828</td><td style=\"text-align: right;\">      0.0367818</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0228709 </td><td style=\"text-align: right;\">        0.94175 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_d93dede2</td><td>TERMINATED</td><td>172.19.2.2:3000</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.0334569</td><td style=\"text-align: right;\">  0.915505</td><td style=\"text-align: right;\">      0.0408415</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0186877 </td><td style=\"text-align: right;\">        0.951315</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_6ef6937a</td><td>TERMINATED</td><td>172.19.2.2:3077</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.067763 </td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0761904</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0846179 </td><td style=\"text-align: right;\">        0.879726</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_53796627</td><td>TERMINATED</td><td>172.19.2.2:3164</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.0531532</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0534973</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0538413 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_d533639b</td><td>TERMINATED</td><td>172.19.2.2:3247</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0265209</td><td style=\"text-align: right;\">  0.925377</td><td style=\"text-align: right;\">      0.0339129</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0117369 </td><td style=\"text-align: right;\">        0.966157</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_47f6acad</td><td>TERMINATED</td><td>172.19.2.2:3320</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0280829</td><td style=\"text-align: right;\">  0.925958</td><td style=\"text-align: right;\">      0.0359493</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0123499 </td><td style=\"text-align: right;\">        0.964814</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_020303b2</td><td>TERMINATED</td><td>172.19.2.2:3444</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0276149</td><td style=\"text-align: right;\">  0.926249</td><td style=\"text-align: right;\">      0.0356498</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0115451 </td><td style=\"text-align: right;\">        0.967437</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_491d1eb9</td><td>TERMINATED</td><td>172.19.2.2:3518</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.0323038</td><td style=\"text-align: right;\">  0.91899 </td><td style=\"text-align: right;\">      0.0370228</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">  0.0228659 </td><td style=\"text-align: right;\">        0.940631</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_1569e222</td><td>TERMINATED</td><td>172.19.2.2:3618</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.0326885</td><td style=\"text-align: right;\">  0.915796</td><td style=\"text-align: right;\">      0.0389495</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0201663 </td><td style=\"text-align: right;\">        0.947316</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_1e48b813</td><td>TERMINATED</td><td>172.19.2.2:3713</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.0865701</td><td style=\"text-align: right;\">  0.889082</td><td style=\"text-align: right;\">      0.0987551</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.11094   </td><td style=\"text-align: right;\">        0.8756  </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_6a2e8e4f</td><td>TERMINATED</td><td>172.19.2.2:3793</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.0914459</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.102465 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.113484  </td><td style=\"text-align: right;\">        0.855831</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_67b0e7ad</td><td>TERMINATED</td><td>172.19.2.2:3873</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.0797924</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.091586 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.10338   </td><td style=\"text-align: right;\">        0.884812</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f0c5cd0b</td><td>TERMINATED</td><td>172.19.2.2:3953</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.179643 </td><td style=\"text-align: right;\">  0.748258</td><td style=\"text-align: right;\">      0.181048 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.176833  </td><td style=\"text-align: right;\">        0.710511</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_4afdd8fd</td><td>TERMINATED</td><td>172.19.2.2:4033</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.182321 </td><td style=\"text-align: right;\">  0.698606</td><td style=\"text-align: right;\">      0.182607 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.182893  </td><td style=\"text-align: right;\">        0.63067 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_72ad7df0</td><td>TERMINATED</td><td>172.19.2.2:4113</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.181231 </td><td style=\"text-align: right;\">  0.658537</td><td style=\"text-align: right;\">      0.181752 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.182273  </td><td style=\"text-align: right;\">        0.652357</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_950c8317</td><td>TERMINATED</td><td>172.19.2.2:4189</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.0542759</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0544102</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0540075 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_c794fc05</td><td>TERMINATED</td><td>172.19.2.2:4272</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.0542598</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0543486</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0540823 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_2c4e7606</td><td>TERMINATED</td><td>172.19.2.2:4361</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.053536 </td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.053545 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0535181 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_347cd09f</td><td>TERMINATED</td><td>172.19.2.2:4447</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.0323255</td><td style=\"text-align: right;\">  0.915215</td><td style=\"text-align: right;\">      0.0361837</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.024609  </td><td style=\"text-align: right;\">        0.936792</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_0fb43e5a</td><td>TERMINATED</td><td>172.19.2.2:4537</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.0541947</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0543113</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0539614 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_91b80175</td><td>TERMINATED</td><td>172.19.2.2:4622</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.0335769</td><td style=\"text-align: right;\">  0.923055</td><td style=\"text-align: right;\">      0.0360181</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">  0.0286944 </td><td style=\"text-align: right;\">        0.92806 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_45e18a66</td><td>TERMINATED</td><td>172.19.2.2:4712</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.0549212</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0573218</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">  0.0597225 </td><td style=\"text-align: right;\">        0.889259</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_4f1482ac</td><td>TERMINATED</td><td>172.19.2.2:4792</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0546542</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0563531</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">  0.0580521 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_d92b504a</td><td>TERMINATED</td><td>172.19.2.2:4882</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0847072</td><td style=\"text-align: right;\">  0.888792</td><td style=\"text-align: right;\">      0.0963449</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.107983  </td><td style=\"text-align: right;\">        0.877679</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_359e4372</td><td>TERMINATED</td><td>172.19.2.2:4962</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0264799</td><td style=\"text-align: right;\">  0.930023</td><td style=\"text-align: right;\">      0.0337181</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0120034 </td><td style=\"text-align: right;\">        0.966637</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_b4124ea3</td><td>TERMINATED</td><td>172.19.2.2:5038</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0276891</td><td style=\"text-align: right;\">  0.925377</td><td style=\"text-align: right;\">      0.0353351</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0123972 </td><td style=\"text-align: right;\">        0.963918</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_5e112015</td><td>TERMINATED</td><td>172.19.2.2:5159</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0272193</td><td style=\"text-align: right;\">  0.9277  </td><td style=\"text-align: right;\">      0.0354948</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0106683 </td><td style=\"text-align: right;\">        0.968012</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_d05fd1ef</td><td>TERMINATED</td><td>172.19.2.2:5236</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0261017</td><td style=\"text-align: right;\">  0.9277  </td><td style=\"text-align: right;\">      0.0334414</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0114223 </td><td style=\"text-align: right;\">        0.966989</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_ca793110</td><td>TERMINATED</td><td>172.19.2.2:5355</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.0283761</td><td style=\"text-align: right;\">  0.92712 </td><td style=\"text-align: right;\">      0.0369938</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0111408 </td><td style=\"text-align: right;\">        0.967117</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_b0a2e06c</td><td>TERMINATED</td><td>172.19.2.2:5433</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0281772</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0363679</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0117959 </td><td style=\"text-align: right;\">        0.965229</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_69b26dcc</td><td>TERMINATED</td><td>172.19.2.2:5552</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0281241</td><td style=\"text-align: right;\">  0.926249</td><td style=\"text-align: right;\">      0.0365198</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0113327 </td><td style=\"text-align: right;\">        0.967852</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_5d299b78</td><td>TERMINATED</td><td>172.19.2.2:5630</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0262172</td><td style=\"text-align: right;\">  0.925958</td><td style=\"text-align: right;\">      0.0341013</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0104489 </td><td style=\"text-align: right;\">        0.967117</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_54c14e43</td><td>TERMINATED</td><td>172.19.2.2:5749</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0544888</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0545609</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0543445 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_22f6d600</td><td>TERMINATED</td><td>172.19.2.2:5827</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0540581</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0541724</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0542868 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_043c4e06</td><td>TERMINATED</td><td>172.19.2.2:5908</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0298011</td><td style=\"text-align: right;\">  0.922184</td><td style=\"text-align: right;\">      0.0387847</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0118338 </td><td style=\"text-align: right;\">        0.965613</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_5053289e</td><td>TERMINATED</td><td>172.19.2.2:5986</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0287294</td><td style=\"text-align: right;\">  0.924506</td><td style=\"text-align: right;\">      0.0370009</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0121862 </td><td style=\"text-align: right;\">        0.964877</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_d632c1c6</td><td>TERMINATED</td><td>172.19.2.2:6105</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0270765</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0353629</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0105037 </td><td style=\"text-align: right;\">        0.96878 </td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_9f75eb17</td><td>TERMINATED</td><td>172.19.2.2:6183</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0546763</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0568888</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0591013 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_0e045bb4</td><td>TERMINATED</td><td>172.19.2.2:6271</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.0558471</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0598302</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0638133 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_127de4e9</td><td>TERMINATED</td><td>172.19.2.2:6359</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.0302625</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0389561</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0128753 </td><td style=\"text-align: right;\">        0.964014</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_370c4e9e</td><td>TERMINATED</td><td>172.19.2.2:6443</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0518172</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0542495</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0566817 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_5f9cb34d</td><td>TERMINATED</td><td>172.19.2.2:6532</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0540313</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0559872</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0579431 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_a19f515b</td><td>TERMINATED</td><td>172.19.2.2:6620</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.176796 </td><td style=\"text-align: right;\">  0.630662</td><td style=\"text-align: right;\">      0.176868 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.176941  </td><td style=\"text-align: right;\">        0.611477</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_a785b2ad</td><td>TERMINATED</td><td>172.19.2.2:6699</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.186563 </td><td style=\"text-align: right;\">  0.625726</td><td style=\"text-align: right;\">      0.187153 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.187743  </td><td style=\"text-align: right;\">        0.560873</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_b678c162</td><td>TERMINATED</td><td>172.19.2.2:6776</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.0264818</td><td style=\"text-align: right;\">  0.927991</td><td style=\"text-align: right;\">      0.0344368</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0105718 </td><td style=\"text-align: right;\">        0.968876</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_c01ccb79</td><td>TERMINATED</td><td>172.19.2.2:6858</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.0274731</td><td style=\"text-align: right;\">  0.926829</td><td style=\"text-align: right;\">      0.035723 </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0109731 </td><td style=\"text-align: right;\">        0.967309</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_621475ca</td><td>TERMINATED</td><td>172.19.2.2:6974</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.0278046</td><td style=\"text-align: right;\">  0.927991</td><td style=\"text-align: right;\">      0.0366089</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0101961 </td><td style=\"text-align: right;\">        0.96974 </td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_aee678ac</td><td>TERMINATED</td><td>172.19.2.2:7055</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.0279878</td><td style=\"text-align: right;\">  0.925087</td><td style=\"text-align: right;\">      0.0348873</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">  0.0141887 </td><td style=\"text-align: right;\">        0.960655</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_9e2a29cd</td><td>TERMINATED</td><td>172.19.2.2:7165</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.0259717</td><td style=\"text-align: right;\">  0.92712 </td><td style=\"text-align: right;\">      0.0331025</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">  0.0117101 </td><td style=\"text-align: right;\">        0.966157</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_b676dab8</td><td>TERMINATED</td><td>172.19.2.2:7240</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.141498 </td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.152486 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.163474  </td><td style=\"text-align: right;\">        0.814119</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e7883aac</td><td>TERMINATED</td><td>172.19.2.2:7330</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.029291 </td><td style=\"text-align: right;\">  0.921603</td><td style=\"text-align: right;\">      0.0380291</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">  0.0118149 </td><td style=\"text-align: right;\">        0.965453</td><td style=\"text-align: right;\">                     9</td></tr>\n",
       "<tr><td>train_fn_1e089cde</td><td>TERMINATED</td><td>172.19.2.2:7418</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.0273212</td><td style=\"text-align: right;\">  0.924797</td><td style=\"text-align: right;\">      0.0357923</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.010379  </td><td style=\"text-align: right;\">        0.9683  </td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_204986f6</td><td>TERMINATED</td><td>172.19.2.2:7522</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.0269711</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0348474</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0112185 </td><td style=\"text-align: right;\">        0.966221</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_6c1dc7d9</td><td>TERMINATED</td><td>172.19.2.2:7615</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.0296371</td><td style=\"text-align: right;\">  0.918699</td><td style=\"text-align: right;\">      0.0402345</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">  0.0084423 </td><td style=\"text-align: right;\">        0.973002</td><td style=\"text-align: right;\">                    11</td></tr>\n",
       "<tr><td>train_fn_f8d507a2</td><td>TERMINATED</td><td>172.19.2.2:7718</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.0284469</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0363861</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0125684 </td><td style=\"text-align: right;\">        0.96459 </td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_fc5bfd0b</td><td>TERMINATED</td><td>172.19.2.2:7817</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0311806</td><td style=\"text-align: right;\">  0.915215</td><td style=\"text-align: right;\">      0.0366594</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0202231 </td><td style=\"text-align: right;\">        0.946996</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_c0ca0c49</td><td>TERMINATED</td><td>172.19.2.2:7915</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.028639 </td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0375186</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">  0.0108799 </td><td style=\"text-align: right;\">        0.967564</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_86a52d73</td><td>TERMINATED</td><td>172.19.2.2:7991</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0332111</td><td style=\"text-align: right;\">  0.918118</td><td style=\"text-align: right;\">      0.039939 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0197554 </td><td style=\"text-align: right;\">        0.948756</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_adb27a30</td><td>TERMINATED</td><td>172.19.2.2:8097</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0255258</td><td style=\"text-align: right;\">  0.92741 </td><td style=\"text-align: right;\">      0.0357987</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">  0.00498007</td><td style=\"text-align: right;\">        0.980104</td><td style=\"text-align: right;\">                    15</td></tr>\n",
       "<tr><td>train_fn_d6f5edd8</td><td>TERMINATED</td><td>172.19.2.2:8184</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.0316395</td><td style=\"text-align: right;\">  0.91957 </td><td style=\"text-align: right;\">      0.04218  </td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">  0.0105584 </td><td style=\"text-align: right;\">        0.968204</td><td style=\"text-align: right;\">                    11</td></tr>\n",
       "<tr><td>train_fn_062d6a63</td><td>TERMINATED</td><td>172.19.2.2:8315</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.0275304</td><td style=\"text-align: right;\">  0.925958</td><td style=\"text-align: right;\">      0.0367888</td><td style=\"text-align: right;\">                  12</td><td style=\"text-align: right;\">  0.00901365</td><td style=\"text-align: right;\">        0.970571</td><td style=\"text-align: right;\">                    12</td></tr>\n",
       "<tr><td>train_fn_d5788737</td><td>TERMINATED</td><td>172.19.2.2:8394</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0545398</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0546881</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0542431 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_099e89a9</td><td>TERMINATED</td><td>172.19.2.2:8482</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0252554</td><td style=\"text-align: right;\">  0.92741 </td><td style=\"text-align: right;\">      0.034118 </td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">  0.0075304 </td><td style=\"text-align: right;\">        0.97441 </td><td style=\"text-align: right;\">                    11</td></tr>\n",
       "<tr><td>train_fn_936869cf</td><td>TERMINATED</td><td>172.19.2.2:8594</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.0261151</td><td style=\"text-align: right;\">  0.924797</td><td style=\"text-align: right;\">      0.0355395</td><td style=\"text-align: right;\">                  12</td><td style=\"text-align: right;\">  0.00726639</td><td style=\"text-align: right;\">        0.974666</td><td style=\"text-align: right;\">                    12</td></tr>\n",
       "<tr><td>train_fn_bfb1d397</td><td>TERMINATED</td><td>172.19.2.2:8685</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.0320145</td><td style=\"text-align: right;\">  0.916667</td><td style=\"text-align: right;\">      0.038085 </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0198734 </td><td style=\"text-align: right;\">        0.947892</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_39aec43e</td><td>TERMINATED</td><td>172.19.2.2:8791</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0253335</td><td style=\"text-align: right;\">  0.929152</td><td style=\"text-align: right;\">      0.0351829</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">  0.00563469</td><td style=\"text-align: right;\">        0.977705</td><td style=\"text-align: right;\">                    15</td></tr>\n",
       "<tr><td>train_fn_4b42666c</td><td>TERMINATED</td><td>172.19.2.2:8875</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0319205</td><td style=\"text-align: right;\">  0.918409</td><td style=\"text-align: right;\">      0.0391017</td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">  0.0175581 </td><td style=\"text-align: right;\">        0.952498</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_09257540</td><td>TERMINATED</td><td>172.19.2.2:8979</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0255441</td><td style=\"text-align: right;\">  0.928571</td><td style=\"text-align: right;\">      0.0358076</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">  0.00501695</td><td style=\"text-align: right;\">        0.978632</td><td style=\"text-align: right;\">                    15</td></tr>\n",
       "<tr><td>train_fn_4a28d0ec</td><td>TERMINATED</td><td>172.19.2.2:9086</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.0543715</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0543978</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.0543191 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_78bb8549</td><td>TERMINATED</td><td>172.19.2.2:9174</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.0539551</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.054025 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">  0.054095  </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_297153bc</td><td>TERMINATED</td><td>172.19.2.2:9262</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.0273629</td><td style=\"text-align: right;\">  0.923345</td><td style=\"text-align: right;\">      0.0377938</td><td style=\"text-align: right;\">                  12</td><td style=\"text-align: right;\">  0.00650095</td><td style=\"text-align: right;\">        0.976041</td><td style=\"text-align: right;\">                    12</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 18:12:44,092\tINFO worker.py:1753 -- Started a local Ray instance.\n",
      "2024-08-29 18:12:45,260\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-08-29 18:12:45,267\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "[I 2024-08-29 18:12:45,327] A new study created in memory with name: optuna\n",
      "\u001b[36m(train_fn pid=340)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=340)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=376)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=376)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  early_stopping_epoch</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_020303b2</td><td style=\"text-align: right;\">  0.926249</td><td style=\"text-align: right;\">      0.0356498</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0276149</td><td style=\"text-align: right;\">        0.967437</td><td style=\"text-align: right;\">  0.0115451 </td></tr>\n",
       "<tr><td>train_fn_043c4e06</td><td style=\"text-align: right;\">  0.922184</td><td style=\"text-align: right;\">      0.0387847</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0298011</td><td style=\"text-align: right;\">        0.965613</td><td style=\"text-align: right;\">  0.0118338 </td></tr>\n",
       "<tr><td>train_fn_062d6a63</td><td style=\"text-align: right;\">  0.925958</td><td style=\"text-align: right;\">      0.0367888</td><td style=\"text-align: right;\">                    12</td><td style=\"text-align: right;\">0.0275304</td><td style=\"text-align: right;\">        0.970571</td><td style=\"text-align: right;\">  0.00901365</td></tr>\n",
       "<tr><td>train_fn_09257540</td><td style=\"text-align: right;\">  0.928571</td><td style=\"text-align: right;\">      0.0358076</td><td style=\"text-align: right;\">                    15</td><td style=\"text-align: right;\">0.0255441</td><td style=\"text-align: right;\">        0.978632</td><td style=\"text-align: right;\">  0.00501695</td></tr>\n",
       "<tr><td>train_fn_099e89a9</td><td style=\"text-align: right;\">  0.92741 </td><td style=\"text-align: right;\">      0.034118 </td><td style=\"text-align: right;\">                    11</td><td style=\"text-align: right;\">0.0252554</td><td style=\"text-align: right;\">        0.97441 </td><td style=\"text-align: right;\">  0.0075304 </td></tr>\n",
       "<tr><td>train_fn_0cd05ae1</td><td style=\"text-align: right;\">  0.928571</td><td style=\"text-align: right;\">      0.0340638</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0261782</td><td style=\"text-align: right;\">        0.967277</td><td style=\"text-align: right;\">  0.0104071 </td></tr>\n",
       "<tr><td>train_fn_0e045bb4</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0598302</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0558471</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0638133 </td></tr>\n",
       "<tr><td>train_fn_0f77054f</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0943399</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0871905</td><td style=\"text-align: right;\">        0.888811</td><td style=\"text-align: right;\">  0.101489  </td></tr>\n",
       "<tr><td>train_fn_0fb43e5a</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0543113</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0541947</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0539614 </td></tr>\n",
       "<tr><td>train_fn_127de4e9</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0389561</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0302625</td><td style=\"text-align: right;\">        0.964014</td><td style=\"text-align: right;\">  0.0128753 </td></tr>\n",
       "<tr><td>train_fn_12eb906a</td><td style=\"text-align: right;\">  0.914344</td><td style=\"text-align: right;\">      0.0377519</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.0319682</td><td style=\"text-align: right;\">        0.945589</td><td style=\"text-align: right;\">  0.0204008 </td></tr>\n",
       "<tr><td>train_fn_1569e222</td><td style=\"text-align: right;\">  0.915796</td><td style=\"text-align: right;\">      0.0389495</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0326885</td><td style=\"text-align: right;\">        0.947316</td><td style=\"text-align: right;\">  0.0201663 </td></tr>\n",
       "<tr><td>train_fn_1a9af771</td><td style=\"text-align: right;\">  0.927991</td><td style=\"text-align: right;\">      0.0365611</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0271437</td><td style=\"text-align: right;\">        0.970731</td><td style=\"text-align: right;\">  0.0083088 </td></tr>\n",
       "<tr><td>train_fn_1c04c123</td><td style=\"text-align: right;\">  0.924216</td><td style=\"text-align: right;\">      0.0379767</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0284404</td><td style=\"text-align: right;\">        0.968492</td><td style=\"text-align: right;\">  0.0093679 </td></tr>\n",
       "<tr><td>train_fn_1e089cde</td><td style=\"text-align: right;\">  0.924797</td><td style=\"text-align: right;\">      0.0357923</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0273212</td><td style=\"text-align: right;\">        0.9683  </td><td style=\"text-align: right;\">  0.010379  </td></tr>\n",
       "<tr><td>train_fn_1e48b813</td><td style=\"text-align: right;\">  0.889082</td><td style=\"text-align: right;\">      0.0987551</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0865701</td><td style=\"text-align: right;\">        0.8756  </td><td style=\"text-align: right;\">  0.11094   </td></tr>\n",
       "<tr><td>train_fn_1ff8a192</td><td style=\"text-align: right;\">  0.889082</td><td style=\"text-align: right;\">      0.105833 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.095339 </td><td style=\"text-align: right;\">        0.883181</td><td style=\"text-align: right;\">  0.116328  </td></tr>\n",
       "<tr><td>train_fn_2000499c</td><td style=\"text-align: right;\">  0.694251</td><td style=\"text-align: right;\">      0.182979 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.182922 </td><td style=\"text-align: right;\">        0.636875</td><td style=\"text-align: right;\">  0.183035  </td></tr>\n",
       "<tr><td>train_fn_204986f6</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0348474</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0269711</td><td style=\"text-align: right;\">        0.966221</td><td style=\"text-align: right;\">  0.0112185 </td></tr>\n",
       "<tr><td>train_fn_22f6d600</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0541724</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0540581</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0542868 </td></tr>\n",
       "<tr><td>train_fn_24a37924</td><td style=\"text-align: right;\">  0.924216</td><td style=\"text-align: right;\">      0.0372064</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.027673 </td><td style=\"text-align: right;\">        0.971787</td><td style=\"text-align: right;\">  0.0086063 </td></tr>\n",
       "<tr><td>train_fn_297153bc</td><td style=\"text-align: right;\">  0.923345</td><td style=\"text-align: right;\">      0.0377938</td><td style=\"text-align: right;\">                    12</td><td style=\"text-align: right;\">0.0273629</td><td style=\"text-align: right;\">        0.976041</td><td style=\"text-align: right;\">  0.00650095</td></tr>\n",
       "<tr><td>train_fn_2b17105f</td><td style=\"text-align: right;\">  0.921893</td><td style=\"text-align: right;\">      0.0356395</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.0305297</td><td style=\"text-align: right;\">        0.947156</td><td style=\"text-align: right;\">  0.02031   </td></tr>\n",
       "<tr><td>train_fn_2c4e7606</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.053545 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.053536 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0535181 </td></tr>\n",
       "<tr><td>train_fn_347cd09f</td><td style=\"text-align: right;\">  0.915215</td><td style=\"text-align: right;\">      0.0361837</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0323255</td><td style=\"text-align: right;\">        0.936792</td><td style=\"text-align: right;\">  0.024609  </td></tr>\n",
       "<tr><td>train_fn_359e4372</td><td style=\"text-align: right;\">  0.930023</td><td style=\"text-align: right;\">      0.0337181</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0264799</td><td style=\"text-align: right;\">        0.966637</td><td style=\"text-align: right;\">  0.0120034 </td></tr>\n",
       "<tr><td>train_fn_370c4e9e</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0542495</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0518172</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0566817 </td></tr>\n",
       "<tr><td>train_fn_393cddc8</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0542331</td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.054192 </td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0541099 </td></tr>\n",
       "<tr><td>train_fn_39aec43e</td><td style=\"text-align: right;\">  0.929152</td><td style=\"text-align: right;\">      0.0351829</td><td style=\"text-align: right;\">                    15</td><td style=\"text-align: right;\">0.0253335</td><td style=\"text-align: right;\">        0.977705</td><td style=\"text-align: right;\">  0.00563469</td></tr>\n",
       "<tr><td>train_fn_3fc17697</td><td style=\"text-align: right;\">  0.920151</td><td style=\"text-align: right;\">      0.0366122</td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.0345609</td><td style=\"text-align: right;\">        0.928156</td><td style=\"text-align: right;\">  0.0304584 </td></tr>\n",
       "<tr><td>train_fn_45e18a66</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0573218</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.0549212</td><td style=\"text-align: right;\">        0.889259</td><td style=\"text-align: right;\">  0.0597225 </td></tr>\n",
       "<tr><td>train_fn_47f6acad</td><td style=\"text-align: right;\">  0.925958</td><td style=\"text-align: right;\">      0.0359493</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0280829</td><td style=\"text-align: right;\">        0.964814</td><td style=\"text-align: right;\">  0.0123499 </td></tr>\n",
       "<tr><td>train_fn_491d1eb9</td><td style=\"text-align: right;\">  0.91899 </td><td style=\"text-align: right;\">      0.0370228</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.0323038</td><td style=\"text-align: right;\">        0.940631</td><td style=\"text-align: right;\">  0.0228659 </td></tr>\n",
       "<tr><td>train_fn_4a28d0ec</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0543978</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0543715</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0543191 </td></tr>\n",
       "<tr><td>train_fn_4afdd8fd</td><td style=\"text-align: right;\">  0.698606</td><td style=\"text-align: right;\">      0.182607 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.182321 </td><td style=\"text-align: right;\">        0.63067 </td><td style=\"text-align: right;\">  0.182893  </td></tr>\n",
       "<tr><td>train_fn_4b42666c</td><td style=\"text-align: right;\">  0.918409</td><td style=\"text-align: right;\">      0.0391017</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0319205</td><td style=\"text-align: right;\">        0.952498</td><td style=\"text-align: right;\">  0.0175581 </td></tr>\n",
       "<tr><td>train_fn_4f1482ac</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0563531</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.0546542</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0580521 </td></tr>\n",
       "<tr><td>train_fn_5053289e</td><td style=\"text-align: right;\">  0.924506</td><td style=\"text-align: right;\">      0.0370009</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0287294</td><td style=\"text-align: right;\">        0.964877</td><td style=\"text-align: right;\">  0.0121862 </td></tr>\n",
       "<tr><td>train_fn_53796627</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0534973</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0531532</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0538413 </td></tr>\n",
       "<tr><td>train_fn_540286d0</td><td style=\"text-align: right;\">  0.577526</td><td style=\"text-align: right;\">      0.183712 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.183323 </td><td style=\"text-align: right;\">        0.58352 </td><td style=\"text-align: right;\">  0.1841    </td></tr>\n",
       "<tr><td>train_fn_54c14e43</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0545609</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0544888</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0543445 </td></tr>\n",
       "<tr><td>train_fn_558a49aa</td><td style=\"text-align: right;\">  0.927991</td><td style=\"text-align: right;\">      0.0370972</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0289212</td><td style=\"text-align: right;\">        0.964046</td><td style=\"text-align: right;\">  0.0125692 </td></tr>\n",
       "<tr><td>train_fn_5866b754</td><td style=\"text-align: right;\">  0.92712 </td><td style=\"text-align: right;\">      0.033005 </td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0257922</td><td style=\"text-align: right;\">        0.967341</td><td style=\"text-align: right;\">  0.0113664 </td></tr>\n",
       "<tr><td>train_fn_5d299b78</td><td style=\"text-align: right;\">  0.925958</td><td style=\"text-align: right;\">      0.0341013</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0262172</td><td style=\"text-align: right;\">        0.967117</td><td style=\"text-align: right;\">  0.0104489 </td></tr>\n",
       "<tr><td>train_fn_5e112015</td><td style=\"text-align: right;\">  0.9277  </td><td style=\"text-align: right;\">      0.0354948</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0272193</td><td style=\"text-align: right;\">        0.968012</td><td style=\"text-align: right;\">  0.0106683 </td></tr>\n",
       "<tr><td>train_fn_5f9cb34d</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0559872</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0540313</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0579431 </td></tr>\n",
       "<tr><td>train_fn_5fbaa364</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0540257</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0540203</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0540093 </td></tr>\n",
       "<tr><td>train_fn_621475ca</td><td style=\"text-align: right;\">  0.927991</td><td style=\"text-align: right;\">      0.0366089</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0278046</td><td style=\"text-align: right;\">        0.96974 </td><td style=\"text-align: right;\">  0.0101961 </td></tr>\n",
       "<tr><td>train_fn_67b0e7ad</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.091586 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0797924</td><td style=\"text-align: right;\">        0.884812</td><td style=\"text-align: right;\">  0.10338   </td></tr>\n",
       "<tr><td>train_fn_69b26dcc</td><td style=\"text-align: right;\">  0.926249</td><td style=\"text-align: right;\">      0.0365198</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0281241</td><td style=\"text-align: right;\">        0.967852</td><td style=\"text-align: right;\">  0.0113327 </td></tr>\n",
       "<tr><td>train_fn_6a2e8e4f</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.102465 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0914459</td><td style=\"text-align: right;\">        0.855831</td><td style=\"text-align: right;\">  0.113484  </td></tr>\n",
       "<tr><td>train_fn_6c1dc7d9</td><td style=\"text-align: right;\">  0.918699</td><td style=\"text-align: right;\">      0.0402345</td><td style=\"text-align: right;\">                    11</td><td style=\"text-align: right;\">0.0296371</td><td style=\"text-align: right;\">        0.973002</td><td style=\"text-align: right;\">  0.0084423 </td></tr>\n",
       "<tr><td>train_fn_6ef6937a</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0761904</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.067763 </td><td style=\"text-align: right;\">        0.879726</td><td style=\"text-align: right;\">  0.0846179 </td></tr>\n",
       "<tr><td>train_fn_6fb14e84</td><td style=\"text-align: right;\">  0.924216</td><td style=\"text-align: right;\">      0.0348247</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0268659</td><td style=\"text-align: right;\">        0.967085</td><td style=\"text-align: right;\">  0.0109482 </td></tr>\n",
       "<tr><td>train_fn_6fd1942f</td><td style=\"text-align: right;\">  0.889082</td><td style=\"text-align: right;\">      0.0646622</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0586483</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0706761 </td></tr>\n",
       "<tr><td>train_fn_72ad7df0</td><td style=\"text-align: right;\">  0.658537</td><td style=\"text-align: right;\">      0.181752 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.181231 </td><td style=\"text-align: right;\">        0.652357</td><td style=\"text-align: right;\">  0.182273  </td></tr>\n",
       "<tr><td>train_fn_74e1235b</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0549307</td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.0546616</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0541233 </td></tr>\n",
       "<tr><td>train_fn_75d8ffb3</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.100568 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0932546</td><td style=\"text-align: right;\">        0.88654 </td><td style=\"text-align: right;\">  0.107882  </td></tr>\n",
       "<tr><td>train_fn_78bb8549</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.054025 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0539551</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.054095  </td></tr>\n",
       "<tr><td>train_fn_7e0568dc</td><td style=\"text-align: right;\">  0.895761</td><td style=\"text-align: right;\">      0.0477495</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0450784</td><td style=\"text-align: right;\">        0.890698</td><td style=\"text-align: right;\">  0.0504207 </td></tr>\n",
       "<tr><td>train_fn_86a52d73</td><td style=\"text-align: right;\">  0.918118</td><td style=\"text-align: right;\">      0.039939 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0332111</td><td style=\"text-align: right;\">        0.948756</td><td style=\"text-align: right;\">  0.0197554 </td></tr>\n",
       "<tr><td>train_fn_90c8d9ba</td><td style=\"text-align: right;\">  0.926829</td><td style=\"text-align: right;\">      0.0360044</td><td style=\"text-align: right;\">                    12</td><td style=\"text-align: right;\">0.0268234</td><td style=\"text-align: right;\">        0.973514</td><td style=\"text-align: right;\">  0.00846155</td></tr>\n",
       "<tr><td>train_fn_91b80175</td><td style=\"text-align: right;\">  0.923055</td><td style=\"text-align: right;\">      0.0360181</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.0335769</td><td style=\"text-align: right;\">        0.92806 </td><td style=\"text-align: right;\">  0.0286944 </td></tr>\n",
       "<tr><td>train_fn_936869cf</td><td style=\"text-align: right;\">  0.924797</td><td style=\"text-align: right;\">      0.0355395</td><td style=\"text-align: right;\">                    12</td><td style=\"text-align: right;\">0.0261151</td><td style=\"text-align: right;\">        0.974666</td><td style=\"text-align: right;\">  0.00726639</td></tr>\n",
       "<tr><td>train_fn_950c8317</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0544102</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0542759</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0540075 </td></tr>\n",
       "<tr><td>train_fn_9d1a2145</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.051457 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0481916</td><td style=\"text-align: right;\">        0.889323</td><td style=\"text-align: right;\">  0.0547223 </td></tr>\n",
       "<tr><td>train_fn_9e2a29cd</td><td style=\"text-align: right;\">  0.92712 </td><td style=\"text-align: right;\">      0.0331025</td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.0259717</td><td style=\"text-align: right;\">        0.966157</td><td style=\"text-align: right;\">  0.0117101 </td></tr>\n",
       "<tr><td>train_fn_9f75eb17</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0568888</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0546763</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0591013 </td></tr>\n",
       "<tr><td>train_fn_a19f515b</td><td style=\"text-align: right;\">  0.630662</td><td style=\"text-align: right;\">      0.176868 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.176796 </td><td style=\"text-align: right;\">        0.611477</td><td style=\"text-align: right;\">  0.176941  </td></tr>\n",
       "<tr><td>train_fn_a785b2ad</td><td style=\"text-align: right;\">  0.625726</td><td style=\"text-align: right;\">      0.187153 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.186563 </td><td style=\"text-align: right;\">        0.560873</td><td style=\"text-align: right;\">  0.187743  </td></tr>\n",
       "<tr><td>train_fn_adb27a30</td><td style=\"text-align: right;\">  0.92741 </td><td style=\"text-align: right;\">      0.0357987</td><td style=\"text-align: right;\">                    15</td><td style=\"text-align: right;\">0.0255258</td><td style=\"text-align: right;\">        0.980104</td><td style=\"text-align: right;\">  0.00498007</td></tr>\n",
       "<tr><td>train_fn_aee678ac</td><td style=\"text-align: right;\">  0.925087</td><td style=\"text-align: right;\">      0.0348873</td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.0279878</td><td style=\"text-align: right;\">        0.960655</td><td style=\"text-align: right;\">  0.0141887 </td></tr>\n",
       "<tr><td>train_fn_b0a2e06c</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0363679</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0281772</td><td style=\"text-align: right;\">        0.965229</td><td style=\"text-align: right;\">  0.0117959 </td></tr>\n",
       "<tr><td>train_fn_b4124ea3</td><td style=\"text-align: right;\">  0.925377</td><td style=\"text-align: right;\">      0.0353351</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0276891</td><td style=\"text-align: right;\">        0.963918</td><td style=\"text-align: right;\">  0.0123972 </td></tr>\n",
       "<tr><td>train_fn_b676dab8</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.152486 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.141498 </td><td style=\"text-align: right;\">        0.814119</td><td style=\"text-align: right;\">  0.163474  </td></tr>\n",
       "<tr><td>train_fn_b678c162</td><td style=\"text-align: right;\">  0.927991</td><td style=\"text-align: right;\">      0.0344368</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0264818</td><td style=\"text-align: right;\">        0.968876</td><td style=\"text-align: right;\">  0.0105718 </td></tr>\n",
       "<tr><td>train_fn_b6d7a778</td><td style=\"text-align: right;\">  0.91957 </td><td style=\"text-align: right;\">      0.0394588</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0305016</td><td style=\"text-align: right;\">        0.964366</td><td style=\"text-align: right;\">  0.0125873 </td></tr>\n",
       "<tr><td>train_fn_ba74eb45</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.053252 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0527208</td><td style=\"text-align: right;\">        0.888779</td><td style=\"text-align: right;\">  0.0537831 </td></tr>\n",
       "<tr><td>train_fn_bfb1d397</td><td style=\"text-align: right;\">  0.916667</td><td style=\"text-align: right;\">      0.038085 </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0320145</td><td style=\"text-align: right;\">        0.947892</td><td style=\"text-align: right;\">  0.0198734 </td></tr>\n",
       "<tr><td>train_fn_c01ccb79</td><td style=\"text-align: right;\">  0.926829</td><td style=\"text-align: right;\">      0.035723 </td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0274731</td><td style=\"text-align: right;\">        0.967309</td><td style=\"text-align: right;\">  0.0109731 </td></tr>\n",
       "<tr><td>train_fn_c0ca0c49</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0375186</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.028639 </td><td style=\"text-align: right;\">        0.967564</td><td style=\"text-align: right;\">  0.0108799 </td></tr>\n",
       "<tr><td>train_fn_c794fc05</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0543486</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0542598</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0540823 </td></tr>\n",
       "<tr><td>train_fn_ca793110</td><td style=\"text-align: right;\">  0.92712 </td><td style=\"text-align: right;\">      0.0369938</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0283761</td><td style=\"text-align: right;\">        0.967117</td><td style=\"text-align: right;\">  0.0111408 </td></tr>\n",
       "<tr><td>train_fn_cb80e71d</td><td style=\"text-align: right;\">  0.917828</td><td style=\"text-align: right;\">      0.0367818</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0321448</td><td style=\"text-align: right;\">        0.94175 </td><td style=\"text-align: right;\">  0.0228709 </td></tr>\n",
       "<tr><td>train_fn_d05fd1ef</td><td style=\"text-align: right;\">  0.9277  </td><td style=\"text-align: right;\">      0.0334414</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0261017</td><td style=\"text-align: right;\">        0.966989</td><td style=\"text-align: right;\">  0.0114223 </td></tr>\n",
       "<tr><td>train_fn_d533639b</td><td style=\"text-align: right;\">  0.925377</td><td style=\"text-align: right;\">      0.0339129</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0265209</td><td style=\"text-align: right;\">        0.966157</td><td style=\"text-align: right;\">  0.0117369 </td></tr>\n",
       "<tr><td>train_fn_d5788737</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0546881</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0545398</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0542431 </td></tr>\n",
       "<tr><td>train_fn_d632c1c6</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0353629</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0270765</td><td style=\"text-align: right;\">        0.96878 </td><td style=\"text-align: right;\">  0.0105037 </td></tr>\n",
       "<tr><td>train_fn_d69d1057</td><td style=\"text-align: right;\">  0.91899 </td><td style=\"text-align: right;\">      0.0394349</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0319305</td><td style=\"text-align: right;\">        0.953554</td><td style=\"text-align: right;\">  0.0169216 </td></tr>\n",
       "<tr><td>train_fn_d6f5edd8</td><td style=\"text-align: right;\">  0.91957 </td><td style=\"text-align: right;\">      0.04218  </td><td style=\"text-align: right;\">                    11</td><td style=\"text-align: right;\">0.0316395</td><td style=\"text-align: right;\">        0.968204</td><td style=\"text-align: right;\">  0.0105584 </td></tr>\n",
       "<tr><td>train_fn_d8aa3878</td><td style=\"text-align: right;\">  0.917828</td><td style=\"text-align: right;\">      0.0412064</td><td style=\"text-align: right;\">                    13</td><td style=\"text-align: right;\">0.0333584</td><td style=\"text-align: right;\">        0.954641</td><td style=\"text-align: right;\">  0.0176624 </td></tr>\n",
       "<tr><td>train_fn_d92b504a</td><td style=\"text-align: right;\">  0.888792</td><td style=\"text-align: right;\">      0.0963449</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0847072</td><td style=\"text-align: right;\">        0.877679</td><td style=\"text-align: right;\">  0.107983  </td></tr>\n",
       "<tr><td>train_fn_d93dede2</td><td style=\"text-align: right;\">  0.915505</td><td style=\"text-align: right;\">      0.0408415</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0334569</td><td style=\"text-align: right;\">        0.951315</td><td style=\"text-align: right;\">  0.0186877 </td></tr>\n",
       "<tr><td>train_fn_da6d62b1</td><td style=\"text-align: right;\">  0.889373</td><td style=\"text-align: right;\">      0.0545259</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.0527615</td><td style=\"text-align: right;\">        0.889291</td><td style=\"text-align: right;\">  0.0562904 </td></tr>\n",
       "<tr><td>train_fn_e7883aac</td><td style=\"text-align: right;\">  0.921603</td><td style=\"text-align: right;\">      0.0380291</td><td style=\"text-align: right;\">                     9</td><td style=\"text-align: right;\">0.029291 </td><td style=\"text-align: right;\">        0.965453</td><td style=\"text-align: right;\">  0.0118149 </td></tr>\n",
       "<tr><td>train_fn_f0c5cd0b</td><td style=\"text-align: right;\">  0.748258</td><td style=\"text-align: right;\">      0.181048 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.179643 </td><td style=\"text-align: right;\">        0.710511</td><td style=\"text-align: right;\">  0.176833  </td></tr>\n",
       "<tr><td>train_fn_f64cae7c</td><td style=\"text-align: right;\">  0.676249</td><td style=\"text-align: right;\">      0.183867 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.182334 </td><td style=\"text-align: right;\">        0.563336</td><td style=\"text-align: right;\">  0.185401  </td></tr>\n",
       "<tr><td>train_fn_f767dbb7</td><td style=\"text-align: right;\">  0.916667</td><td style=\"text-align: right;\">      0.0360066</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0316796</td><td style=\"text-align: right;\">        0.940951</td><td style=\"text-align: right;\">  0.0230258 </td></tr>\n",
       "<tr><td>train_fn_f8d507a2</td><td style=\"text-align: right;\">  0.923926</td><td style=\"text-align: right;\">      0.0363861</td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.0284469</td><td style=\"text-align: right;\">        0.96459 </td><td style=\"text-align: right;\">  0.0125684 </td></tr>\n",
       "<tr><td>train_fn_fc5bfd0b</td><td style=\"text-align: right;\">  0.915215</td><td style=\"text-align: right;\">      0.0366594</td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.0311806</td><td style=\"text-align: right;\">        0.946996</td><td style=\"text-align: right;\">  0.0202231 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_fn pid=483)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=483)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=573)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=573)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=678)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=678)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=759)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=759)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=848)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=848)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=934)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=934)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1028)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1028)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1103)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1103)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1204)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1204)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1270)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1270)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1376)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1376)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1474)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1474)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1573)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1573)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1637)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1637)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1770)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1770)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1835)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1835)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1930)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1930)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2038)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2038)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2127)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2127)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2232)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2232)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2306)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2306)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2391)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2391)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2465)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2465)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2550)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2550)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2624)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2624)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2726)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2726)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2802)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2802)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2902)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2902)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3000)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3000)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3077)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3077)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3164)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3164)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3247)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3247)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3320)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3320)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3444)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3444)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3518)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3518)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3618)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3618)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3713)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3713)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3793)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3793)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3873)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3873)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3953)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3953)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4033)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4033)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4113)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4113)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4189)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4189)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4272)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4272)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4361)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4361)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4447)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4447)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4537)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4537)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4622)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4622)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4712)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4712)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4792)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4792)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4882)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4882)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4962)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4962)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5038)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5038)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5159)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5159)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5236)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5236)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5355)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5355)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5433)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5433)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5552)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5552)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5630)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5630)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5749)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5749)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5827)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5827)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5908)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5908)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5986)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5986)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6105)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6105)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6183)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6183)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6271)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6271)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6359)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6359)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6443)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6443)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6532)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6532)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6620)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6620)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6699)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6699)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6776)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6776)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6858)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6858)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6974)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6974)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7055)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7055)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7165)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7165)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7240)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7240)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7330)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7330)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7418)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7418)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7522)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7522)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7615)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7615)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7718)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7718)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7817)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7817)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7915)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7915)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7991)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7991)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8097)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8097)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8184)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8184)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8315)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8315)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8394)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8394)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8482)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8482)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8594)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8594)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8685)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8685)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8791)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8791)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8875)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8875)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8979)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8979)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=9086)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=9086)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=9174)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=9174)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=9262)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=9262)\u001b[0m   warnings.warn(\n",
      "2024-08-29 23:41:53,063\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_fn_2024-08-29_18-12-45' in 0.0471s.\n",
      "2024-08-29 23:41:53,116\tINFO tune.py:1041 -- Total run time: 19747.85 seconds (19736.69 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir /kaggle/working/tensorboard_logs\n",
    "\n",
    "\n",
    "# ray.init(ignore_reinit_error=True)\n",
    "# reporter = CLIReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "#     print_intermediate_tables=False\n",
    "# )\n",
    "\n",
    "reporter = JupyterNotebookReporter(\n",
    "    metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "    print_intermediate_tables=False,\n",
    ")\n",
    "\n",
    "# tuner = tune.run(\n",
    "#     train_fn,\n",
    "#     config=search_space,\n",
    "#     num_samples=25,\n",
    "#     progress_reporter=reporter,\n",
    "#     resources_per_trial={\"cpu\": 4, \"gpu\": 2},  # Adjust resources as needed\n",
    "#     scheduler=ASHAScheduler(\n",
    "#         metric=\"accuracy\",\n",
    "#         mode=\"max\",\n",
    "#         max_t=15,\n",
    "#         grace_period=1,\n",
    "#         reduction_factor=2\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# reporter = TensorBoardReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"training_iteration\", \"train_loss\", \"train_accuracy\"]\n",
    "# )\n",
    "\n",
    "\n",
    "result = tune.run(\n",
    "    train_fn,\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "    config=search_space,\n",
    "    num_samples=100,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    search_alg=optuna_search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac605d4",
   "metadata": {
    "papermill": {
     "duration": 0.045969,
     "end_time": "2024-08-29T23:41:53.390255",
     "exception": false,
     "start_time": "2024-08-29T23:41:53.344286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3eafd9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:41:53.493253Z",
     "iopub.status.busy": "2024-08-29T23:41:53.491349Z",
     "iopub.status.idle": "2024-08-29T23:41:53.502028Z",
     "shell.execute_reply": "2024-08-29T23:41:53.501060Z"
    },
    "papermill": {
     "duration": 0.067828,
     "end_time": "2024-08-29T23:41:53.504073",
     "exception": false,
     "start_time": "2024-08-29T23:41:53.436245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'dropout_rate': 0.3, 'batch_size': 32, 'weight_decay': 0.001, 'lr': 2e-05, 'epochs': 10}\n",
      "Best trial final validation loss: 0.026479910709895194\n",
      "Best trial final validation accuracy: 0.9300232288037166\n",
      "Best trial final training loss: 0.012003432234217013\n",
      "Best trial final training accuracy: 0.9666368114643976\n",
      "Best trial final custom_metric: 0.03371814994773428\n",
      "Best trial final Early Stopping Epoch: 10\n",
      "NOTE: Both the accuracy are based on converting values > 0.5 to 1 and values < 0.5 to 0, hence, rely on the loss, MSE here.\n"
     ]
    }
   ],
   "source": [
    "# best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "# best_checkpoint_dir = best_trial.checkpoint.value\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n",
    "print(f\"Best trial final training loss: {best_trial.last_result['train_loss']}\")\n",
    "print(f\"Best trial final training accuracy: {best_trial.last_result['train_accuracy']}\")\n",
    "print(f\"Best trial final custom_metric: {best_trial.last_result['custom_metric']}\")\n",
    "print(f\"Best trial final Early Stopping Epoch: {best_trial.last_result['early_stopping_epoch']}\")\n",
    "print(f\"NOTE: Both the accuracy are based on converting values > 0.5 to 1 and values < 0.5 to 0, hence, rely on the loss, MSE here.\")\n",
    "\n",
    "\n",
    "# print(\"\\nModel Parameters:\")\n",
    "# for name, param in best_model.named_parameters():\n",
    "#     print(f\"{name}: {param.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbeec21",
   "metadata": {
    "papermill": {
     "duration": 0.046068,
     "end_time": "2024-08-29T23:41:53.597249",
     "exception": false,
     "start_time": "2024-08-29T23:41:53.551181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to Train the Model with the Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad86cc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:41:53.693744Z",
     "iopub.status.busy": "2024-08-29T23:41:53.692777Z",
     "iopub.status.idle": "2024-08-29T23:41:53.719280Z",
     "shell.execute_reply": "2024-08-29T23:41:53.718346Z"
    },
    "papermill": {
     "duration": 0.077747,
     "end_time": "2024-08-29T23:41:53.721788",
     "exception": false,
     "start_time": "2024-08-29T23:41:53.644041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_best_model(config, device, train_dataset = train_ds_pd, val_dataset = validation_ds_pd):\n",
    "    \n",
    "    print(f\"\"\"\n",
    "    Tuning Model with:\n",
    "    {config}\n",
    "    \"\"\")\n",
    "    \n",
    "#     model = EmotionModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=7,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    model = EmotionModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=7,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = nn.MSELoss()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    ## DATASET ENCODING\n",
    "    \n",
    "    train_dataset = EmotionDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = EmotionDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = None\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    \n",
    "    ### Running for config epochs +patience+1 for introducing noise. \n",
    "    \n",
    "    for epoch in range((config[\"epochs\"]+patience+1)):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                outputs = torch.sigmoid(outputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "            correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    outputs = torch.sigmoid(outputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "                correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "        checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "#         # Save the best model based on validation loss\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "#             best_model_path = checkpoint_path\n",
    "\n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_since_improvement = 0\n",
    "            best_model_path = checkpoint_path\n",
    "            # Save the model checkpoint with the best validation loss\n",
    "#             checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#             torch.save(model.state_dict(), checkpoint_path)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'config': config  # Save configuration\n",
    "            }, checkpoint_path)\n",
    "    \n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            print(f\"Best Model Epoch Saved: {epoch - patience+1}\")\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "#         if epochs_since_improvement >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "#             print(f\"Best Model Epoch Saved: {epoch - patience}\")\n",
    "#             break\n",
    "            \n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, avg_train_loss)        \n",
    "#         custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "        print(f\"\"\"\n",
    "        Validation Loss: {avg_val_loss},\n",
    "        Training Loss: {avg_train_loss},\n",
    "        Argmax Binary Validation Accuracy: {val_accuracy},\n",
    "        Argmax Binary Training Accuracy: {train_accuracy},\n",
    "        Custom Metric: {custom_metric},\n",
    "        Epochs: {epoch+1}\n",
    "        \"\"\")\n",
    "    \n",
    "    print(f\"Best Validation Loss: {best_val_loss}, Best Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224194e",
   "metadata": {
    "papermill": {
     "duration": 0.046782,
     "end_time": "2024-08-29T23:41:53.870229",
     "exception": false,
     "start_time": "2024-08-29T23:41:53.823447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BEST MODEL AFTER FINAL TRAINING & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ed78b75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:41:53.966542Z",
     "iopub.status.busy": "2024-08-29T23:41:53.965699Z",
     "iopub.status.idle": "2024-08-29T23:56:40.589359Z",
     "shell.execute_reply": "2024-08-29T23:56:40.588326Z"
    },
    "papermill": {
     "duration": 886.73016,
     "end_time": "2024-08-29T23:56:40.647871",
     "exception": false,
     "start_time": "2024-08-29T23:41:53.917711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Tuning Model with:\n",
      "    {'dropout_rate': 0.3, 'batch_size': 32, 'weight_decay': 0.001, 'lr': 2e-05, 'epochs': 10}\n",
      "    \n",
      "\n",
      "        Validation Loss: 0.05399746051989496,\n",
      "        Training Loss: 0.08133941407182387,\n",
      "        Argmax Binary Validation Accuracy: 0.8893728222996515,\n",
      "        Argmax Binary Training Accuracy: 0.8630925724521784,\n",
      "        Custom Metric: 0.06766843729585942,\n",
      "        Epochs: 1\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.04040440125390887,\n",
      "        Training Loss: 0.05019156983388322,\n",
      "        Argmax Binary Validation Accuracy: 0.9065040650406504,\n",
      "        Argmax Binary Training Accuracy: 0.8907619474121937,\n",
      "        Custom Metric: 0.045297985543896045,\n",
      "        Epochs: 2\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.03679997811559588,\n",
      "        Training Loss: 0.03775902975882803,\n",
      "        Argmax Binary Validation Accuracy: 0.9102787456445993,\n",
      "        Argmax Binary Training Accuracy: 0.9121937176124368,\n",
      "        Custom Metric: 0.03727950393721195,\n",
      "        Epochs: 3\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.032480860594660044,\n",
      "        Training Loss: 0.030939556152692862,\n",
      "        Argmax Binary Validation Accuracy: 0.9204413472706156,\n",
      "        Argmax Binary Training Accuracy: 0.925020792015866,\n",
      "        Custom Metric: 0.03325151281564363,\n",
      "        Epochs: 4\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.032478304114192724,\n",
      "        Training Loss: 0.026329102852780905,\n",
      "        Argmax Binary Validation Accuracy: 0.9189895470383276,\n",
      "        Argmax Binary Training Accuracy: 0.9331136843452115,\n",
      "        Custom Metric: 0.03555290474489863,\n",
      "        Epochs: 5\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.030301414895802736,\n",
      "        Training Loss: 0.022538544769798007,\n",
      "        Argmax Binary Validation Accuracy: 0.9207317073170732,\n",
      "        Argmax Binary Training Accuracy: 0.9423261467596443,\n",
      "        Custom Metric: 0.0341828499588051,\n",
      "        Epochs: 6\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.03114848246332258,\n",
      "        Training Loss: 0.018889936305848617,\n",
      "        Argmax Binary Validation Accuracy: 0.9247967479674797,\n",
      "        Argmax Binary Training Accuracy: 0.9508028916895912,\n",
      "        Custom Metric: 0.03727775554205956,\n",
      "        Epochs: 7\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.03063835552893579,\n",
      "        Training Loss: 0.0165759433925684,\n",
      "        Argmax Binary Validation Accuracy: 0.9227642276422764,\n",
      "        Argmax Binary Training Accuracy: 0.9578721770839997,\n",
      "        Custom Metric: 0.03766956159711948,\n",
      "        Epochs: 8\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.0315241739153862,\n",
      "        Training Loss: 0.014998687703960708,\n",
      "        Argmax Binary Validation Accuracy: 0.921602787456446,\n",
      "        Argmax Binary Training Accuracy: 0.9603992067046254,\n",
      "        Custom Metric: 0.03978691702109895,\n",
      "        Epochs: 9\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.02907537593273446,\n",
      "        Training Loss: 0.012948002134050642,\n",
      "        Argmax Binary Validation Accuracy: 0.9247967479674797,\n",
      "        Argmax Binary Training Accuracy: 0.9654532659458768,\n",
      "        Custom Metric: 0.03713906283207637,\n",
      "        Epochs: 10\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.029212061897851527,\n",
      "        Training Loss: 0.012505145447461733,\n",
      "        Argmax Binary Validation Accuracy: 0.9274099883855982,\n",
      "        Argmax Binary Training Accuracy: 0.9656771799628943,\n",
      "        Custom Metric: 0.037565520123046425,\n",
      "        Epochs: 11\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.029171479167416692,\n",
      "        Training Loss: 0.012049039303591209,\n",
      "        Argmax Binary Validation Accuracy: 0.9265389082462253,\n",
      "        Argmax Binary Training Accuracy: 0.9663489220139466,\n",
      "        Custom Metric: 0.037732699099329435,\n",
      "        Epochs: 12\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.029040553781669587,\n",
      "        Training Loss: 0.011869484442286193,\n",
      "        Argmax Binary Validation Accuracy: 0.9271196283391405,\n",
      "        Argmax Binary Training Accuracy: 0.967180602648583,\n",
      "        Custom Metric: 0.037626088451361284,\n",
      "        Epochs: 13\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.028963963501155376,\n",
      "        Training Loss: 0.011704542291616755,\n",
      "        Argmax Binary Validation Accuracy: 0.9256678281068524,\n",
      "        Argmax Binary Training Accuracy: 0.9666687991811145,\n",
      "        Custom Metric: 0.037593674105924686,\n",
      "        Epochs: 14\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.029027810087427497,\n",
      "        Training Loss: 0.011482658862535442,\n",
      "        Argmax Binary Validation Accuracy: 0.9259581881533101,\n",
      "        Argmax Binary Training Accuracy: 0.9675324675324676,\n",
      "        Custom Metric: 0.037800385699873526,\n",
      "        Epochs: 15\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.028925861872266978,\n",
      "        Training Loss: 0.01114071727996426,\n",
      "        Argmax Binary Validation Accuracy: 0.9256678281068524,\n",
      "        Argmax Binary Training Accuracy: 0.9682361973002367,\n",
      "        Custom Metric: 0.03781843416841833,\n",
      "        Epochs: 16\n",
      "        \n",
      "Best Validation Loss: 0.028925861872266978, Best Validation accuracy: 0.9256678281068524\n"
     ]
    }
   ],
   "source": [
    "best_config = best_trial.config\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model with the best configuration\n",
    "best_model, best_model_path = train_best_model(best_config, device, train_ds_pd, validation_ds_pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f04678",
   "metadata": {
    "papermill": {
     "duration": 0.047399,
     "end_time": "2024-08-29T23:56:40.743495",
     "exception": false,
     "start_time": "2024-08-29T23:56:40.696096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c909a625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:40.840594Z",
     "iopub.status.busy": "2024-08-29T23:56:40.840244Z",
     "iopub.status.idle": "2024-08-29T23:56:42.038659Z",
     "shell.execute_reply": "2024-08-29T23:56:42.037562Z"
    },
    "papermill": {
     "duration": 1.249508,
     "end_time": "2024-08-29T23:56:42.040795",
     "exception": false,
     "start_time": "2024-08-29T23:56:40.791287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: /kaggle/working/final_best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "# final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path) \n",
    "\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path)\n",
    "torch.save({'model_state_dict': best_model.state_dict(),'config': best_config}, final_model_path)\n",
    "\n",
    "print(f\"Best model saved at: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66a0ed76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:42.140576Z",
     "iopub.status.busy": "2024-08-29T23:56:42.140237Z",
     "iopub.status.idle": "2024-08-29T23:56:42.144111Z",
     "shell.execute_reply": "2024-08-29T23:56:42.143256Z"
    },
    "papermill": {
     "duration": 0.054819,
     "end_time": "2024-08-29T23:56:42.146005",
     "exception": false,
     "start_time": "2024-08-29T23:56:42.091186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_model = EmotionModel(\n",
    "#     roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#     n_classes=7,\n",
    "#     dropout_rate=best_trial.config[\"dropout_rate\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49200d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:42.243708Z",
     "iopub.status.busy": "2024-08-29T23:56:42.242852Z",
     "iopub.status.idle": "2024-08-29T23:56:42.247112Z",
     "shell.execute_reply": "2024-08-29T23:56:42.246238Z"
    },
    "papermill": {
     "duration": 0.055672,
     "end_time": "2024-08-29T23:56:42.248997",
     "exception": false,
     "start_time": "2024-08-29T23:56:42.193325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kaggle_working_dir = '/kaggle/working'\n",
    "# best_model_path = os.path.join(kaggle_working_dir, \"checkpoint.pt\")\n",
    "# best_model.load_state_dict(torch.load(best_model_path))\n",
    "# best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd214350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:42.344721Z",
     "iopub.status.busy": "2024-08-29T23:56:42.344386Z",
     "iopub.status.idle": "2024-08-29T23:56:42.348953Z",
     "shell.execute_reply": "2024-08-29T23:56:42.348079Z"
    },
    "papermill": {
     "duration": 0.054771,
     "end_time": "2024-08-29T23:56:42.350964",
     "exception": false,
     "start_time": "2024-08-29T23:56:42.296193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # best_config = result.get_best_config(metric='accuracy', mode='max')\n",
    "# # best_trial = result.get_best_trial(metric='accuracy', mode='max')\n",
    "\n",
    "# best_config = result.get_best_config(metric='custom_metric', mode='min')\n",
    "# best_trial = result.get_best_trial(metric='custom_metric', mode='min')\n",
    "\n",
    "# print(f\"Best trial config: {best_trial.config}\")\n",
    "# print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "# print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n",
    "\n",
    "# print(\"\\nModel Parameters:\")\n",
    "# for name, param in best_model.named_parameters():\n",
    "#     print(f\"{name}: {param.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94cbe663",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:42.449644Z",
     "iopub.status.busy": "2024-08-29T23:56:42.449347Z",
     "iopub.status.idle": "2024-08-29T23:56:42.453296Z",
     "shell.execute_reply": "2024-08-29T23:56:42.452407Z"
    },
    "papermill": {
     "duration": 0.05581,
     "end_time": "2024-08-29T23:56:42.455259",
     "exception": false,
     "start_time": "2024-08-29T23:56:42.399449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_trial = tuner.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "# print(f\"Best trial config: {best_trial.config}\")\n",
    "# print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "# print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a337916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:42.552963Z",
     "iopub.status.busy": "2024-08-29T23:56:42.552251Z",
     "iopub.status.idle": "2024-08-29T23:56:42.556522Z",
     "shell.execute_reply": "2024-08-29T23:56:42.555708Z"
    },
    "papermill": {
     "duration": 0.055321,
     "end_time": "2024-08-29T23:56:42.558270",
     "exception": false,
     "start_time": "2024-08-29T23:56:42.502949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the best model\n",
    "# best_model = EmotionModel(\n",
    "#     roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#     n_classes=7,\n",
    "#     dropout_rate=best_trial.config[\"dropout_rate\"]\n",
    "# )\n",
    "\n",
    "# best_model_path = os.path.join(best_checkpoint_dir, \"checkpoint.pt\")\n",
    "# best_model.load_state_dict(torch.load(best_model_path))\n",
    "# best_model.eval()\n",
    "\n",
    "# print(f\"Best trial config: {best_trial.config}\")\n",
    "# print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "# print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d47f8b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:42.654530Z",
     "iopub.status.busy": "2024-08-29T23:56:42.654250Z",
     "iopub.status.idle": "2024-08-29T23:56:42.657915Z",
     "shell.execute_reply": "2024-08-29T23:56:42.657084Z"
    },
    "papermill": {
     "duration": 0.053881,
     "end_time": "2024-08-29T23:56:42.659655",
     "exception": false,
     "start_time": "2024-08-29T23:56:42.605774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save the best model\n",
    "# best_model = EmotionClassifier(hidden_size=best_config['hidden_size'], dropout_rate=best_config['dropout_rate']).to(device)\n",
    "# checkpoint_path = \"best_model.pth\"\n",
    "# torch.save(best_model.state_dict(), checkpoint_path)\n",
    "# print(f\"Best model saved to {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0febe64f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:42.756480Z",
     "iopub.status.busy": "2024-08-29T23:56:42.755903Z",
     "iopub.status.idle": "2024-08-29T23:56:42.759839Z",
     "shell.execute_reply": "2024-08-29T23:56:42.758948Z"
    },
    "papermill": {
     "duration": 0.05438,
     "end_time": "2024-08-29T23:56:42.761828",
     "exception": false,
     "start_time": "2024-08-29T23:56:42.707448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save the best model\n",
    "# best_model = EmotionClassifier(hidden_size=best_config['hidden_size'], dropout_rate=best_config['dropout_rate']).to(device)\n",
    "# bestmodel_path = f\"/kaggle/working/bestmodel.pt\"\n",
    "# torch.save(best_model.state_dict(), checkpoint_path)\n",
    "# print(f\"Best model saved to {bestmodel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6e786",
   "metadata": {
    "papermill": {
     "duration": 0.048424,
     "end_time": "2024-08-29T23:56:42.857637",
     "exception": false,
     "start_time": "2024-08-29T23:56:42.809213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c7c5ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:42.954976Z",
     "iopub.status.busy": "2024-08-29T23:56:42.954716Z",
     "iopub.status.idle": "2024-08-29T23:56:44.535513Z",
     "shell.execute_reply": "2024-08-29T23:56:44.534408Z"
    },
    "papermill": {
     "duration": 1.632401,
     "end_time": "2024-08-29T23:56:44.537523",
     "exception": false,
     "start_time": "2024-08-29T23:56:42.905122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /kaggle/working/final_best_model.pt for inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# final_model_path = \"/kaggle/input/tachygraphy-lv2-emotion-moodtags-v1/transformers/default/1/final_best_model.pt\"\n",
    "\n",
    "\n",
    "checkpoint = torch.load(final_model_path)\n",
    "config = checkpoint['config']\n",
    "\n",
    "# loaded_model = EmotionModel(\n",
    "#     roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#     n_classes=7,\n",
    "#     dropout_rate=config[\"dropout_rate\"]\n",
    "# )\n",
    "loaded_model = EmotionModel(\n",
    "    roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "    n_classes=7,\n",
    "    dropout_rate=config[\"dropout_rate\"]\n",
    ")\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(f\"Loaded model from {final_model_path} for inference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268b31d",
   "metadata": {
    "papermill": {
     "duration": 0.048738,
     "end_time": "2024-08-29T23:56:44.636913",
     "exception": false,
     "start_time": "2024-08-29T23:56:44.588175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PREDICT ON RANDOM INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2536d",
   "metadata": {
    "papermill": {
     "duration": 0.047819,
     "end_time": "2024-08-29T23:56:44.733355",
     "exception": false,
     "start_time": "2024-08-29T23:56:44.685536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed1c7d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:44.834171Z",
     "iopub.status.busy": "2024-08-29T23:56:44.833755Z",
     "iopub.status.idle": "2024-08-29T23:56:44.841268Z",
     "shell.execute_reply": "2024-08-29T23:56:44.840344Z"
    },
    "papermill": {
     "duration": 0.061662,
     "end_time": "2024-08-29T23:56:44.843318",
     "exception": false,
     "start_time": "2024-08-29T23:56:44.781656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, device, max_len=128):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    return torch.sigmoid(outputs).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02a9849c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:44.948335Z",
     "iopub.status.busy": "2024-08-29T23:56:44.947952Z",
     "iopub.status.idle": "2024-08-29T23:56:44.957672Z",
     "shell.execute_reply": "2024-08-29T23:56:44.956923Z"
    },
    "papermill": {
     "duration": 0.06192,
     "end_time": "2024-08-29T23:56:44.959783",
     "exception": false,
     "start_time": "2024-08-29T23:56:44.897863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = loaded_model\n",
    "best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "182666de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:45.060072Z",
     "iopub.status.busy": "2024-08-29T23:56:45.059766Z",
     "iopub.status.idle": "2024-08-29T23:56:45.901225Z",
     "shell.execute_reply": "2024-08-29T23:56:45.900308Z"
    },
    "papermill": {
     "duration": 0.892625,
     "end_time": "2024-08-29T23:56:45.903503",
     "exception": false,
     "start_time": "2024-08-29T23:56:45.010878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e806c0c",
   "metadata": {
    "papermill": {
     "duration": 0.057548,
     "end_time": "2024-08-29T23:56:46.010607",
     "exception": false,
     "start_time": "2024-08-29T23:56:45.953059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Samples & Random Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ca91f8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:46.109429Z",
     "iopub.status.busy": "2024-08-29T23:56:46.108631Z",
     "iopub.status.idle": "2024-08-29T23:56:48.220783Z",
     "shell.execute_reply": "2024-08-29T23:56:48.219817Z"
    },
    "papermill": {
     "duration": 2.164176,
     "end_time": "2024-08-29T23:56:48.223042",
     "exception": false,
     "start_time": "2024-08-29T23:56:46.058866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotions for 'hey! hru, wanna ply valo toni8?': [[0.03541061 0.02611484 0.07163358 0.15067203 0.24939255 0.07638874\n",
      "  0.42908403]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"d254d7af-0fca-49e7-acf9-fd86f020261f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d254d7af-0fca-49e7-acf9-fd86f020261f\")) {                    Plotly.newPlot(                        \"d254d7af-0fca-49e7-acf9-fd86f020261f\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.03541061,0.02611484,0.07163358,0.15067203,0.24939255,0.07638874,0.42908403,0.03541061],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"anger\",\"disgust\",\"fear\",\"joy\",\"neutral\",\"sadness\",\"surprise\",\"anger\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d254d7af-0fca-49e7-acf9-fd86f020261f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"hey! hru, wanna ply valo toni8?\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted emotions for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()  # Remove unnecessary dimensions\n",
    "\n",
    "emotion_moodtags = []\n",
    "for items in predictions_array:\n",
    "    emotion_moodtags.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=emotion_moodtags, theta=EMOTION_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Since predictions are probabilistic values, normalize to ensure they sum up to 1\n",
    "normalized_predictions = predictions_array / predictions_array.sum()  # Normalize the values\n",
    "\n",
    "\n",
    "## Horizontal Stacked Bar Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=EMOTION_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(EMOTION_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Emotion Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5b16dd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:48.322916Z",
     "iopub.status.busy": "2024-08-29T23:56:48.322597Z",
     "iopub.status.idle": "2024-08-29T23:56:48.688773Z",
     "shell.execute_reply": "2024-08-29T23:56:48.687894Z"
    },
    "papermill": {
     "duration": 0.41822,
     "end_time": "2024-08-29T23:56:48.690798",
     "exception": false,
     "start_time": "2024-08-29T23:56:48.272578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotions for 'what a badass char is arthur, he is the best game char ever made, i luv rdr2': [[0.00771297 0.00803996 0.01252394 0.86562926 0.04117928 0.02902116\n",
      "  0.0905266 ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"ef0f5c86-bf5c-43ed-8d17-fa678a56d17d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ef0f5c86-bf5c-43ed-8d17-fa678a56d17d\")) {                    Plotly.newPlot(                        \"ef0f5c86-bf5c-43ed-8d17-fa678a56d17d\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.007712966,0.008039958,0.012523939,0.86562926,0.041179284,0.029021155,0.090526596,0.007712966],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"anger\",\"disgust\",\"fear\",\"joy\",\"neutral\",\"sadness\",\"surprise\",\"anger\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ef0f5c86-bf5c-43ed-8d17-fa678a56d17d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"what a badass char is arthur, he is the best game char ever made, i luv rdr2\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted emotions for '{sample_text}': {predictions}\")\n",
    "\n",
    "predictions_array = predictions.squeeze()  # Remove unnecessary dimensions\n",
    "\n",
    "\n",
    "emotion_moodtags = []\n",
    "for items in predictions_array:\n",
    "    emotion_moodtags.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=emotion_moodtags, theta=EMOTION_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "# fig = px.line_polar(pd.DataFrame(dict(r=emotion_moodtags, theta=EMOTION_LABELS)), r='r', theta='theta', line_close=True)\n",
    "# fig.show()\n",
    "\n",
    "    \n",
    "# Since predictions are probabilistic values, normalize to ensure they sum up to 1\n",
    "normalized_predictions = predictions_array / predictions_array.sum()  # Normalize the values\n",
    "\n",
    "## Horizontal Stacked Bar Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=EMOTION_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(EMOTION_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Emotion Prediction Distribution')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da4f9424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:48.794053Z",
     "iopub.status.busy": "2024-08-29T23:56:48.793684Z",
     "iopub.status.idle": "2024-08-29T23:56:49.148381Z",
     "shell.execute_reply": "2024-08-29T23:56:49.147529Z"
    },
    "papermill": {
     "duration": 0.408737,
     "end_time": "2024-08-29T23:56:49.150370",
     "exception": false,
     "start_time": "2024-08-29T23:56:48.741633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotions for 'I don't no fr y hes sooo sad.': [[0.0237023  0.00739243 0.02094549 0.02251158 0.02742196 0.9462292\n",
      "  0.02245248]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"29b8126e-45af-470d-829a-7110718c40f6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"29b8126e-45af-470d-829a-7110718c40f6\")) {                    Plotly.newPlot(                        \"29b8126e-45af-470d-829a-7110718c40f6\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.023702295,0.0073924293,0.020945488,0.022511583,0.027421957,0.9462292,0.022452485,0.023702295],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"anger\",\"disgust\",\"fear\",\"joy\",\"neutral\",\"sadness\",\"surprise\",\"anger\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('29b8126e-45af-470d-829a-7110718c40f6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLQAAAHeCAYAAACCDFI4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEPUlEQVR4nO3deZhWZf0/8M8wMAvDjiDwFdlBRBaFIFyAFCJFAu2rZalgbrlAamAayaaJkamEgjtUZJgK1tcFARUTNaUEU0ECBLFEMROURZaZ8/vDi+fHyDrIzHDo9bquuS6e89znnM8593OeObznnPtkJUmSBAAAAACkRIXyLgAAAAAASkKgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUARETEihUrIisrKyZPnlzepZS5nW37yJEjIysra7+tY86cOZGVlRVz5szZb8ssTY0bN46BAweW+np2tu8HDhwYVapUKfV1b5OVlRUjR44ss/UBAF+eQAsAStHkyZMjKytrlz9/+ctfyrymBx54IG677bYyX+/uDBw4sNh+qVatWrRv3z5++ctfxqZNm8q7vBKZMGHCARcK9ujRI7NvK1SoENWqVYtWrVrFOeecE7Nmzdpv63niiScO2GDoQK4NACi5iuVdAAD8Nxg9enQ0adJkh+nNmzcv81oeeOCBeOONN+KKK64oNr1Ro0axcePGqFSpUpnXFBGRm5sb9957b0RErFmzJh555JEYMmRIzJs3L6ZOnVrm9fz0pz+Na665psTzTZgwIQ455JAdrm7q1q1bbNy4MXJycvZThSVz2GGHxZgxYyIiYv369bF06dKYNm1aTJkyJc4888yYMmVKsb5fvHhxVKhQsr99PvHEE3HHHXeUKDgqq8/d7mrbuHFjVKzotBgA0sRvbgAoAyeffHJ06tSpvMvYraysrMjLyyu39VesWDHOPvvszOtLL700unTpEg8++GDccsst0aBBgx3mSZIkPvvss8jPzy+VevZnyFGhQoVy3b/Vq1cvtn8jIm666aYYPHhwTJgwIRo3bhw///nPM+/l5uaWaj1bt26NoqKiyMnJKdf9EhHlvn4AoOTccggAB4Bt4wjdfPPNcccdd0TTpk2jcuXK8fWvfz3efffdSJIkrr/++jjssMMiPz8/+vXrF//5z392WM6ECROiTZs2kZubGw0aNIjLLrss1qxZk3m/R48e8fjjj8c777yTuQWtcePGxWr44u1yzzzzTJxwwglRUFAQNWrUiH79+sWiRYuKtdk23tTSpUtj4MCBUaNGjahevXqcd955sWHDhn3aJxUqVIgePXpkaov4fFynU089NZ566qno1KlT5Ofnx1133RURn1/VdcUVV0TDhg0jNzc3mjdvHj//+c+jqKio2HLXrFkTAwcOjOrVq0eNGjViwIABxfbRF7fpi6ZMmRKdO3eOypUrR82aNaNbt24xc+bMTH1vvvlmPPfcc5n9u20bdjWG1kMPPRQdO3aM/Pz8OOSQQ+Lss8+Of/3rX8XabBtT6l//+lf0798/qlSpEnXq1IkhQ4ZEYWFhCffs/5ednR2/+tWv4sgjj4zbb7891q5dm3nvi2NobdmyJUaNGhUtWrSIvLy8qF27dhx//PGZWxYHDhwYd9xxR0REsdtHI4p/vm+77bZo1qxZ5ObmxsKFC3c7dtvbb78dvXv3joKCgmjQoEGMHj06kiTJvL+rffrFZe6utm3Tvnjl1vz58+Pkk0+OatWqRZUqVeKkk07a4RbhbbcUv/DCC3HVVVdFnTp1oqCgIE477bT48MMP99wBAMA+c4UWAJSBtWvXxr///e9i07KysqJ27drFpv3ud7+LzZs3x6BBg+I///lPjB07Ns4888w48cQTY86cOfHjH/84li5dGuPHj48hQ4bE/fffn5l35MiRMWrUqOjZs2dccsklsXjx4pg4cWLMmzcvXnjhhahUqVIMGzYs1q5dG//85z/j1ltvjYjY7eDbs2fPjpNPPjmaNm0aI0eOjI0bN8b48ePjuOOOi1dffTUThm1z5plnRpMmTWLMmDHx6quvxr333ht169YtduVPSSxbtiwioth+Wrx4cZx11llx8cUXx4UXXhitWrWKDRs2RPfu3eNf//pXXHzxxXH44YfHiy++GNdee22sWrUqM2ZYkiTRr1+/mDt3bvzgBz+I1q1bx/Tp02PAgAF7Vc+oUaNi5MiRceyxx8bo0aMjJycnXn755XjmmWfi61//etx2220xaNCgqFKlSgwbNiwiIg499NBdLm/y5Mlx3nnnxVe+8pUYM2ZMfPDBBzFu3Lh44YUXYv78+VGjRo1M28LCwujdu3d06dIlbr755pg9e3b88pe/jGbNmsUll1xSwj37/2VnZ8dZZ50V1113XcydOzf69Omz03YjR46MMWPGxAUXXBCdO3eOTz75JP7617/Gq6++Gr169YqLL7443nvvvZg1a1b89re/3ekyJk2aFJ999llcdNFFkZubG7Vq1dohcNx+e7/xjW/EV7/61Rg7dmzMmDEjRowYEVu3bo3Ro0eXaBv3prbtvfnmm3HCCSdEtWrV4uqrr45KlSrFXXfdFT169IjnnnsuunTpUqz9oEGDombNmjFixIhYsWJF3HbbbXH55ZfHgw8+WKI6AYASSACAUjNp0qQkInb6k5ubm2m3fPnyJCKSOnXqJGvWrMlMv/baa5OISNq3b59s2bIlM/2ss85KcnJyks8++yxJkiRZvXp1kpOTk3z9619PCgsLM+1uv/32JCKS+++/PzOtT58+SaNGjXaodVsNkyZNykzr0KFDUrdu3eSjjz7KTHvttdeSChUqJOeee25m2ogRI5KISL7//e8XW+Zpp52W1K5de4/7acCAAUlBQUHy4YcfJh9++GGydOnS5MYbb0yysrKSdu3aZdo1atQoiYhkxowZxea//vrrk4KCguQf//hHsenXXHNNkp2dnaxcuTJJkiR59NFHk4hIxo4dm2mzdevW5IQTTthh27dt0zZLlixJKlSokJx22mnF9nGSJElRUVHm323atEm6d+++wzY+++yzSUQkzz77bJIkSbJ58+akbt26yVFHHZVs3Lgx0+6xxx5LIiIZPnx4sf0TEcno0aOLLfPoo49OOnbsuMO6vqh79+5JmzZtdvn+9OnTk4hIxo0bl5nWqFGjZMCAAZnX7du3T/r06bPb9Vx22WXJzk4vt322qlWrlqxevXqn722/77dt76BBgzLTioqKkj59+iQ5OTnJhx9+mCTJjvt0d8vcVW1JkiQRkYwYMSLzun///klOTk6ybNmyzLT33nsvqVq1atKtW7fMtG3Hd8+ePYt9Bq688sokOzu72LEMAOxfbjkEgDJwxx13xKxZs4r9PPnkkzu0O+OMM6J69eqZ19uuBDn77LOLjefUpUuX2Lx5c+bWtNmzZ8fmzZvjiiuuKDaQ94UXXhjVqlWLxx9/vMQ1r1q1KhYsWBADBw6MWrVqZaa3a9cuevXqFU888cQO8/zgBz8o9vqEE06Ijz76KD755JM9rm/9+vVRp06dqFOnTjRv3jx+8pOfRNeuXWP69OnF2jVp0iR69+5dbNpDDz0UJ5xwQtSsWTP+/e9/Z3569uwZhYWF8ec//zkiPh8YvGLFisWuaMrOzo5Bgwbtsb5HH300ioqKYvjw4TsMlr6zWxP35K9//WusXr06Lr300mJjOPXp0yeOOOKInfbZzvbv22+/XeJ1f9G2q/Q+/fTTXbapUaNGvPnmm7FkyZJ9Xs+3vvWtqFOnzl63v/zyyzP/zsrKissvvzw2b94cs2fP3uca9qSwsDBmzpwZ/fv3j6ZNm2am169fP7773e/G3Llzd/g8X3TRRcU+AyeccEIUFhbGO++8U2p1AsB/O7ccAkAZ6Ny5814NCn/44YcXe70t3GrYsOFOp3/88ccREZn/OLdq1apYu5ycnGjatOk+/cd6V8uMiGjdunU89dRTsX79+igoKNhl/TVr1szUWa1atd2uLy8vL/7v//4vIj4fkLxJkyZx2GGH7dBuZ0+LXLJkSfz973/fZViyevXqzDbVr19/h9ssd7aNX7Rs2bKoUKFCHHnkkXtsuzd2t3+POOKImDt3brFpeXl5O2xfzZo1M5+BL2PdunUREVG1atVdthk9enT069cvWrZsGUcddVR84xvfiHPOOSfatWu31+vZWd/tSoUKFYoFShERLVu2jIj/P6Zaafjwww9jw4YNu/zcFxUVxbvvvhtt2rTJTN/d5x4AKB0CLQA4gGRnZ5doerLdANkHgi9TZ3Z2dvTs2XOP7Xb2RMOioqLo1atXXH311TudZ1sQkma72rf7wxtvvBEREc2bN99lm27dusWyZcvij3/8Y8ycOTPuvffeuPXWW+POO++MCy64YK/Ws7+fRrmrK+O+zED5+yItxycAHEzccggAB4FGjRpFxOcDpm9v8+bNsXz58sz7EXt/e9yulhkR8dZbb8UhhxxS7Oqs8tSsWbNYt25d9OzZc6c/266gadSoUaxatSpzRdI2O9vGna2jqKgoFi5cuNt2+2P/Ll68uFiflabCwsJ44IEHonLlynH88cfvtm2tWrXivPPOi9///vfx7rvvRrt27Yo9HXBfbr3claKioh1up/zHP/4REZF5GMG2K6G++JTKnV2RuLe11alTJypXrrzLz32FChV2uGISACh7Ai0AOAj07NkzcnJy4le/+lWxq0Luu+++WLt2bbEn1xUUFMTatWv3uMz69etHhw4d4te//nWxwOCNN96ImTNnximnnLJft+HLOPPMM+Oll16Kp556aof31qxZE1u3bo2IiFNOOSW2bt0aEydOzLxfWFgY48eP3+M6+vfvHxUqVIjRo0fv8GS+7fd5QUHBDgHLznTq1Cnq1q0bd955Z2zatCkz/cknn4xFixbt8mmD+1NhYWEMHjw4Fi1aFIMHD97tbaEfffRRsddVqlSJ5s2bF6t9W8C5N9u/N26//fbMv5Mkidtvvz0qVaoUJ510UkR8HgpmZ2dnxkjbZsKECTssa29ry87Ojq9//evxxz/+sditjR988EE88MADcfzxx+/x9lkAoPS55RAAysCTTz4Zb7311g7Tjz322B3GCdoXderUiWuvvTZGjRoV3/jGN+Kb3/xmLF68OCZMmBBf+cpX4uyzz8607dixYzz44INx1VVXxVe+8pWoUqVK9O3bd6fL/cUvfhEnn3xydO3aNc4///zYuHFjjB8/PqpXr17sypzyNnTo0PjTn/4Up556agwcODA6duwY69evj9dffz0efvjhWLFiRRxyyCHRt2/fOO644+Kaa66JFStWxJFHHhnTpk3bq4CvefPmMWzYsLj++uvjhBNOiNNPPz1yc3Nj3rx50aBBgxgzZkxEfL5/J06cGDfccEM0b9486tatGyeeeOIOy6tUqVL8/Oc/j/POOy+6d+8eZ511VnzwwQcxbty4aNy4cVx55ZX7dR+tXbs2pkyZEhERGzZsiKVLl8a0adNi2bJl8Z3vfCeuv/763c5/5JFHRo8ePaJjx45Rq1at+Otf/xoPP/xwsYHbO3bsGBERgwcPjt69e0d2dnZ85zvf2ad68/LyYsaMGTFgwIDo0qVLPPnkk/H444/HT37yk8xYYtWrV48zzjgjxo8fH1lZWdGsWbN47LHHMmOmba8ktd1www0xa9asOP744+PSSy+NihUrxl133RWbNm2KsWPH7tP2AAD7l0ALAMrA8OHDdzp90qRJ+yXQiogYOXJk1KlTJ26//fa48soro1atWnHRRRfFjTfeGJUqVcq0u/TSS2PBggUxadKkuPXWW6NRo0a7DLR69uwZM2bMiBEjRsTw4cOjUqVK0b179/j5z39eogG+S1vlypXjueeeixtvvDEeeuih+M1vfhPVqlWLli1bxqhRozKD6FeoUCH+9Kc/xRVXXBFTpkyJrKys+OY3vxm//OUv4+ijj97jekaPHh1NmjSJ8ePHx7Bhw6Jy5crRrl27OOecczJthg8fHu+8806MHTs2Pv300+jevftOA62IiIEDB0blypXjpptuih//+MdRUFAQp512Wvz85z+PGjVq7Jd9s80///nPTJ1VqlSJ+vXrR9euXWPixInRq1evPc4/ePDg+NOf/hQzZ86MTZs2RaNGjeKGG26IoUOHZtqcfvrpMWjQoJg6dWpMmTIlkiTZ50ArOzs7ZsyYEZdcckkMHTo0qlatmvkcbm/8+PGxZcuWuPPOOyM3NzfOPPPM+MUvfhFHHXVUsXYlqa1Nmzbx/PPPx7XXXhtjxoyJoqKi6NKlS0yZMiXz5FEAoHxlJUarBAAAACBFjKEFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVKm4vxdYVFQU7733XlStWjWysrL29+IBAAAASIkkSeLTTz+NBg0aRIUK+++6qv0eaL333nvRsGHD/b1YAAAAAFLq3XffjcMOO2y/LW+/B1pVq1aNiM8LrVat2v5ePAAAAAAp8cknn0TDhg0zedH+st8DrW23GVarVk2gBQAAAMB+H5bKoPAAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASJWKpbXgo0Y8FRVyK5fW4iMiYkXed3f7ftsmh5fKev8wZmupLHd7z/S4o9TXsTOffXxLuawXAAAAKB/fbvLjUlv2p5vWl8pyXaEFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFQRaAEAAACQKgItAAAAAFJFoAUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkSlaSJMn+XOAnn3wS1atXj7Vr10a1atX256IBAAAASJHSyolcoQUAAABAqgi0AAAAAEgVgRYAAAAAqSLQAgAAACBVBFoAAAAApIpACwAAAIBUEWgBAAAAkCoCLQAAAABSRaAFAAAAQKoItAAAAABIFYEWAAAAAKki0AIAAAAgVQRaAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUqXi/l5gkiQREfHJJ5/s70UDAAAAkCLb8qFtedH+st8DrY8++igiIho2bLi/Fw0AAABACn300UdRvXr1/ba8/R5o1apVKyIiVq5cuV8LpXx88skn0bBhw3j33XejWrVq5V0OX5L+PPjo04OL/jy46M+Di/48+OjTg4v+PLjoz4PL2rVr4/DDD8/kRfvLfg+0KlT4fFiu6tWr++AdRKpVq6Y/DyL68+CjTw8u+vPgoj8PLvrz4KNPDy768+CiPw8u2/Ki/ba8/bo0AAAAAChlAi0AAAAAUmW/B1q5ubkxYsSIyM3N3d+Lphzoz4OL/jz46NODi/48uOjPg4v+PPjo04OL/jy46M+DS2n1Z1ayv5+bCAAAAAClyC2HAAAAAKSKQAsAAACAVBFoAQAAAJAqAi0AAAAAUmWfAq077rgjGjduHHl5edGlS5d45ZVXdtv+oYceiiOOOCLy8vKibdu28cQTT+xTsZSOkvTnm2++Gd/61reicePGkZWVFbfddlvZFcpeKUl/3nPPPXHCCSdEzZo1o2bNmtGzZ889Hs+UvZL06bRp06JTp05Ro0aNKCgoiA4dOsRvf/vbMqyWPSnp79Btpk6dGllZWdG/f//SLZASKUl/Tp48ObKysor95OXllWG17ElJj881a9bEZZddFvXr14/c3Nxo2bKl89wDTEn6tEePHjsco1lZWdGnT58yrJjdKekxetttt0WrVq0iPz8/GjZsGFdeeWV89tlnZVQte1KS/tyyZUuMHj06mjVrFnl5edG+ffuYMWNGGVbL7vz5z3+Ovn37RoMGDSIrKyseffTRPc4zZ86cOOaYYyI3NzeaN28ekydPLvmKkxKaOnVqkpOTk9x///3Jm2++mVx44YVJjRo1kg8++GCn7V944YUkOzs7GTt2bLJw4cLkpz/9aVKpUqXk9ddfL+mqKQUl7c9XXnklGTJkSPL73/8+qVevXnLrrbeWbcHsVkn787vf/W5yxx13JPPnz08WLVqUDBw4MKlevXryz3/+s4wrZ1dK2qfPPvtsMm3atGThwoXJ0qVLk9tuuy3Jzs5OZsyYUcaVszMl7c9tli9fnvzP//xPcsIJJyT9+vUrm2LZo5L256RJk5Jq1aolq1atyvy8//77ZVw1u1LS/ty0aVPSqVOn5JRTTknmzp2bLF++PJkzZ06yYMGCMq6cXSlpn3700UfFjs833ngjyc7OTiZNmlS2hbNTJe3P3/3ud0lubm7yu9/9Llm+fHny1FNPJfXr10+uvPLKMq6cnSlpf1599dVJgwYNkscffzxZtmxZMmHChCQvLy959dVXy7hyduaJJ55Ihg0blkybNi2JiGT69Om7bf/2228nlStXTq666qpk4cKFyfjx4/fp/ywlDrQ6d+6cXHbZZZnXhYWFSYMGDZIxY8bstP2ZZ56Z9OnTp9i0Ll26JBdffHFJV00pKGl/bq9Ro0YCrQPMl+nPJEmSrVu3JlWrVk1+/etfl1aJlNCX7dMkSZKjjz46+elPf1oa5VFC+9KfW7duTY499tjk3nvvTQYMGCDQOoCUtD8nTZqUVK9evYyqo6RK2p8TJ05MmjZtmmzevLmsSqSEvuzv0FtvvTWpWrVqsm7dutIqkRIoaX9edtllyYknnlhs2lVXXZUcd9xxpVone6ek/Vm/fv3k9ttvLzbt9NNPT773ve+Vap2U3N4EWldffXXSpk2bYtO+/e1vJ7179y7Rukp0y+HmzZvjb3/7W/Ts2TMzrUKFCtGzZ8946aWXdjrPSy+9VKx9RETv3r132Z6ysy/9yYFrf/Tnhg0bYsuWLVGrVq3SKpMS+LJ9miRJPP3007F48eLo1q1baZbKXtjX/hw9enTUrVs3zj///LIok720r/25bt26aNSoUTRs2DD69esXb775ZlmUyx7sS3/+6U9/iq5du8Zll10Whx56aBx11FFx4403RmFhYVmVzW7sj/Oi++67L77zne9EQUFBaZXJXtqX/jz22GPjb3/7W+Y2trfffjueeOKJOOWUU8qkZnZtX/pz06ZNO9ymn5+fH3Pnzi3VWikd+ysnKlGg9e9//zsKCwvj0EMPLTb90EMPjffff3+n87z//vslak/Z2Zf+5MC1P/rzxz/+cTRo0GCHLxfKx7726dq1a6NKlSqRk5MTffr0ifHjx0evXr1Ku1z2YF/6c+7cuXHffffFPffcUxYlUgL70p+tWrWK+++/P/74xz/GlClToqioKI499tj45z//WRYlsxv70p9vv/12PPzww1FYWBhPPPFEXHfddfHLX/4ybrjhhrIomT34sudFr7zySrzxxhtxwQUXlFaJlMC+9Od3v/vdGD16dBx//PFRqVKlaNasWfTo0SN+8pOflEXJ7Ma+9Gfv3r3jlltuiSVLlkRRUVHMmjUrpk2bFqtWrSqLktnPdpUTffLJJ7Fx48a9Xo6nHAIREXHTTTfF1KlTY/r06QYpTrmqVavGggULYt68efGzn/0srrrqqpgzZ055l0UJffrpp3HOOefEPffcE4ccckh5l8N+0LVr1zj33HOjQ4cO0b1795g2bVrUqVMn7rrrrvIujX1QVFQUdevWjbvvvjs6duwY3/72t2PYsGFx5513lndp7Af33XdftG3bNjp37lzepbCP5syZEzfeeGNMmDAhXn311Zg2bVo8/vjjcf3115d3aeyDcePGRYsWLeKII46InJycuPzyy+O8886LChVEGv/NKpak8SGHHBLZ2dnxwQcfFJv+wQcfRL169XY6T7169UrUnrKzL/3JgevL9OfNN98cN910U8yePTvatWtXmmVSAvvapxUqVIjmzZtHRESHDh1i0aJFMWbMmOjRo0dplsselLQ/ly1bFitWrIi+fftmphUVFUVERMWKFWPx4sXRrFmz0i2aXdofv0MrVaoURx99dCxdurQ0SqQE9qU/69evH5UqVYrs7OzMtNatW8f7778fmzdvjpycnFKtmd37Msfo+vXrY+rUqTF69OjSLJES2Jf+vO666+Kcc87JXGXXtm3bWL9+fVx00UUxbNgwQUg52pf+rFOnTjz66KPx2WefxUcffRQNGjSIa665Jpo2bVoWJbOf7SonqlatWuTn5+/1ckp0FOfk5ETHjh3j6aefzkwrKiqKp59+Orp27brTebp27VqsfUTErFmzdtmesrMv/cmBa1/7c+zYsXH99dfHjBkzolOnTmVRKntpfx2jRUVFsWnTptIokRIoaX8eccQR8frrr8eCBQsyP9/85jfja1/7WixYsCAaNmxYluXzBfvj+CwsLIzXX3896tevX1plspf2pT+PO+64WLp0aSZojoj4xz/+EfXr1xdmHQC+zDH60EMPxaZNm+Lss88u7TLZS/vSnxs2bNghtNoWQH8+bjXl5cscn3l5efE///M/sXXr1njkkUeiX79+pV0upWC/5UQlG6/+88dr5ubmJpMnT04WLlyYXHTRRUmNGjUyj50+55xzkmuuuSbT/oUXXkgqVqyY3HzzzcmiRYuSESNGJJUqVUpef/31kq6aUlDS/ty0aVMyf/78ZP78+Un9+vWTIUOGJPPnz0+WLFlSXpvAdkranzfddFOSk5OTPPzww8UeU/3pp5+W1ybwBSXt0xtvvDGZOXNmsmzZsmThwoXJzTffnFSsWDG55557ymsT2E5J+/OLPOXwwFLS/hw1alTy1FNPJcuWLUv+9re/Jd/5zneSvLy85M033yyvTWA7Je3PlStXJlWrVk0uv/zyZPHixcljjz2W1K1bN7nhhhvKaxP4gn39zj3++OOTb3/722VdLntQ0v4cMWJEUrVq1eT3v/998vbbbyczZ85MmjVrlpx55pnltQlsp6T9+Ze//CV55JFHkmXLliV//vOfkxNPPDFp0qRJ8vHHH5fTFrC9Tz/9NJMTRERyyy23JPPnz0/eeeedJEmS5JprrknOOeecTPu33347qVy5cjJ06NBk0aJFyR133JFkZ2cnM2bMKNF6SxxoJUmSjB8/Pjn88MOTnJycpHPnzslf/vKXzHvdu3dPBgwYUKz9H/7wh6Rly5ZJTk5O0qZNm+Txxx/fl9VSSkrSn8uXL08iYoef7t27l33h7FRJ+rNRo0Y77c8RI0aUfeHsUkn6dNiwYUnz5s2TvLy8pGbNmknXrl2TqVOnlkPV7EpJf4duT6B14ClJf15xxRWZtoceemhyyimnJK+++mo5VM2ulPT4fPHFF5MuXbokubm5SdOmTZOf/exnydatW8u4ananpH361ltvJRGRzJw5s4wrZW+UpD+3bNmSjBw5MmnWrFmSl5eXNGzYMLn00ksFIAeQkvTnnDlzktatWye5ublJ7dq1k3POOSf517/+VQ5VszPPPvvsTv9fua0PBwwYsENm8OyzzyYdOnRIcnJykqZNmyaTJk0q8XqzksT1lgAAAACkh5HwAAAAAEgVgRYAAAAAqSLQAgAAACBVKpZ3AUBxhYWFsWXLlvIuAwAA+IJKlSpFdnZ2eZcBhEALDhhJksT7778fa9asKe9SAACAXahRo0bUq1cvsrKyyrsU+K8m0IIDxLYwq27dulG5cmW/IAEA4ACSJEls2LAhVq9eHRER9evXL+eK4L+bQAsOAIWFhZkwq3bt2uVdDgAAsBP5+fkREbF69eqoW7eu2w+hHBkUHg4A28bMqly5cjlXAgAA7M62c3bj3kL5EmjBAcRthgAAcGBzzg4HBoEWAAAAAKki0AL4L9ajR4+44oorIiKicePGcdttt5VrPZRMkiRx0UUXRa1atSIrKysWLFhQ3iX91xg4cGD079+/vMvgAOC7s2xlZWXFo48+Wt5lcIAbOXJkdOjQobzLAEqZQeHhANb4msfLdH0rbupTpus7qIysXsbrW7vfFzlv3rwoKCjY78vdFytWrIgmTZrE/Pnzy+2EtO2v25bp+l4f8HqJ55kxY0ZMnjw55syZE02bNo1DDjmkFCore4uOaF2m62v91qISzzNu3LhIkqQUqildd/zgmTJd32V3nlim69sbPXr0iA4dOhw0IdQvv31qma3rRw8+Vmbrorh/XvN8ma7vsJtOKNP17W9DhgyJQYMGlXcZQCkTaAEHpS1btkSlSpXKu4xUqVOnTnmXQAktW7Ys6tevH8cee2yprWPz5s2Rk5NTastPq+rVyzjEpkwlSRKFhYVRsaJTZSgP+/q7Z9uxW6VKlahSpUopVAYcSNxyCHwpM2bMiOOPPz5q1KgRtWvXjlNPPTWWLVsWEZ9fZZOVlRXTpk2Lr33ta1G5cuVo3759vPTSS8WWcc8990TDhg2jcuXKcdppp8Utt9wSNWrUKNbmj3/8YxxzzDGRl5cXTZs2jVGjRsXWrVsz72dlZcXEiRPjm9/8ZhQUFMTPfvazUt/2tFm/fn2ce+65UaVKlahfv3788pe/LPb+9rfNJEkSI0eOjMMPPzxyc3OjQYMGMXjw4EzbVatWRZ8+fSI/Pz+aNGkSDzzwQLH5t/X99rfArVmzJrKysmLOnDkREfHxxx/H9773vahTp07k5+dHixYtYtKkSRER0aRJk4iIOProoyMrKyt69OhRKvskzQYOHBiDBg2KlStXRlZWVjRu3DiKiopizJgx0aRJk8jPz4/27dvHww8/nJmnsLAwzj///Mz7rVq1inHjxu2w3P79+8fPfvazaNCgQbRq1aqsNy0Vtr/lcNOmTTF48OCoW7du5OXlxfHHHx/z5s2LiM+PpebNm8fNN99cbP4FCxZEVlZWLF26tKxLP6D16NEjBg8eHFdffXXUqlUr6tWrFyNHjsy8v2bNmrjggguiTp06Ua1atTjxxBPjtddey7y/s1tBr7jiisx3yMCBA+O5556LcePGRVZWVmRlZcWKFStizpw5kZWVFU8++WR07NgxcnNzY+7cubFs2bLo169fHHrooVGlSpX4yle+ErNnzy6DPXHwePjhh6Nt27aRn58ftWvXjp49e8b69etj3rx50atXrzjkkEOievXq0b1793j11VeLzbtkyZLo1q1b5OXlxZFHHhmzZs0q9v7enmfMnTs3TjjhhMjPz4+GDRvG4MGDY/369Zn3J0yYEC1atIi8vLw49NBD43//93/3WD872tW+2n54g2369+8fAwcOzLxu3LhxXH/99XHuuedGtWrV4qKLLsr079SpU+PYY4+NvLy8OOqoo+K5557LzLerY/eLtxzOmTMnOnfuHAUFBVGjRo047rjj4p133sm8v6fzTODAJNACvpT169fHVVddFX/961/j6aefjgoVKsRpp50WRUVFmTbDhg2LIUOGxIIFC6Jly5Zx1llnZU4SXnjhhfjBD34QP/zhD2PBggXRq1evHcKo559/Ps4999z44Q9/GAsXLoy77rorJk+evEO7kSNHxmmnnRavv/56fP/73y/9jU+ZoUOHxnPPPRd//OMfY+bMmTFnzpwd/vOwzSOPPBK33npr3HXXXbFkyZJ49NFHo23b/38L3rnnnhvvvfdezJkzJx555JG4++67Y/Xq1SWq57rrrouFCxfGk08+GYsWLYqJEydmbpl75ZVXIiJi9uzZsWrVqpg2bdo+bvXBa9y4cTF69Og47LDDYtWqVTFv3rwYM2ZM/OY3v4k777wz3nzzzbjyyivj7LPPzpz8FxUVxWGHHRYPPfRQLFy4MIYPHx4/+clP4g9/+EOxZT/99NOxePHimDVrVjz2mFuM9uTqq6+ORx55JH7961/Hq6++Gs2bN4/evXvHf/7zn8jKyorvf//7mbB2m0mTJkW3bt2iefPm5VT1gevXv/51FBQUxMsvvxxjx46N0aNHZ4KMM844I1avXh1PPvlk/O1vf4tjjjkmTjrppPjPf/6zV8seN25cdO3aNS688MJYtWpVrFq1Kho2bJh5/5prrombbropFi1aFO3atYt169bFKaecEk8//XTMnz8/vvGNb0Tfvn1j5cqVpbLtB5tVq1bFWWedFd///vdj0aJFMWfOnDj99NMjSZL49NNPY8CAATF37tz4y1/+Ei1atIhTTjklPv3004j4/Pvq9NNPj5ycnHj55ZfjzjvvjB//+Mc7Xc/uzjOWLVsW3/jGN+Jb3/pW/P3vf48HH3ww5s6dG5dffnlERPz1r3+NwYMHx+jRo2Px4sUxY8aM6Nat2x7rp7j9sa9uvvnmaN++fcyfPz+uu+66zPShQ4fGj370o5g/f3507do1+vbtGx999FGxeb947G5v69at0b9//+jevXv8/e9/j5deeikuuuiizJMK9/Y8EzjwuI4a+FK+9a1vFXt9//33R506dWLhwoWZS72HDBkSffp8Pj7XqFGjok2bNrF06dI44ogjYvz48XHyySfHkCFDIiKiZcuW8eKLLxb7T/SoUaPimmuuiQEDBkRERNOmTeP666+Pq6++OkaMGJFp993vfjfOO++8Ut3etFq3bl3cd999MWXKlDjppJMi4vP/NB522GE7bb9y5cqoV69e9OzZMypVqhSHH354dO7cOSIi3nrrrZg9e3bMmzcvOnXqFBER9957b7Ro0aJENa1cuTKOPvrozDIaN26ceW/b7Y+1a9eOevXqlWi5/y2qV68eVatWjezs7KhXr15s2rQpbrzxxpg9e3Z07do1Ij4/VubOnRt33XVXdO/ePSpVqhSjRo3KLKNJkybx0ksvxR/+8Ic488wzM9MLCgri3nvvdavhXli/fn1MnDgxJk+eHCeffHJEfH7V6axZs+K+++6LoUOHxsCBA2P48OHxyiuvROfOnWPLli3xwAMP7HDVFp9r165d5ru9RYsWcfvtt8fTTz8d+fn58corr8Tq1asjNzc3Ij7/D/Cjjz4aDz/8cFx00UV7XHb16tUjJycnKleuvNPvltGjR0evXr0yr2vVqhXt27fPvL7++utj+vTp8ac//SkTiLBrq1atiq1bt8bpp58ejRo1iojI/HHkxBOLj6929913R40aNeK5556LU089NWbPnh1vvfVWPPXUU9GgQYOIiLjxxhszx9n2dneeMWbMmPje976XuUKoRYsW8atf/Sq6d+8eEydOjJUrV0ZBQUGceuqpUbVq1WjUqFEcffTRe6yf4vbHvjrxxBPjRz/6Ueb1ihUrIiLi8ssvz5xvTpw4MWbMmBH33XdfXH311Zm2Xzx2t/fJJ5/E2rVr49RTT41mzZpFRETr1v9/rMa9Pc8EDjyu0AK+lCVLlsRZZ50VTZs2jWrVqmVCie3/er39X8rq168fEZG5mmfx4sWZoGSbL75+7bXXYvTo0ZnxEKpUqZL56/qGDRsy7bYFI+xo2bJlsXnz5ujSpUtmWq1atXZ5O9kZZ5wRGzdujKZNm8aFF14Y06dPz/y1e/HixVGxYsU45phjMu2bN28eNWvWLFFNl1xySUydOjU6dOgQV199dbz44ov7sGVss3Tp0tiwYUP06tWr2LHym9/8JnMbcETEHXfcER07dow6depElSpV4u67797hapO2bdsKs/bSsmXLYsuWLXHcccdlplWqVCk6d+4cixZ9Pth8gwYNok+fPnH//fdHRMT//d//xaZNm+KMM84ol5oPdF+8uqJ+/fqxevXqeO2112LdunVRu3btYp/x5cuXF/uMfxlf/D2ybt26GDJkSLRu3Tpq1KgRVapUiUWLFrlCay+1b98+TjrppGjbtm2cccYZcc8998THH38cEREffPBBXHjhhdGiRYuoXr16VKtWLdatW5fZt4sWLYqGDRtmwqyIyIT1X7S784zXXnstJk+eXOwz07t37ygqKorly5dHr169olGjRtG0adM455xz4ne/+13m3GJ39VPc/thXuzqP277fK1asGJ06dcp8v+5p3ojPz3cGDhwYvXv3jr59+8a4ceNi1apVmff39jwTOPAItIAvpW/fvvGf//wn7rnnnnj55Zfj5ZdfjojPB/PcZvvB2bdd3r39LYl7sm7duhg1alQsWLAg8/P666/HkiVLIi8vL9PuQHlC38GgYcOGsXjx4pgwYULk5+fHpZdeGt26dYstW7bs1fwVKnz+62X7Ww2+OO/JJ58c77zzTlx55ZXx3nvvxUknnZS5Uo+SW7duXUREPP7448WOlYULF2bG0Zo6dWoMGTIkzj///Jg5c2YsWLAgzjvvvGLHa4RjqTRccMEFMXXq1Ni4cWNMmjQpvv3tb0flypXLu6wD0hcf6JGVlRVFRUWxbt26qF+/frHP94IFC2Lx4sUxdOjQiPj8u+eLtzjt7fdWxI6f/SFDhsT06dPjxhtvjOeffz4WLFgQbdu23eGYYeeys7Nj1qxZ8eSTT8aRRx4Z48ePj1atWsXy5ctjwIABsWDBghg3bly8+OKLsWDBgqhdu/Y+7dvdnWesW7cuLr744mKfmddeey2WLFkSzZo1i6pVq8arr74av//976N+/foxfPjwaN++faxZs2a39VPc7vbV3h6XX+Z3z57mnTRpUrz00ktx7LHHxoMPPhgtW7aMv/zlLxGx9+eZwIFHoAXss48++igWL14cP/3pT+Okk06K1q1bl/ivca1atcoMnrzNF18fc8wxsXjx4mjevPkOP9uCE3avWbNmUalSpUzgGPH5oOz/+Mc/djlPfn5+9O3bN371q1/FnDlz4qWXXorXX389WrVqFVu3bo358+dn2i5durRY32+7ZXD7v4BuP0D89u0GDBgQU6ZMidtuuy3uvvvuiIjM1UGFhYX7tsH/hY488sjIzc2NlStX7nCcbBsj6IUXXohjjz02Lr300jj66KOjefPm++3Klv9WzZo1i5ycnHjhhRcy07Zs2RLz5s2LI488MjPtlFNOiYKCgsztMsb5K7ljjjkm3n///ahYseIOn/Ft4+/VqVOn2PdOxI7fPTk5OXv93fLCCy/EwIED47TTTou2bdtGvXr1MrdBsXeysrLiuOOOi1GjRsX8+fMjJycnpk+fHi+88EIMHjw4TjnllGjTpk3k5ubGv//978x8rVu3jnfffbdYf24LIErimGOOiYULF+70HGLb75qKFStGz549Y+zYsfH3v/89VqxYEc8888xu62dHu9pXXzwuCwsL44033tjr5W7f71u3bo2//e1vxW4Z3FtHH310XHvttfHiiy/GUUcdFQ888EBEOM+ENDOGFrDPatasGbVr146777476tevHytXroxrrrmmRMsYNGhQdOvWLW655Zbo27dvPPPMM/Hkk09m/sIaETF8+PA49dRT4/DDD4///d//jQoVKsRrr70Wb7zxRtxwww37e7MOSlWqVInzzz8/hg4dGrVr1466devGsGHDdnmiNnny5CgsLIwuXbpE5cqVY8qUKZGfnx+NGjXKPLnooosuiokTJ0alSpXiRz/6UeTn52f6LT8/P7761a/GTTfdFE2aNInVq1fHT3/602LrGD58eHTs2DHatGkTmzZtisceeyxzglq3bt3Iz8+PGTNmxGGHHRZ5eXlRvXr10t1JKVe1atUYMmRIXHnllVFUVBTHH398rF27Nl544YWoVq1aDBgwIFq0aBG/+c1v4qmnnoomTZrEb3/725g3b17mqZKUXEFBQVxyySUxdOjQqFWrVhx++OExduzY2LBhQ5x//vmZdtnZ2TFw4MC49tpro0WLFru8dYpd69mzZ3Tt2jX69+8fY8eOjZYtW8Z7770Xjz/+eJx22mnRqVOnOPHEE+MXv/hF/OY3v4muXbvGlClT4o033siMiRTx+Xh9L7/8cqxYsSKqVKkStWrV2uU6W7RoEdOmTYu+fftGVlZWXHfddSW6wvi/3csvvxxPP/10fP3rX4+6devGyy+/HB9++GG0bt06WrRoEb/97W+jU6dO8cknn8TQoUMjPz8/M2/Pnj2jZcuWMWDAgPjFL34Rn3zySQwbNqzENfz4xz+Or371q3H55ZfHBRdcEAUFBbFw4cKYNWtW3H777fHYY4/F22+/Hd26dYuaNWvGE088EUVFRdGqVavd1k9xu9tXBQUFcdVVV8Xjjz8ezZo1i1tuuSXWrFmz18u+4447okWLFtG6deu49dZb4+OPPy7RHwWWL18ed999d3zzm9+MBg0axOLFi2PJkiVx7rnnRoTzTEi1BCh3GzduTBYuXJhs3LixvEspsVmzZiWtW7dOcnNzk3bt2iVz5sxJIiKZPn16snz58iQikvnz52faf/zxx0lEJM8++2xm2t133538z//8T5Kfn5/0798/ueGGG5J69eoVW8+MGTOSY489NsnPz0+qVauWdO7cObn77rsz729bJ7v26aefJmeffXZSuXLl5NBDD03Gjh2bdO/ePfnhD3+YJEmSNGrUKLn11luTJEmS6dOnJ126dEmqVauWFBQUJF/96leT2bNnZ5b13nvvJSeffHKSm5ubNGrUKHnggQeSunXrJnfeeWemzcKFC5OuXbsm+fn5SYcOHZKZM2cW6/vrr78+ad26dZKfn5/UqlUr6devX/L2229n5r/nnnuShg0bJhUqVEi6d+9e2rsnlW699dakUaNGmddFRUXJbbfdlrRq1SqpVKlSUqdOnaR3797Jc889lyRJknz22WfJwIEDk+rVqyc1atRILrnkkuSaa65J2rdvn1nGgAEDkn79+pXthqTQ9vtp48aNyaBBg5JDDjkkyc3NTY477rjklVde2WGeZcuWJRGRjB07toyrTY/tv5O26devXzJgwIAkSZLkk08+SQYNGpQ0aNAgqVSpUtKwYcPke9/7XrJy5cpM++HDhyeHHnpoUr169eTKK69MLr/88mLfIYsXL06++tWvJvn5+UlEJMuXL0+effbZJCKSjz/+uNi6ly9fnnzta19L8vPzk4YNGya33377DjVu/91JcQsXLkx69+6d1KlTJ8nNzU1atmyZjB8/PkmSJHn11VeTTp06JXl5eUmLFi2Shx56aId9uXjx4uT4449PcnJykpYtWyYzZswo9vt+b88zXnnllaRXr15JlSpVkoKCgqRdu3bJz372syRJkuT5559PunfvntSsWTPJz89P2rVrlzz44IN7rJ/idrevNm/enFxyySVJrVq1krp16yZjxowpdlwnyc6Po239+8ADDySdO3dOcnJykiOPPDJ55plnMm12deyOGDEi87vt/fffT/r375/Ur18/ycnJSRo1apQMHz48KSwszLTf03nmF6X53B0OJllJ4rmzUN4+++yzWL58eTRp0sS9+hFx4YUXxltvvRXPP/98eZfCXvrnP/8ZDRs2jNmzZ2eeoggHs7POOiuys7NjypQpez3P888/HyeddFK8++67ceihh5ZidQDpt2LFimjSpEnMnz8/OnToUN7lFOPcHQ4MbjkEyt3NN98cvXr1ioKCgnjyySfj17/+dUyYMKG8y2I3nnnmmVi3bl20bds2Vq1aFVdffXU0btw4unXrVt6lQanaunVr/OMf/4iXXnopLr744r2aZ9OmTfHhhx/GyJEj44wzzhBmAQDsB0a5A8rdK6+8Er169Yq2bdvGnXfeGb/61a/iggsuKO+y2I0tW7bET37yk2jTpk2cdtppUadOnZgzZ84OTyeDg80bb7wRnTp1ijZt2sQPfvCDvZrn97//fTRq1CjWrFkTY8eOLeUKAQD+O7jlEA4ALlsGAIB0cO4OBwZXaAEAAACQKgItOIC4YBIAAA5sztnhwCDQggPAtnGHNmzYUM6VAAAAu7PtnN3YoVC+POUQDgDZ2dlRo0aNWL16dUREVK5cObKyssq5KgAAYJskSWLDhg2xevXqqFGjRmRnZ5d3SfBfzaDwcIBIkiTef//9WLNmTXmXAgAA7EKNGjWiXr16/gAN5UygBQeYwsLC2LJlS3mXAQAAfEGlSpVcmQUHCIEWAAAAAKliUHgAAAAAUkWgBQAAAECqCLQAAAAASBWBFgAAAACpItACAAAAIFUEWgAAAACkikALAAAAgFT5fwd+S0149cTDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"I don't no fr y hes sooo sad.\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted emotions for '{sample_text}': {predictions}\")\n",
    "\n",
    "predictions_array = predictions.squeeze()  # Remove unnecessary dimensions\n",
    "\n",
    "\n",
    "emotion_moodtags = []\n",
    "for items in predictions_array:\n",
    "    emotion_moodtags.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=emotion_moodtags, theta=EMOTION_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "# fig = px.line_polar(pd.DataFrame(dict(r=emotion_moodtags, theta=EMOTION_LABELS)), r='r', theta='theta', line_close=True)\n",
    "# fig.show()\n",
    "\n",
    "    \n",
    "# Since predictions are probabilistic values, normalize to ensure they sum up to 1\n",
    "normalized_predictions = predictions_array / predictions_array.sum()  # Normalize the values\n",
    "\n",
    "## Horizontal Stacked Bar Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=EMOTION_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(EMOTION_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Emotion Prediction Distribution')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16153def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:49.261572Z",
     "iopub.status.busy": "2024-08-29T23:56:49.261217Z",
     "iopub.status.idle": "2024-08-29T23:56:49.265395Z",
     "shell.execute_reply": "2024-08-29T23:56:49.264487Z"
    },
    "papermill": {
     "duration": 0.065029,
     "end_time": "2024-08-29T23:56:49.267306",
     "exception": false,
     "start_time": "2024-08-29T23:56:49.202277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# sample_text = \"hey! hru, wanna ply valo toni8?\"\n",
    "# predictions = predict(sample_text, best_model, tokenizer, max_len=128, device=device)\n",
    "# print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f9dcd40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:49.370277Z",
     "iopub.status.busy": "2024-08-29T23:56:49.369951Z",
     "iopub.status.idle": "2024-08-29T23:56:49.373824Z",
     "shell.execute_reply": "2024-08-29T23:56:49.373057Z"
    },
    "papermill": {
     "duration": 0.057283,
     "end_time": "2024-08-29T23:56:49.375631",
     "exception": false,
     "start_time": "2024-08-29T23:56:49.318348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# sample_text = \"hey! hru, wanna ply valo toni8?\"\n",
    "# predictions = predict(sample_text, best_model, tokenizer, max_len=128, device=device)\n",
    "# print(f\"Predictions: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bbbdc303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T23:56:49.479710Z",
     "iopub.status.busy": "2024-08-29T23:56:49.479407Z",
     "iopub.status.idle": "2024-08-29T23:56:49.483275Z",
     "shell.execute_reply": "2024-08-29T23:56:49.482455Z"
    },
    "papermill": {
     "duration": 0.057927,
     "end_time": "2024-08-29T23:56:49.485045",
     "exception": false,
     "start_time": "2024-08-29T23:56:49.427118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample_text = \"hey! hru, wanna ply valo toni8?\"\n",
    "# best_model = RoBERTaEmotionModel('roberta-base').to(device)\n",
    "# best_model.load_state_dict(torch.load(\"best_model.pth\"))  # Assuming best model is saved during training\n",
    "# predicted_emotions = predict_emotions(best_model, sample_text, tokenizer, best_params['max_len'], device)\n",
    "# print(predicted_emotions)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5557640,
     "sourceId": 9273793,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20693.934115,
   "end_time": "2024-08-29T23:56:54.856383",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-29T18:12:00.922268",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "176485dc6a5240b59c95bac62c9727ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_af698b74db70471bb66ff560037a9154",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ea23c2373d4f4db49094bff5129890c1",
       "value": 579.0
      }
     },
     "1eb5793c3a5e4f46b93c0afadeaee671": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2048ec22b7574822be457d8f57f28986": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4013bfcf759c4d20bfea2dcab0e005a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "465bc173fd7b4bf9872bd15dd8031d51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "680171b805da41b09d2fec22a2848791": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6c883df953a4468db2fc82ea602fa5e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6cc76854731b48d999c03e09e32f42f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76a6867d070e4f9eadf8bfc22ca04c4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77c07c0513b147f4bcd3a6c8e56a77cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77cc1a243a644fb782cc784af7338edb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cc77c0316a664b8386d3aecc07c4e12a",
        "IPY_MODEL_99a8164ff2f34998985b38147a809d8f",
        "IPY_MODEL_9fa628142a164ed4bcf0d0b0fcd9062c"
       ],
       "layout": "IPY_MODEL_dc77f3a467994045be739daff4e68c39"
      }
     },
     "78bb0698cb7f4ea2a09fb808c9ef25fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_77c07c0513b147f4bcd3a6c8e56a77cc",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_680171b805da41b09d2fec22a2848791",
       "value": 52.0
      }
     },
     "8dbd67ecc0b945a8b106dbacec0524bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_abc1ed8c76414145a22c3b262b0f0118",
        "IPY_MODEL_176485dc6a5240b59c95bac62c9727ba",
        "IPY_MODEL_e80bdd12841245cdae7f456a517d8225"
       ],
       "layout": "IPY_MODEL_d8ac0b0260314405b20724f5517f4f8b"
      }
     },
     "93d5b8fc863941498df7937ff1c02e60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "99a8164ff2f34998985b38147a809d8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6cc76854731b48d999c03e09e32f42f8",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c3eb270c7c7e4c5e909b123fecf801a3",
       "value": 2464616.0
      }
     },
     "9a6401cf91704110acd02ddc4ca4fe4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2048ec22b7574822be457d8f57f28986",
       "placeholder": "​",
       "style": "IPY_MODEL_b3a5040a43c34709bad9ab3446723f5c",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "9fa628142a164ed4bcf0d0b0fcd9062c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_76a6867d070e4f9eadf8bfc22ca04c4c",
       "placeholder": "​",
       "style": "IPY_MODEL_d905c4a6922340ef8031bf538c6154ea",
       "value": " 2.46M/2.46M [00:00&lt;00:00, 36.3MB/s]"
      }
     },
     "a67eaf6295fe40828e8f2677510ffbaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9a6401cf91704110acd02ddc4ca4fe4d",
        "IPY_MODEL_78bb0698cb7f4ea2a09fb808c9ef25fb",
        "IPY_MODEL_bf55da0c04da424c97934860d4b5ed4f"
       ],
       "layout": "IPY_MODEL_465bc173fd7b4bf9872bd15dd8031d51"
      }
     },
     "abc1ed8c76414145a22c3b262b0f0118": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d1caf95a748248ec98a28d6c1ecfaa68",
       "placeholder": "​",
       "style": "IPY_MODEL_93d5b8fc863941498df7937ff1c02e60",
       "value": "config.json: 100%"
      }
     },
     "af698b74db70471bb66ff560037a9154": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3a5040a43c34709bad9ab3446723f5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b82dd0a3679540f2bd7ee2acef902920": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf55da0c04da424c97934860d4b5ed4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c7ff83ae7e0344bfb188f36cfed075bf",
       "placeholder": "​",
       "style": "IPY_MODEL_6c883df953a4468db2fc82ea602fa5e3",
       "value": " 52.0/52.0 [00:00&lt;00:00, 4.16kB/s]"
      }
     },
     "c3eb270c7c7e4c5e909b123fecf801a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c7ff83ae7e0344bfb188f36cfed075bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc77c0316a664b8386d3aecc07c4e12a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1eb5793c3a5e4f46b93c0afadeaee671",
       "placeholder": "​",
       "style": "IPY_MODEL_e45a5ea2bcba4dd193fb782aaed0beac",
       "value": "spm.model: 100%"
      }
     },
     "d1caf95a748248ec98a28d6c1ecfaa68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8ac0b0260314405b20724f5517f4f8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d905c4a6922340ef8031bf538c6154ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dc77f3a467994045be739daff4e68c39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e45a5ea2bcba4dd193fb782aaed0beac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e80bdd12841245cdae7f456a517d8225": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b82dd0a3679540f2bd7ee2acef902920",
       "placeholder": "​",
       "style": "IPY_MODEL_4013bfcf759c4d20bfea2dcab0e005a8",
       "value": " 579/579 [00:00&lt;00:00, 34.1kB/s]"
      }
     },
     "ea23c2373d4f4db49094bff5129890c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
