{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97abeb0c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:17.220387Z",
     "iopub.status.busy": "2024-11-28T19:48:17.219524Z",
     "iopub.status.idle": "2024-11-28T19:48:18.017095Z",
     "shell.execute_reply": "2024-11-28T19:48:18.016173Z"
    },
    "papermill": {
     "duration": 0.816672,
     "end_time": "2024-11-28T19:48:18.018948",
     "exception": false,
     "start_time": "2024-11-28T19:48:17.202276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/Tachygraphy_EmotionMoodtags_Dataset.csv\n",
      "/kaggle/input/Tachygraphy_dataset_main.csv\n",
      "/kaggle/input/Tachygraphy_MicroText-AIO-V2.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3425032",
   "metadata": {
    "papermill": {
     "duration": 0.014481,
     "end_time": "2024-11-28T19:48:18.048376",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.033895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET & PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0066ec47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.078928Z",
     "iopub.status.busy": "2024-11-28T19:48:18.078537Z",
     "iopub.status.idle": "2024-11-28T19:48:18.288256Z",
     "shell.execute_reply": "2024-11-28T19:48:18.287384Z"
    },
    "papermill": {
     "duration": 0.226845,
     "end_time": "2024-11-28T19:48:18.290133",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.063288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For emoji cleaning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "'''For emoji cleaning'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baedb1db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.320887Z",
     "iopub.status.busy": "2024-11-28T19:48:18.320511Z",
     "iopub.status.idle": "2024-11-28T19:48:18.355353Z",
     "shell.execute_reply": "2024-11-28T19:48:18.354692Z"
    },
    "papermill": {
     "duration": 0.052026,
     "end_time": "2024-11-28T19:48:18.357082",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.305056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('/kaggle/input/dataset-tachygraphy/Tachygraphy_dataset_main.csv')\n",
    "dataset = pd.read_csv('/kaggle/input/Tachygraphy_dataset_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f139e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.388654Z",
     "iopub.status.busy": "2024-11-28T19:48:18.388374Z",
     "iopub.status.idle": "2024-11-28T19:48:18.391845Z",
     "shell.execute_reply": "2024-11-28T19:48:18.391206Z"
    },
    "papermill": {
     "duration": 0.021074,
     "end_time": "2024-11-28T19:48:18.393327",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.372253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d57e82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.423511Z",
     "iopub.status.busy": "2024-11-28T19:48:18.423258Z",
     "iopub.status.idle": "2024-11-28T19:48:18.431162Z",
     "shell.execute_reply": "2024-11-28T19:48:18.430255Z"
    },
    "papermill": {
     "duration": 0.025075,
     "end_time": "2024-11-28T19:48:18.432891",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.407816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text         1\n",
      "Meaning      1\n",
      "Sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ce4495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.463526Z",
     "iopub.status.busy": "2024-11-28T19:48:18.463283Z",
     "iopub.status.idle": "2024-11-28T19:48:18.483823Z",
     "shell.execute_reply": "2024-11-28T19:48:18.483091Z"
    },
    "papermill": {
     "duration": 0.037713,
     "end_time": "2024-11-28T19:48:18.485441",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.447728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
    "                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n",
    "                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n",
    "                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n",
    "                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
    "                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
    "                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n",
    "                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
    "                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n",
    "                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
    "                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n",
    "\n",
    "punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n",
    "                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n",
    "                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '}\n",
    "\n",
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n",
    "                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n",
    "                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n",
    "                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n",
    "                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n",
    "                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n",
    "                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n",
    "                'demonetisation': 'demonetization'}\n",
    "\n",
    "def clean_text(text):\n",
    "    '''Clean emoji, Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "#     text = emoji.demojize(text)\n",
    "#     text = re.sub(r'\\:(.*?)\\:','',text)\n",
    "#     text = str(text).lower()    #Making Text Lowercase\n",
    "#     text = re.sub('\\[.*?\\]', '', text)\n",
    "    #The next 2 lines remove html text\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "#     text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # replacing everything with space except (a-z, A-Z, 0-9, \"%\", \".\", \"&\", \",\", \"'\", \"?\", \"!\", \",\", \"'\", \";\", \"-\")\n",
    "    text = re.sub(r\"[^a-zA-Z0-9?.!,¿'%&,';-]+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    '''Clean contraction using contraction mapping'''    \n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    for word in mapping.keys():\n",
    "        if \"\"+word+\"\" in text:\n",
    "            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n",
    "    #Remove Punctuations\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    '''Cleans special characters present(if any)'''   \n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def correct_spelling(x, dic):\n",
    "    '''Corrects common spelling errors'''   \n",
    "    for word in dic.keys():\n",
    "        x = x.replace(word, dic[word])\n",
    "    return x\n",
    "\n",
    "def remove_space(text):\n",
    "    '''Removes awkward spaces'''   \n",
    "    #Removes awkward spaces \n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)\n",
    "\n",
    "def text_preprocessing_pipeline(text):\n",
    "    '''Cleaning and parsing the text.'''\n",
    "#     text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_text(text)\n",
    "#     text = clean_contractions(text, contraction_mapping)\n",
    "#     text = clean_special_chars(text, punct, punct_mapping)\n",
    "#     text = correct_spelling(text, mispell_dict)\n",
    "    text = remove_space(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61033a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.515229Z",
     "iopub.status.busy": "2024-11-28T19:48:18.514950Z",
     "iopub.status.idle": "2024-11-28T19:48:18.523863Z",
     "shell.execute_reply": "2024-11-28T19:48:18.523232Z"
    },
    "papermill": {
     "duration": 0.025695,
     "end_time": "2024-11-28T19:48:18.525552",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.499857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Text':'text', 'Sentiment':'sentiment_polarity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d91f15fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.555368Z",
     "iopub.status.busy": "2024-11-28T19:48:18.555112Z",
     "iopub.status.idle": "2024-11-28T19:48:18.563073Z",
     "shell.execute_reply": "2024-11-28T19:48:18.562270Z"
    },
    "papermill": {
     "duration": 0.024596,
     "end_time": "2024-11-28T19:48:18.564578",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.539982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Meaning'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5862f9db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.594874Z",
     "iopub.status.busy": "2024-11-28T19:48:18.594237Z",
     "iopub.status.idle": "2024-11-28T19:48:18.601326Z",
     "shell.execute_reply": "2024-11-28T19:48:18.600758Z"
    },
    "papermill": {
     "duration": 0.023835,
     "end_time": "2024-11-28T19:48:18.602977",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.579142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['text', 'sentiment_polarity'], inplace=True) # Dropping NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f5194b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.634103Z",
     "iopub.status.busy": "2024-11-28T19:48:18.633840Z",
     "iopub.status.idle": "2024-11-28T19:48:18.650879Z",
     "shell.execute_reply": "2024-11-28T19:48:18.649904Z"
    },
    "papermill": {
     "duration": 0.033842,
     "end_time": "2024-11-28T19:48:18.652645",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.618803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4957 entries, 0 to 4957\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   text                4957 non-null   object\n",
      " 1   sentiment_polarity  4957 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 116.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# df['text'] = df['text'].astype('str')\n",
    "# df['sentiment_polarity'] = df['sentiment_polarity'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c17f83d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:18.682937Z",
     "iopub.status.busy": "2024-11-28T19:48:18.682686Z",
     "iopub.status.idle": "2024-11-28T19:48:20.108128Z",
     "shell.execute_reply": "2024-11-28T19:48:20.107365Z"
    },
    "papermill": {
     "duration": 1.442565,
     "end_time": "2024-11-28T19:48:20.110069",
     "exception": false,
     "start_time": "2024-11-28T19:48:18.667504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/603547440.py:51: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, 'lxml').get_text()\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lambda x: text_preprocessing_pipeline(x))\n",
    "df['sentiment_polarity'] = df['sentiment_polarity'].apply(lambda x: text_preprocessing_pipeline(x))\n",
    "df['sentiment_polarity'] = df['sentiment_polarity'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "798aba65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.141483Z",
     "iopub.status.busy": "2024-11-28T19:48:20.141228Z",
     "iopub.status.idle": "2024-11-28T19:48:20.153393Z",
     "shell.execute_reply": "2024-11-28T19:48:20.152630Z"
    },
    "papermill": {
     "duration": 0.02968,
     "end_time": "2024-11-28T19:48:20.154995",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.125315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting precisely -- ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report ASAP!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The OGs - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>make a pet face . wtf wrong with me tonight haha</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>I dnt care anymore ... Boyz ain't worth d dram...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>No relationship is perfect tho me bae goo from...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>Over here tryna get my nail polishes and shit lol</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>No one was loved d way i luv U</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment_polarity\n",
       "0                               Last session of the day            neutral\n",
       "1     Shanghai is also really exciting precisely -- ...           positive\n",
       "2                               submit the report ASAP!           negative\n",
       "3                                           happy bday!           positive\n",
       "4                                 The OGs - I like it!!           positive\n",
       "...                                                 ...                ...\n",
       "4953   make a pet face . wtf wrong with me tonight haha           negative\n",
       "4954  I dnt care anymore ... Boyz ain't worth d dram...           negative\n",
       "4955  No relationship is perfect tho me bae goo from...           negative\n",
       "4956  Over here tryna get my nail polishes and shit lol           negative\n",
       "4957                     No one was loved d way i luv U           positive\n",
       "\n",
       "[4957 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b2eafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.186874Z",
     "iopub.status.busy": "2024-11-28T19:48:20.186220Z",
     "iopub.status.idle": "2024-11-28T19:48:20.194568Z",
     "shell.execute_reply": "2024-11-28T19:48:20.193957Z"
    },
    "papermill": {
     "duration": 0.025886,
     "end_time": "2024-11-28T19:48:20.196113",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.170227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_polar = pd.get_dummies(df['sentiment_polarity'], prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaeab5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.227331Z",
     "iopub.status.busy": "2024-11-28T19:48:20.227088Z",
     "iopub.status.idle": "2024-11-28T19:48:20.230867Z",
     "shell.execute_reply": "2024-11-28T19:48:20.230082Z"
    },
    "papermill": {
     "duration": 0.02111,
     "end_time": "2024-11-28T19:48:20.232418",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.211308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_polar = bin_polar.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f11117fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.264236Z",
     "iopub.status.busy": "2024-11-28T19:48:20.263944Z",
     "iopub.status.idle": "2024-11-28T19:48:20.273521Z",
     "shell.execute_reply": "2024-11-28T19:48:20.272664Z"
    },
    "papermill": {
     "duration": 0.026659,
     "end_time": "2024-11-28T19:48:20.274956",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.248297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      negative  neutral  positive\n",
       "0            0        1         0\n",
       "1            0        0         1\n",
       "2            1        0         0\n",
       "3            0        0         1\n",
       "4            0        0         1\n",
       "...        ...      ...       ...\n",
       "4953         1        0         0\n",
       "4954         1        0         0\n",
       "4955         1        0         0\n",
       "4956         1        0         0\n",
       "4957         0        0         1\n",
       "\n",
       "[4957 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9845a49d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.305872Z",
     "iopub.status.busy": "2024-11-28T19:48:20.305612Z",
     "iopub.status.idle": "2024-11-28T19:48:20.315221Z",
     "shell.execute_reply": "2024-11-28T19:48:20.314399Z"
    },
    "papermill": {
     "duration": 0.027143,
     "end_time": "2024-11-28T19:48:20.316967",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.289824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting precisely -- ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report ASAP!</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The OGs - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            Last session of the day            neutral   \n",
       "1  Shanghai is also really exciting precisely -- ...           positive   \n",
       "2                            submit the report ASAP!           negative   \n",
       "3                                        happy bday!           positive   \n",
       "4                              The OGs - I like it!!           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, bin_polar], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a85b23bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.386100Z",
     "iopub.status.busy": "2024-11-28T19:48:20.385774Z",
     "iopub.status.idle": "2024-11-28T19:48:20.394590Z",
     "shell.execute_reply": "2024-11-28T19:48:20.393788Z"
    },
    "papermill": {
     "duration": 0.026749,
     "end_time": "2024-11-28T19:48:20.396240",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.369491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting precisely -- ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report ASAP!</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The OGs - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            Last session of the day            neutral   \n",
       "1  Shanghai is also really exciting precisely -- ...           positive   \n",
       "2                            submit the report ASAP!           negative   \n",
       "3                                        happy bday!           positive   \n",
       "4                              The OGs - I like it!!           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop(columns=['sentiment_polarity'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6241f358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.427700Z",
     "iopub.status.busy": "2024-11-28T19:48:20.427450Z",
     "iopub.status.idle": "2024-11-28T19:48:20.436476Z",
     "shell.execute_reply": "2024-11-28T19:48:20.435653Z"
    },
    "papermill": {
     "duration": 0.026891,
     "end_time": "2024-11-28T19:48:20.438416",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.411525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4957 entries, 0 to 4957\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   text                4957 non-null   object\n",
      " 1   sentiment_polarity  4957 non-null   object\n",
      " 2   negative            4957 non-null   int64 \n",
      " 3   neutral             4957 non-null   int64 \n",
      " 4   positive            4957 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 232.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b228de43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.470468Z",
     "iopub.status.busy": "2024-11-28T19:48:20.469928Z",
     "iopub.status.idle": "2024-11-28T19:48:20.473552Z",
     "shell.execute_reply": "2024-11-28T19:48:20.472779Z"
    },
    "papermill": {
     "duration": 0.021191,
     "end_time": "2024-11-28T19:48:20.475160",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.453969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_polarity_label_mapping = {\n",
    "    0: \"negative\", 1: \"neutral\", 2: \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1de52c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.511136Z",
     "iopub.status.busy": "2024-11-28T19:48:20.510828Z",
     "iopub.status.idle": "2024-11-28T19:48:20.514756Z",
     "shell.execute_reply": "2024-11-28T19:48:20.513955Z"
    },
    "papermill": {
     "duration": 0.02607,
     "end_time": "2024-11-28T19:48:20.516672",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.490602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_polarity_label_mapping_rev = {\n",
    "    'negative': 0, 'neutral': 1, 'positive': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2a89146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.559896Z",
     "iopub.status.busy": "2024-11-28T19:48:20.559617Z",
     "iopub.status.idle": "2024-11-28T19:48:20.563123Z",
     "shell.execute_reply": "2024-11-28T19:48:20.562402Z"
    },
    "papermill": {
     "duration": 0.024436,
     "end_time": "2024-11-28T19:48:20.564800",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.540364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SENTIMENT_POLARITY_LABELS = [\n",
    "    \"negative\", \"neutral\", \"positive\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc9f6ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.596707Z",
     "iopub.status.busy": "2024-11-28T19:48:20.596463Z",
     "iopub.status.idle": "2024-11-28T19:48:20.600275Z",
     "shell.execute_reply": "2024-11-28T19:48:20.599534Z"
    },
    "papermill": {
     "duration": 0.021474,
     "end_time": "2024-11-28T19:48:20.601774",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.580300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_train_split(dataset, test_ratio=0.1):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92440fac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.634214Z",
     "iopub.status.busy": "2024-11-28T19:48:20.633858Z",
     "iopub.status.idle": "2024-11-28T19:48:20.642201Z",
     "shell.execute_reply": "2024-11-28T19:48:20.641182Z"
    },
    "papermill": {
     "duration": 0.027088,
     "end_time": "2024-11-28T19:48:20.644517",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.617429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4462 examples in training, 495 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "train_ds_pd, validation_ds_pd = test_train_split(df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_ds_pd), len(validation_ds_pd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4e66771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.698928Z",
     "iopub.status.busy": "2024-11-28T19:48:20.698398Z",
     "iopub.status.idle": "2024-11-28T19:48:20.704728Z",
     "shell.execute_reply": "2024-11-28T19:48:20.704031Z"
    },
    "papermill": {
     "duration": 0.036362,
     "end_time": "2024-11-28T19:48:20.706463",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.670101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd = train_ds_pd.reset_index(drop=True)\n",
    "validation_ds_pd = validation_ds_pd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "650ee9d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.754477Z",
     "iopub.status.busy": "2024-11-28T19:48:20.754207Z",
     "iopub.status.idle": "2024-11-28T19:48:20.764302Z",
     "shell.execute_reply": "2024-11-28T19:48:20.763475Z"
    },
    "papermill": {
     "duration": 0.031447,
     "end_time": "2024-11-28T19:48:20.765846",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.734399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting precisely -- ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report ASAP!</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The OGs - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            Last session of the day            neutral   \n",
       "1  Shanghai is also really exciting precisely -- ...           positive   \n",
       "2                            submit the report ASAP!           negative   \n",
       "3                                        happy bday!           positive   \n",
       "4                              The OGs - I like it!!           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "308713aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.798927Z",
     "iopub.status.busy": "2024-11-28T19:48:20.798301Z",
     "iopub.status.idle": "2024-11-28T19:48:20.803692Z",
     "shell.execute_reply": "2024-11-28T19:48:20.802893Z"
    },
    "papermill": {
     "duration": 0.023321,
     "end_time": "2024-11-28T19:48:20.805234",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.781913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative', ..., 'negative', 'negative',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_labels = np.array(train_ds_pd['sentiment_polarity'])\n",
    "sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8629ffdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.838572Z",
     "iopub.status.busy": "2024-11-28T19:48:20.837955Z",
     "iopub.status.idle": "2024-11-28T19:48:20.845179Z",
     "shell.execute_reply": "2024-11-28T19:48:20.844250Z"
    },
    "papermill": {
     "duration": 0.026007,
     "end_time": "2024-11-28T19:48:20.846924",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.820917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd.drop(columns=['sentiment_polarity'], inplace=True)\n",
    "validation_ds_pd.drop(columns=['sentiment_polarity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7facfd05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.884329Z",
     "iopub.status.busy": "2024-11-28T19:48:20.884063Z",
     "iopub.status.idle": "2024-11-28T19:48:20.891805Z",
     "shell.execute_reply": "2024-11-28T19:48:20.890973Z"
    },
    "papermill": {
     "duration": 0.028935,
     "end_time": "2024-11-28T19:48:20.893498",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.864563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last session of the day</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shanghai is also really exciting precisely -- ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report ASAP!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The OGs - I like it!!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  neutral  \\\n",
       "0                            Last session of the day         0        1   \n",
       "1  Shanghai is also really exciting precisely -- ...         0        0   \n",
       "2                            submit the report ASAP!         1        0   \n",
       "3                                        happy bday!         0        0   \n",
       "4                              The OGs - I like it!!         0        0   \n",
       "\n",
       "   positive  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26cb2fd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.926313Z",
     "iopub.status.busy": "2024-11-28T19:48:20.926060Z",
     "iopub.status.idle": "2024-11-28T19:48:20.933570Z",
     "shell.execute_reply": "2024-11-28T19:48:20.932778Z"
    },
    "papermill": {
     "duration": 0.025497,
     "end_time": "2024-11-28T19:48:20.935195",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.909698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>about to go to sleep</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hope ur havin fun in da club</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ll oscillate from one to the other.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You seem nice, you re generous and you know yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TGIF...I think I broke my toe last night - on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  neutral  \\\n",
       "0                               about to go to sleep         0        1   \n",
       "1                       Hope ur havin fun in da club         0        0   \n",
       "2              I ll oscillate from one to the other.         0        1   \n",
       "3  You seem nice, you re generous and you know yo...         0        0   \n",
       "4  TGIF...I think I broke my toe last night - on ...         0        1   \n",
       "\n",
       "   positive  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dc2f503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:20.969402Z",
     "iopub.status.busy": "2024-11-28T19:48:20.969045Z",
     "iopub.status.idle": "2024-11-28T19:48:20.977139Z",
     "shell.execute_reply": "2024-11-28T19:48:20.975988Z"
    },
    "papermill": {
     "duration": 0.028269,
     "end_time": "2024-11-28T19:48:20.979326",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.951057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_indexed_labels = np.array([sentiment_polarity_label_mapping_rev[label] for label in sentiment_labels])\n",
    "sentiment_indexed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7a74406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:21.017230Z",
     "iopub.status.busy": "2024-11-28T19:48:21.016475Z",
     "iopub.status.idle": "2024-11-28T19:48:24.530732Z",
     "shell.execute_reply": "2024-11-28T19:48:24.529812Z"
    },
    "papermill": {
     "duration": 3.533975,
     "end_time": "2024-11-28T19:48:24.532858",
     "exception": false,
     "start_time": "2024-11-28T19:48:20.998883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18754cb",
   "metadata": {
    "papermill": {
     "duration": 0.015767,
     "end_time": "2024-11-28T19:48:24.566238",
     "exception": false,
     "start_time": "2024-11-28T19:48:24.550471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Calculating Class Weights for each labels to avoid imbalanced distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "206ae64c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:24.600004Z",
     "iopub.status.busy": "2024-11-28T19:48:24.599265Z",
     "iopub.status.idle": "2024-11-28T19:48:24.699096Z",
     "shell.execute_reply": "2024-11-28T19:48:24.698237Z"
    },
    "papermill": {
     "duration": 0.118724,
     "end_time": "2024-11-28T19:48:24.700895",
     "exception": false,
     "start_time": "2024-11-28T19:48:24.582171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3498, 0.3165, 0.3337])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = np.bincount(sentiment_indexed_labels)\n",
    "total_samples = len(sentiment_labels)\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a232b3",
   "metadata": {
    "papermill": {
     "duration": 0.015888,
     "end_time": "2024-11-28T19:48:24.733519",
     "exception": false,
     "start_time": "2024-11-28T19:48:24.717631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class Weight NOTE\n",
    "### This class weights are for the training dataset and are to be used while training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17378b3",
   "metadata": {
    "papermill": {
     "duration": 0.016352,
     "end_time": "2024-11-28T19:48:24.765900",
     "exception": false,
     "start_time": "2024-11-28T19:48:24.749548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SETTING CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6f482ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:24.799382Z",
     "iopub.status.busy": "2024-11-28T19:48:24.799074Z",
     "iopub.status.idle": "2024-11-28T19:48:24.886021Z",
     "shell.execute_reply": "2024-11-28T19:48:24.885271Z"
    },
    "papermill": {
     "duration": 0.105544,
     "end_time": "2024-11-28T19:48:24.887578",
     "exception": false,
     "start_time": "2024-11-28T19:48:24.782034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1637b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:24.921452Z",
     "iopub.status.busy": "2024-11-28T19:48:24.921142Z",
     "iopub.status.idle": "2024-11-28T19:48:27.070390Z",
     "shell.execute_reply": "2024-11-28T19:48:27.069667Z"
    },
    "papermill": {
     "duration": 2.168174,
     "end_time": "2024-11-28T19:48:27.072324",
     "exception": false,
     "start_time": "2024-11-28T19:48:24.904150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import DebertaV2Model, DebertaV2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "222681e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:27.106415Z",
     "iopub.status.busy": "2024-11-28T19:48:27.105946Z",
     "iopub.status.idle": "2024-11-28T19:48:28.630291Z",
     "shell.execute_reply": "2024-11-28T19:48:28.629405Z"
    },
    "papermill": {
     "duration": 1.543175,
     "end_time": "2024-11-28T19:48:28.632124",
     "exception": false,
     "start_time": "2024-11-28T19:48:27.088949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf1693296a14ff788aa6a8929fcef52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cd943fbaaa4f87b0e3c2b565f423aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d265b14e6dc844e795619b440ae9aa77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8610b",
   "metadata": {
    "papermill": {
     "duration": 0.016308,
     "end_time": "2024-11-28T19:48:28.665599",
     "exception": false,
     "start_time": "2024-11-28T19:48:28.649291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TORCH IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "556e6a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:28.699913Z",
     "iopub.status.busy": "2024-11-28T19:48:28.699602Z",
     "iopub.status.idle": "2024-11-28T19:48:44.398978Z",
     "shell.execute_reply": "2024-11-28T19:48:44.398272Z"
    },
    "papermill": {
     "duration": 15.718772,
     "end_time": "2024-11-28T19:48:44.400911",
     "exception": false,
     "start_time": "2024-11-28T19:48:28.682139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 19:48:30,785\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-11-28 19:48:31,292\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "# from optuna.integration import PyTorchLightningPruner\n",
    "from ray import tune\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from ray.tune.integration.pytorch import TuneReportCallback\n",
    "from torch.amp import GradScaler, autocast\n",
    "# from ray.tune.integration.optuna import OptunaSearch\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from torch import autocast\n",
    "# from ray import tune\n",
    "# from ray.tune.integration.tensorboard import TensorBoardReporter\n",
    "from ray.tune.logger import TBXLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ray.train import report\n",
    "# from ray.tune.integration.jupyter import JupyterNotebookReporter\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from ray.tune.schedulers import HyperBandScheduler, AsyncHyperBandScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26419380",
   "metadata": {
    "papermill": {
     "duration": 0.016938,
     "end_time": "2024-11-28T19:48:44.435552",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.418614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET CONFIG & ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7017ffb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:44.471166Z",
     "iopub.status.busy": "2024-11-28T19:48:44.469999Z",
     "iopub.status.idle": "2024-11-28T19:48:44.476971Z",
     "shell.execute_reply": "2024-11-28T19:48:44.476255Z"
    },
    "papermill": {
     "duration": 0.026199,
     "end_time": "2024-11-28T19:48:44.478546",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.452347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         text = self.data.iloc[index, 0]\n",
    "#         labels = self.data.iloc[index, 1:].values.astype(float)\n",
    "        text = str(self.data.iloc[index]['text'])\n",
    "        labels = self.data.iloc[index][['negative', 'neutral', 'positive']].values.astype(np.float32)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de2334",
   "metadata": {
    "papermill": {
     "duration": 0.016328,
     "end_time": "2024-11-28T19:48:44.511387",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.495059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8454da66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:44.545705Z",
     "iopub.status.busy": "2024-11-28T19:48:44.545452Z",
     "iopub.status.idle": "2024-11-28T19:48:44.550808Z",
     "shell.execute_reply": "2024-11-28T19:48:44.550082Z"
    },
    "papermill": {
     "duration": 0.024428,
     "end_time": "2024-11-28T19:48:44.552395",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.527967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.roberta = roberta_model\n",
    "        self.drop = nn.Dropout(p=dropout_rate)\n",
    "        self.fc1 = nn.Linear(self.roberta.config.hidden_size, 256)  # Reduced neurons\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(256, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get the RoBERTa output\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token_state = output.last_hidden_state[:, 0, :]\n",
    "        # Pass through the custom layers\n",
    "        output = self.drop(cls_token_state)\n",
    "        output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9522995",
   "metadata": {
    "papermill": {
     "duration": 0.016296,
     "end_time": "2024-11-28T19:48:44.585164",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.568868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Other Models to try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1c55ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:44.620813Z",
     "iopub.status.busy": "2024-11-28T19:48:44.620560Z",
     "iopub.status.idle": "2024-11-28T19:48:44.624589Z",
     "shell.execute_reply": "2024-11-28T19:48:44.623906Z"
    },
    "papermill": {
     "duration": 0.022975,
     "end_time": "2024-11-28T19:48:44.626065",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.603090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class SentimentModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(SentimentModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size, 512)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.out = nn.Linear(256, n_classes)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         # Get the RoBERTa output\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         cls_token_state = output.last_hidden_state[:, 0, :]\n",
    "#         # Pass through the custom layers\n",
    "#         output = self.drop(cls_token_state)\n",
    "# #         output = cls_token_state\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "# #         output = self.drop(output)\n",
    "#         return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cb7e802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:44.660673Z",
     "iopub.status.busy": "2024-11-28T19:48:44.660393Z",
     "iopub.status.idle": "2024-11-28T19:48:44.663900Z",
     "shell.execute_reply": "2024-11-28T19:48:44.663186Z"
    },
    "papermill": {
     "duration": 0.022848,
     "end_time": "2024-11-28T19:48:44.665442",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.642594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AdvancedPooling(nn.Module):\n",
    "#     def __init__(self, hidden_size):\n",
    "#         super(AdvancedPooling, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#     def forward(self, hidden_states):\n",
    "#         cls_output = hidden_states[:, 0, :]  # [CLS] token output\n",
    "#         mean_output = hidden_states.mean(dim=1)  # Mean pooling over sequence\n",
    "#         max_output, _ = hidden_states.max(dim=1)  # Max pooling over sequence\n",
    "#         combined_output = torch.cat([cls_output, mean_output, max_output], dim=1)\n",
    "#         return combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5efedd43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:44.699487Z",
     "iopub.status.busy": "2024-11-28T19:48:44.699220Z",
     "iopub.status.idle": "2024-11-28T19:48:44.703123Z",
     "shell.execute_reply": "2024-11-28T19:48:44.702462Z"
    },
    "papermill": {
     "duration": 0.022837,
     "end_time": "2024-11-28T19:48:44.704576",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.681739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class SentimentModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(SentimentModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size * 3, 512)\n",
    "#         self.attention_pooling = AdvancedPooling(hidden_size=self.roberta.config.hidden_size)\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.out = nn.Linear(256, n_classes)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         cls_output = output.last_hidden_state[:, 0, :]  # Extract [CLS] token representation\n",
    "#         hidden_states = output.last_hidden_state  # Sequence hidden states\n",
    "#         pooled_output = self.attention_pooling(hidden_states)  # Attention pooling  # Combine CLS and attention pooling\n",
    "#         output = self.drop(pooled_output)\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "#         output = self.drop(output)\n",
    "#         return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40821e0",
   "metadata": {
    "papermill": {
     "duration": 0.016297,
     "end_time": "2024-11-28T19:48:44.737301",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.721004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRAIN & VALIDATION\n",
    "### Custom metric is a metric for determining the best model free from any overfitting, underfitting. ```custom_metric = (avg_val_loss−val_accuracy) + α × ∣avg_train_loss−avg_val_loss∣ + β × ∣val_accuracy-train_accuracy∣``` This metric balances between low validation loss, high validation accuracy, and penalizing large discrepancies between training and validation loss. Note that, in the model selection we have used ```α = β = 0.5```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc94c9cb",
   "metadata": {
    "papermill": {
     "duration": 0.01646,
     "end_time": "2024-11-28T19:48:44.770495",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.754035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### But, if we have probabilistic values as input and output we cannot directly calculate the accuracy, infact we need to rely on loss only. ```custom_metric = avg_val_loss + α × ∣avg_train_loss−avg_val_loss∣```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b619d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:44.804753Z",
     "iopub.status.busy": "2024-11-28T19:48:44.804450Z",
     "iopub.status.idle": "2024-11-28T19:48:44.808729Z",
     "shell.execute_reply": "2024-11-28T19:48:44.808066Z"
    },
    "papermill": {
     "duration": 0.023127,
     "end_time": "2024-11-28T19:48:44.810222",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.787095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom metric calculation function\n",
    "def calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy, alpha=0.5, beta=0.5):\n",
    "    loss_diff = abs(avg_train_loss - avg_val_loss)\n",
    "    accuracy_diff = abs(train_accuracy - val_accuracy)\n",
    "    custom_metric = avg_val_loss - val_accuracy + alpha * loss_diff + beta * accuracy_diff\n",
    "    return custom_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220602ee",
   "metadata": {
    "papermill": {
     "duration": 0.016244,
     "end_time": "2024-11-28T19:48:44.842955",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.826711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4926280c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:44.877270Z",
     "iopub.status.busy": "2024-11-28T19:48:44.876988Z",
     "iopub.status.idle": "2024-11-28T19:48:44.882409Z",
     "shell.execute_reply": "2024-11-28T19:48:44.881553Z"
    },
    "papermill": {
     "duration": 0.024404,
     "end_time": "2024-11-28T19:48:44.883936",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.859532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        EarlyStopping to stop training when a metric has stopped improving.\n",
    "\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "            delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss improved to {val_loss:.4f}')\n",
    "#             torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss did not improve. Patience: {self.patience}, Counter: {self.counter}')\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3120565d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:44.919085Z",
     "iopub.status.busy": "2024-11-28T19:48:44.918818Z",
     "iopub.status.idle": "2024-11-28T19:48:44.935355Z",
     "shell.execute_reply": "2024-11-28T19:48:44.934655Z"
    },
    "papermill": {
     "duration": 0.036235,
     "end_time": "2024-11-28T19:48:44.936869",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.900634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training function with variable parameters\n",
    "def train_model(config, train_dataset, val_dataset, device):\n",
    "#     model = SentimentModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=3,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    \n",
    "    model = SentimentModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=3,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     class_weights_tmp = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weight=class_weights_tmp)\n",
    "#     criterion = nn.BCELoss()\n",
    "    scaler = GradScaler()  # Initialize GradScaler\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):  # Ensure epochs are passed from config\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):  # Mixed precision\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = torch.zeros_like(probabilities)\n",
    "            max_indices = torch.argmax(probabilities, dim=1)\n",
    "            predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "            predictions = predictions.float()\n",
    "                \n",
    "#                 loss = criterion(predictions, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "#             outputs = torch.sigmoid(outputs)  \n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "#             predicted_labels = (outputs > 0.5).float()\n",
    "#             correct_train_preds += (predicted_labels == labels).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "            correct_train_preds += (predictions == labels).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "                \n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predictions = torch.zeros_like(probabilities)\n",
    "                max_indices = torch.argmax(probabilities, dim=1)\n",
    "                predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "                predictions = predictions.float()\n",
    "                \n",
    "#                     loss = criterion(predictions, labels)\n",
    "                    \n",
    "#                 outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "    \n",
    "#                 predicted_labels = (outputs > 0.5).float()\n",
    "#                 correct_val_preds += (predicted_labels == labels).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "                \n",
    "#                 correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "\n",
    "                correct_val_preds += (predictions == labels).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "#         custom_metric = avg_val_loss - val_accuracy\n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "\n",
    "        # Report metrics using ray.train.report\n",
    "        report({\n",
    "            \"loss\": avg_val_loss,\n",
    "            \"accuracy\": val_accuracy,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"custom_metric\": custom_metric,\n",
    "            \"early_stopping_epoch\": epoch + 1,\n",
    "        })\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "#         trial_dir = os.path.join(os.environ[\"TUNE_TRIAL_DIR\"], \"checkpoint.pt\")\n",
    "#         torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "#         checkpoint_path = f\"/kaggle/working/checkpoint_epoch_{epoch}.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_fn(config):\n",
    "    # Load your data here\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "    train_dataset = SentimentDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = SentimentDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(config, train_dataset, val_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0380d",
   "metadata": {
    "papermill": {
     "duration": 0.016371,
     "end_time": "2024-11-28T19:48:44.969859",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.953488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "754d3739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:45.003990Z",
     "iopub.status.busy": "2024-11-28T19:48:45.003713Z",
     "iopub.status.idle": "2024-11-28T19:48:45.008442Z",
     "shell.execute_reply": "2024-11-28T19:48:45.007790Z"
    },
    "papermill": {
     "duration": 0.023492,
     "end_time": "2024-11-28T19:48:45.009974",
     "exception": false,
     "start_time": "2024-11-28T19:48:44.986482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'dropout_rate': tune.choice([0.2, 0.25, 0.27, 0.3, 0.32, 0.35, 0.4]),\n",
    "    'batch_size': tune.choice([32, 64]),\n",
    "    'weight_decay': tune.choice([1e-6, 2e-6, 1e-5, 2e-5, 1e-4, 2e-4, 5e-5, 5e-6, 1e-2, 1e-3]),\n",
    "    'lr': tune.choice([1e-6, 1e-5, 2e-5, 1e-4, 2e-4, 2e-6, 3e-6, 5e-6, 3e-5, 5e-5, 2e-7, 1e-7, 1e-3, 5e-7]),\n",
    "    'epochs': tune.choice([5, 7, 10, 12, 15, 20])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16cf87e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:45.043761Z",
     "iopub.status.busy": "2024-11-28T19:48:45.043509Z",
     "iopub.status.idle": "2024-11-28T19:48:45.046917Z",
     "shell.execute_reply": "2024-11-28T19:48:45.046073Z"
    },
    "papermill": {
     "duration": 0.022196,
     "end_time": "2024-11-28T19:48:45.048574",
     "exception": false,
     "start_time": "2024-11-28T19:48:45.026378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     'dropout_rate': tune.uniform(0.1, 0.5),\n",
    "#     'batch_size': tune.choice([16, 32, 64]),\n",
    "#     'weight_decay': tune.loguniform(1e-6, 1e-1),\n",
    "#     'lr': tune.loguniform(1e-6, 1e-1),\n",
    "#     'epochs': tune.choice([5, 7, 10, 12, 15, 20])\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0841a55e",
   "metadata": {
    "papermill": {
     "duration": 0.016286,
     "end_time": "2024-11-28T19:48:45.081488",
     "exception": false,
     "start_time": "2024-11-28T19:48:45.065202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9abef54a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:45.115916Z",
     "iopub.status.busy": "2024-11-28T19:48:45.115644Z",
     "iopub.status.idle": "2024-11-28T19:48:45.119229Z",
     "shell.execute_reply": "2024-11-28T19:48:45.118593Z"
    },
    "papermill": {
     "duration": 0.022638,
     "end_time": "2024-11-28T19:48:45.120794",
     "exception": false,
     "start_time": "2024-11-28T19:48:45.098156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna_search = OptunaSearch(\n",
    "    metric=\"accuracy\",\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb5305f",
   "metadata": {
    "papermill": {
     "duration": 0.016369,
     "end_time": "2024-11-28T19:48:45.153881",
     "exception": false,
     "start_time": "2024-11-28T19:48:45.137512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SCHEDULER ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecfd9c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:45.188049Z",
     "iopub.status.busy": "2024-11-28T19:48:45.187775Z",
     "iopub.status.idle": "2024-11-28T19:48:45.191646Z",
     "shell.execute_reply": "2024-11-28T19:48:45.190930Z"
    },
    "papermill": {
     "duration": 0.022617,
     "end_time": "2024-11-28T19:48:45.193232",
     "exception": false,
     "start_time": "2024-11-28T19:48:45.170615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric='accuracy',\n",
    "    mode='max',\n",
    "    max_t=22,\n",
    "    grace_period=3,\n",
    "    reduction_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7396f",
   "metadata": {
    "papermill": {
     "duration": 0.016258,
     "end_time": "2024-11-28T19:48:45.226194",
     "exception": false,
     "start_time": "2024-11-28T19:48:45.209936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fd3dca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:45.260258Z",
     "iopub.status.busy": "2024-11-28T19:48:45.259962Z",
     "iopub.status.idle": "2024-11-28T19:48:45.263699Z",
     "shell.execute_reply": "2024-11-28T19:48:45.262963Z"
    },
    "papermill": {
     "duration": 0.022554,
     "end_time": "2024-11-28T19:48:45.265241",
     "exception": false,
     "start_time": "2024-11-28T19:48:45.242687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To ignore warinings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71beb94b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T19:48:45.299937Z",
     "iopub.status.busy": "2024-11-28T19:48:45.299675Z",
     "iopub.status.idle": "2024-11-28T23:14:44.779438Z",
     "shell.execute_reply": "2024-11-28T23:14:44.778649Z"
    },
    "papermill": {
     "duration": 12359.499464,
     "end_time": "2024-11-28T23:14:44.781257",
     "exception": false,
     "start_time": "2024-11-28T19:48:45.281793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-28 23:14:44</td></tr>\n",
       "<tr><td>Running for: </td><td>03:25:46.50        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.1/31.4 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=40<br>Bracket: Iter 12.000: None | Iter 6.000: 0.7885521885521886 | Iter 3.000: 0.7858585858585858<br>Logical resource usage: 2.0/4 CPUs, 1.0/2 GPUs (0.0/1.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  early_stopping_epoch</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_e45616c1</td><td>TERMINATED</td><td>172.19.2.2:341 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.683463</td><td style=\"text-align: right;\">  0.543434</td><td style=\"text-align: right;\">    0.141718   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.685229</td><td style=\"text-align: right;\">        0.545047</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_2da04114</td><td>TERMINATED</td><td>172.19.2.2:376 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.636268</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0690538  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.637284</td><td style=\"text-align: right;\">        0.561034</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_10c0bdbb</td><td>TERMINATED</td><td>172.19.2.2:490 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.636123</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0681172  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.63705 </td><td style=\"text-align: right;\">        0.562528</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_ff2f4463</td><td>TERMINATED</td><td>172.19.2.2:576 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.635871</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.068436   </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.636894</td><td style=\"text-align: right;\">        0.561482</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_a8b4cf99</td><td>TERMINATED</td><td>172.19.2.2:668 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.629669</td><td style=\"text-align: right;\">  0.780471</td><td style=\"text-align: right;\">    0.151239   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.181765</td><td style=\"text-align: right;\">        0.93665 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_61130997</td><td>TERMINATED</td><td>172.19.2.2:739 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.538873</td><td style=\"text-align: right;\">  0.788552</td><td style=\"text-align: right;\">   -0.0226138  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.218797</td><td style=\"text-align: right;\">        0.922606</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_c63c3afa</td><td>TERMINATED</td><td>172.19.2.2:835 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.567989</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.0244705  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.183225</td><td style=\"text-align: right;\">        0.93426 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_500ad5ec</td><td>TERMINATED</td><td>172.19.2.2:910 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.668664</td><td style=\"text-align: right;\">  0.555556</td><td style=\"text-align: right;\">    0.116777   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.675305</td><td style=\"text-align: right;\">        0.556253</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_59adcf4e</td><td>TERMINATED</td><td>172.19.2.2:1000</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.642452</td><td style=\"text-align: right;\">  0.569024</td><td style=\"text-align: right;\">    0.0825647  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.653482</td><td style=\"text-align: right;\">        0.561781</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_7558e645</td><td>TERMINATED</td><td>172.19.2.2:1074</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.541306</td><td style=\"text-align: right;\">  0.726599</td><td style=\"text-align: right;\">   -0.167414   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.57585 </td><td style=\"text-align: right;\">        0.725385</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_19d9da1a</td><td>TERMINATED</td><td>172.19.2.2:1160</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.483564</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">   -0.196825   </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.353952</td><td style=\"text-align: right;\">        0.859107</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_fbc8b7bc</td><td>TERMINATED</td><td>172.19.2.2:1246</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.644425</td><td style=\"text-align: right;\">  0.578451</td><td style=\"text-align: right;\">    0.0722161  </td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">    0.649204</td><td style=\"text-align: right;\">        0.570746</td><td style=\"text-align: right;\">                    10</td></tr>\n",
       "<tr><td>train_fn_aa61b758</td><td>TERMINATED</td><td>172.19.2.2:1344</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.542298</td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">   -0.0395569  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.230204</td><td style=\"text-align: right;\">        0.910055</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_6ebb71b1</td><td>TERMINATED</td><td>172.19.2.2:1436</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.575959</td><td style=\"text-align: right;\">  0.804714</td><td style=\"text-align: right;\">    0.00894424 </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.218154</td><td style=\"text-align: right;\">        0.922307</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_c8d7ce42</td><td>TERMINATED</td><td>172.19.2.2:1511</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.642371</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.165396   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.175396</td><td style=\"text-align: right;\">        0.93665 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_4f2cac6b</td><td>TERMINATED</td><td>172.19.2.2:1600</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.605659</td><td style=\"text-align: right;\">  0.788552</td><td style=\"text-align: right;\">    0.11736    </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.160869</td><td style=\"text-align: right;\">        0.94427 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_7b26c394</td><td>TERMINATED</td><td>172.19.2.2:1681</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.539405</td><td style=\"text-align: right;\">  0.800673</td><td style=\"text-align: right;\">   -0.00897058 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.173775</td><td style=\"text-align: right;\">        0.939638</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_edff25af</td><td>TERMINATED</td><td>172.19.2.2:1768</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.617388</td><td style=\"text-align: right;\">  0.691582</td><td style=\"text-align: right;\">   -0.0159713  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.632869</td><td style=\"text-align: right;\">        0.590617</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_5952ce93</td><td>TERMINATED</td><td>172.19.2.2:1849</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.62716 </td><td style=\"text-align: right;\">  0.665993</td><td style=\"text-align: right;\">    0.00763627 </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.634712</td><td style=\"text-align: right;\">        0.580607</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_694b3439</td><td>TERMINATED</td><td>172.19.2.2:1926</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.509437</td><td style=\"text-align: right;\">  0.800673</td><td style=\"text-align: right;\">   -0.112733   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.261662</td><td style=\"text-align: right;\">        0.909906</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_c4c450a0</td><td>TERMINATED</td><td>172.19.2.2:2007</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.540101</td><td style=\"text-align: right;\">  0.780471</td><td style=\"text-align: right;\">   -0.027459   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.249093</td><td style=\"text-align: right;\">        0.915285</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_f35cacf3</td><td>TERMINATED</td><td>172.19.2.2:2100</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.552941</td><td style=\"text-align: right;\">  0.791246</td><td style=\"text-align: right;\">   -0.00463229 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.217404</td><td style=\"text-align: right;\">        0.923054</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_0362c7c3</td><td>TERMINATED</td><td>172.19.2.2:2181</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.489279</td><td style=\"text-align: right;\">  0.789899</td><td style=\"text-align: right;\">   -0.167303   </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.314412</td><td style=\"text-align: right;\">        0.881667</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_b25700a8</td><td>TERMINATED</td><td>172.19.2.2:2279</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.516759</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">   -0.0652085  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.234668</td><td style=\"text-align: right;\">        0.911549</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_23e1f770</td><td>TERMINATED</td><td>172.19.2.2:2360</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.557905</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.02139    </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.168547</td><td style=\"text-align: right;\">        0.943672</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_9d1ac157</td><td>TERMINATED</td><td>172.19.2.2:2442</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.53847 </td><td style=\"text-align: right;\">  0.784512</td><td style=\"text-align: right;\">   -0.0907679  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.316263</td><td style=\"text-align: right;\">        0.872852</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_db49847d</td><td>TERMINATED</td><td>172.19.2.2:2529</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.637036</td><td style=\"text-align: right;\">  0.544781</td><td style=\"text-align: right;\">    0.100758   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638238</td><td style=\"text-align: right;\">        0.560586</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_0dc55755</td><td>TERMINATED</td><td>172.19.2.2:2604</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.536905</td><td style=\"text-align: right;\">  0.761616</td><td style=\"text-align: right;\">    0.0217063  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.208197</td><td style=\"text-align: right;\">        0.925743</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_13de4bf1</td><td>TERMINATED</td><td>172.19.2.2:2687</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.63645 </td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0670085  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637493</td><td style=\"text-align: right;\">        0.565516</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c73300d5</td><td>TERMINATED</td><td>172.19.2.2:2774</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.546472</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">    0.0230714  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.180428</td><td style=\"text-align: right;\">        0.93665 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_0358bae2</td><td>TERMINATED</td><td>172.19.2.2:2838</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.708856</td><td style=\"text-align: right;\">  0.544781</td><td style=\"text-align: right;\">    0.165806   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.711005</td><td style=\"text-align: right;\">        0.546093</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_da33038e</td><td>TERMINATED</td><td>172.19.2.2:2933</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.712415</td><td style=\"text-align: right;\">  0.788552</td><td style=\"text-align: right;\">    0.298044   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.132023</td><td style=\"text-align: right;\">        0.956522</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_096911ae</td><td>TERMINATED</td><td>172.19.2.2:3015</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.615462</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.129901   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.171634</td><td style=\"text-align: right;\">        0.942627</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_d99627b6</td><td>TERMINATED</td><td>172.19.2.2:3108</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.626949</td><td style=\"text-align: right;\">  0.791246</td><td style=\"text-align: right;\">    0.141786   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.16258 </td><td style=\"text-align: right;\">        0.939041</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_71af95d6</td><td>TERMINATED</td><td>172.19.2.2:3182</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.665334</td><td style=\"text-align: right;\">  0.792593</td><td style=\"text-align: right;\">    0.226615   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.125997</td><td style=\"text-align: right;\">        0.961004</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_28927f07</td><td>TERMINATED</td><td>172.19.2.2:3277</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.607813</td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">    0.103462   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.170593</td><td style=\"text-align: right;\">        0.939937</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_bae2a83d</td><td>TERMINATED</td><td>172.19.2.2:3358</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.521175</td><td style=\"text-align: right;\">  0.784512</td><td style=\"text-align: right;\">   -0.0362434  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.209115</td><td style=\"text-align: right;\">        0.92664 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_a5c04bb1</td><td>TERMINATED</td><td>172.19.2.2:3446</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.466147</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">   -0.20178    </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.321326</td><td style=\"text-align: right;\">        0.868818</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_ce9e6f30</td><td>TERMINATED</td><td>172.19.2.2:3526</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.484974</td><td style=\"text-align: right;\">  0.789899</td><td style=\"text-align: right;\">   -0.168074   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.306626</td><td style=\"text-align: right;\">        0.885253</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_32251ed1</td><td>TERMINATED</td><td>172.19.2.2:3607</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.574075</td><td style=\"text-align: right;\">  0.793939</td><td style=\"text-align: right;\">    0.0639634  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.160037</td><td style=\"text-align: right;\">        0.947557</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_d7fd1b2d</td><td>TERMINATED</td><td>172.19.2.2:3705</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.58029 </td><td style=\"text-align: right;\">  0.791246</td><td style=\"text-align: right;\">    0.0755549  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.162236</td><td style=\"text-align: right;\">        0.946212</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_afa2de3a</td><td>TERMINATED</td><td>172.19.2.2:3779</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.578273</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.0317234  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.196432</td><td style=\"text-align: right;\">        0.931122</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_2aa5e8d1</td><td>TERMINATED</td><td>172.19.2.2:3878</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.63758 </td><td style=\"text-align: right;\">  0.547475</td><td style=\"text-align: right;\">    0.100385   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638156</td><td style=\"text-align: right;\">        0.567459</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_cf7d2fba</td><td>TERMINATED</td><td>172.19.2.2:3952</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.554415</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">   -0.0264061  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.271239</td><td style=\"text-align: right;\">        0.904677</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_65aea343</td><td>TERMINATED</td><td>172.19.2.2:4036</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.63709 </td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0701782  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637665</td><td style=\"text-align: right;\">        0.559988</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_231c7eca</td><td>TERMINATED</td><td>172.19.2.2:4125</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.612801</td><td style=\"text-align: right;\">  0.715825</td><td style=\"text-align: right;\">   -0.0275544  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637188</td><td style=\"text-align: right;\">        0.589272</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_7cdd0d75</td><td>TERMINATED</td><td>172.19.2.2:4197</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.64912 </td><td style=\"text-align: right;\">  0.554209</td><td style=\"text-align: right;\">    0.108344   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.673492</td><td style=\"text-align: right;\">        0.556701</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_278611cd</td><td>TERMINATED</td><td>172.19.2.2:4285</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.652696</td><td style=\"text-align: right;\">  0.539394</td><td style=\"text-align: right;\">    0.132738   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.663951</td><td style=\"text-align: right;\">        0.56701 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e62f3f8c</td><td>TERMINATED</td><td>172.19.2.2:4358</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.647781</td><td style=\"text-align: right;\">  0.544781</td><td style=\"text-align: right;\">    0.111028   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.655354</td><td style=\"text-align: right;\">        0.553265</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_4a6d1d5b</td><td>TERMINATED</td><td>172.19.2.2:4446</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.496437</td><td style=\"text-align: right;\">  0.753535</td><td style=\"text-align: right;\">   -0.239015   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.520264</td><td style=\"text-align: right;\">        0.765875</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e7709d97</td><td>TERMINATED</td><td>172.19.2.2:4518</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.49057 </td><td style=\"text-align: right;\">  0.762963</td><td style=\"text-align: right;\">   -0.259881   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.495948</td><td style=\"text-align: right;\">        0.782609</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_b8c7734f</td><td>TERMINATED</td><td>172.19.2.2:4606</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.544161</td><td style=\"text-align: right;\">  0.746801</td><td style=\"text-align: right;\">   -0.137544   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.600942</td><td style=\"text-align: right;\">        0.67339 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e02d58d0</td><td>TERMINATED</td><td>172.19.2.2:4678</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.678749</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.110746   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.682522</td><td style=\"text-align: right;\">        0.565367</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_3c15332a</td><td>TERMINATED</td><td>172.19.2.2:4765</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.577995</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.062013   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.188136</td><td style=\"text-align: right;\">        0.935754</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_90756efd</td><td>TERMINATED</td><td>172.19.2.2:4837</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.582888</td><td style=\"text-align: right;\">  0.776431</td><td style=\"text-align: right;\">    0.0811257  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.192277</td><td style=\"text-align: right;\">        0.935156</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_9c55e964</td><td>TERMINATED</td><td>172.19.2.2:4933</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.669873</td><td style=\"text-align: right;\">  0.559596</td><td style=\"text-align: right;\">    0.118668   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.675692</td><td style=\"text-align: right;\">        0.548633</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c6111dd6</td><td>TERMINATED</td><td>172.19.2.2:5005</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.684108</td><td style=\"text-align: right;\">  0.547475</td><td style=\"text-align: right;\">    0.145183   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.68974 </td><td style=\"text-align: right;\">        0.558942</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_9517f0c5</td><td>TERMINATED</td><td>172.19.2.2:5092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.705206</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.140854   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.715532</td><td style=\"text-align: right;\">        0.56462 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_94f2b157</td><td>TERMINATED</td><td>172.19.2.2:5164</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.548029</td><td style=\"text-align: right;\">  0.793939</td><td style=\"text-align: right;\">   -0.0155198  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.219202</td><td style=\"text-align: right;\">        0.925893</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_9d530c25</td><td>TERMINATED</td><td>172.19.2.2:5250</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.456568</td><td style=\"text-align: right;\">  0.779125</td><td style=\"text-align: right;\">   -0.282776   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.41904 </td><td style=\"text-align: right;\">        0.821156</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_6a9b6b4b</td><td>TERMINATED</td><td>172.19.2.2:5337</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.480637</td><td style=\"text-align: right;\">  0.772391</td><td style=\"text-align: right;\">   -0.24935    </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.43802 </td><td style=\"text-align: right;\">        0.814582</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e45ea0ba</td><td>TERMINATED</td><td>172.19.2.2:5415</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.483298</td><td style=\"text-align: right;\">  0.772391</td><td style=\"text-align: right;\">   -0.153082   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.309496</td><td style=\"text-align: right;\">        0.870611</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_34bd9d6d</td><td>TERMINATED</td><td>172.19.2.2:5495</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.601661</td><td style=\"text-align: right;\">  0.793939</td><td style=\"text-align: right;\">    0.0883882  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.185131</td><td style=\"text-align: right;\">        0.938742</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_56548b4f</td><td>TERMINATED</td><td>172.19.2.2:5573</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.589178</td><td style=\"text-align: right;\">  0.789899</td><td style=\"text-align: right;\">    0.0660661  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.194586</td><td style=\"text-align: right;\">        0.928881</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_f5d6c148</td><td>TERMINATED</td><td>172.19.2.2:5669</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.716625</td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">    0.267631   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.168245</td><td style=\"text-align: right;\">        0.939489</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_3c5f5295</td><td>TERMINATED</td><td>172.19.2.2:5741</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.689894</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">    0.274965   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.129019</td><td style=\"text-align: right;\">        0.958763</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_af44c2fa</td><td>TERMINATED</td><td>172.19.2.2:5838</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.608453</td><td style=\"text-align: right;\">  0.699663</td><td style=\"text-align: right;\">   -0.039246   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.627839</td><td style=\"text-align: right;\">        0.61512 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_cc73b0b9</td><td>TERMINATED</td><td>172.19.2.2:5916</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.600347</td><td style=\"text-align: right;\">  0.679461</td><td style=\"text-align: right;\">   -0.0356985  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.626124</td><td style=\"text-align: right;\">        0.618407</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c2f44f3f</td><td>TERMINATED</td><td>172.19.2.2:5996</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.600464</td><td style=\"text-align: right;\">  0.781818</td><td style=\"text-align: right;\">    0.089417   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.20464 </td><td style=\"text-align: right;\">        0.927536</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_5a266dcd</td><td>TERMINATED</td><td>172.19.2.2:6074</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.641847</td><td style=\"text-align: right;\">  0.613468</td><td style=\"text-align: right;\">    0.0543382  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.654031</td><td style=\"text-align: right;\">        0.573734</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_d7ea1479</td><td>TERMINATED</td><td>172.19.2.2:6161</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.535833</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.0153566  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.163033</td><td style=\"text-align: right;\">        0.943822</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_430ec7c0</td><td>TERMINATED</td><td>172.19.2.2:6235</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.637847</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0703516  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637853</td><td style=\"text-align: right;\">        0.560586</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e2587eeb</td><td>TERMINATED</td><td>172.19.2.2:6323</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.530227</td><td style=\"text-align: right;\">  0.804714</td><td style=\"text-align: right;\">   -0.0345765  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.181745</td><td style=\"text-align: right;\">        0.936053</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_94c3d814</td><td>TERMINATED</td><td>172.19.2.2:6406</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.575758</td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">    0.0502149  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.178681</td><td style=\"text-align: right;\">        0.937696</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_e0aade29</td><td>TERMINATED</td><td>172.19.2.2:6491</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.606584</td><td style=\"text-align: right;\">  0.793939</td><td style=\"text-align: right;\">    0.0790193  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.208029</td><td style=\"text-align: right;\">        0.928134</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_6354055f</td><td>TERMINATED</td><td>172.19.2.2:6575</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.524675</td><td style=\"text-align: right;\">  0.79798 </td><td style=\"text-align: right;\">   -0.0753097  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.238069</td><td style=\"text-align: right;\">        0.907366</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_0c802637</td><td>TERMINATED</td><td>172.19.2.2:6660</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.665338</td><td style=\"text-align: right;\">  0.799327</td><td style=\"text-align: right;\">    0.210864   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.133277</td><td style=\"text-align: right;\">        0.95697 </td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_fd47a8b7</td><td>TERMINATED</td><td>172.19.2.2:6739</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.686817</td><td style=\"text-align: right;\">  0.784512</td><td style=\"text-align: right;\">    0.267204   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.129177</td><td style=\"text-align: right;\">        0.956671</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_e099f78f</td><td>TERMINATED</td><td>172.19.2.2:6834</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.461307</td><td style=\"text-align: right;\">  0.781818</td><td style=\"text-align: right;\">   -0.218353   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.335771</td><td style=\"text-align: right;\">        0.860601</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_378e06a0</td><td>TERMINATED</td><td>172.19.2.2:6913</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.477501</td><td style=\"text-align: right;\">  0.765657</td><td style=\"text-align: right;\">   -0.270855   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.510228</td><td style=\"text-align: right;\">        0.763783</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c1bbca80</td><td>TERMINATED</td><td>172.19.2.2:6992</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.575634</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">    0.0575682  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.192794</td><td style=\"text-align: right;\">        0.930524</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_4f07941d</td><td>TERMINATED</td><td>172.19.2.2:7071</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.479096</td><td style=\"text-align: right;\">  0.767003</td><td style=\"text-align: right;\">   -0.242869   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.43555 </td><td style=\"text-align: right;\">        0.813537</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_bd0fcf80</td><td>TERMINATED</td><td>172.19.2.2:7160</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.501618</td><td style=\"text-align: right;\">  0.776431</td><td style=\"text-align: right;\">   -0.142319   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.326027</td><td style=\"text-align: right;\">        0.86583 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_3db80024</td><td>TERMINATED</td><td>172.19.2.2:7225</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.507201</td><td style=\"text-align: right;\">  0.79798 </td><td style=\"text-align: right;\">   -0.10513    </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.245288</td><td style=\"text-align: right;\">        0.907366</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_57e1efea</td><td>TERMINATED</td><td>172.19.2.2:7321</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.606543</td><td style=\"text-align: right;\">  0.799327</td><td style=\"text-align: right;\">    0.0923517  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.176434</td><td style=\"text-align: right;\">        0.939489</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_07112786</td><td>TERMINATED</td><td>172.19.2.2:7394</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.542119</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.00592017 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.155265</td><td style=\"text-align: right;\">        0.94681 </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_85e1f9cb</td><td>TERMINATED</td><td>172.19.2.2:7489</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.602734</td><td style=\"text-align: right;\">  0.800673</td><td style=\"text-align: right;\">    0.110706   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.138453</td><td style=\"text-align: right;\">        0.953683</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_e28b19e5</td><td>TERMINATED</td><td>172.19.2.2:7563</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.683257</td><td style=\"text-align: right;\">  0.550168</td><td style=\"text-align: right;\">    0.134625   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.686072</td><td style=\"text-align: right;\">        0.550426</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_64ce54e6</td><td>TERMINATED</td><td>172.19.2.2:7651</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.577391</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.0666493  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.145302</td><td style=\"text-align: right;\">        0.952488</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_d11473b2</td><td>TERMINATED</td><td>172.19.2.2:7734</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.638093</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0748509  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.639135</td><td style=\"text-align: right;\">        0.553115</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_d341fefe</td><td>TERMINATED</td><td>172.19.2.2:7820</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.638415</td><td style=\"text-align: right;\">  0.547475</td><td style=\"text-align: right;\">    0.099627   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637588</td><td style=\"text-align: right;\">        0.564022</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_0306faac</td><td>TERMINATED</td><td>172.19.2.2:7892</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.560282</td><td style=\"text-align: right;\">  0.79798 </td><td style=\"text-align: right;\">   -0.0126657  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.230959</td><td style=\"text-align: right;\">        0.918721</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_0236351a</td><td>TERMINATED</td><td>172.19.2.2:7978</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.51504 </td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">   -0.0763097  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.231349</td><td style=\"text-align: right;\">        0.919468</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_31dd1ac7</td><td>TERMINATED</td><td>172.19.2.2:8061</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.494371</td><td style=\"text-align: right;\">  0.773737</td><td style=\"text-align: right;\">   -0.133541   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.304225</td><td style=\"text-align: right;\">        0.875243</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_426054ea</td><td>TERMINATED</td><td>172.19.2.2:8149</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.537551</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.000663332</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.15372 </td><td style=\"text-align: right;\">        0.948454</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_75e375a8</td><td>TERMINATED</td><td>172.19.2.2:8220</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.513844</td><td style=\"text-align: right;\">  0.791246</td><td style=\"text-align: right;\">   -0.0917655  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.252863</td><td style=\"text-align: right;\">        0.901539</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_1042cd33</td><td>TERMINATED</td><td>172.19.2.2:8313</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.570382</td><td style=\"text-align: right;\">  0.792593</td><td style=\"text-align: right;\">    0.053403   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.166649</td><td style=\"text-align: right;\">        0.940087</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_c933ddf0</td><td>TERMINATED</td><td>172.19.2.2:8387</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.56391 </td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.04904    </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.173622</td><td style=\"text-align: right;\">        0.937547</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_3cf25ecf</td><td>TERMINATED</td><td>172.19.2.2:8482</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.601535</td><td style=\"text-align: right;\">  0.799327</td><td style=\"text-align: right;\">    0.0890939  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.167926</td><td style=\"text-align: right;\">        0.939489</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_02e93cef</td><td>TERMINATED</td><td>172.19.2.2:8556</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.531873</td><td style=\"text-align: right;\">  0.788552</td><td style=\"text-align: right;\">   -0.0193691  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.198778</td><td style=\"text-align: right;\">        0.930076</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 19:48:49,433\tINFO worker.py:1753 -- Started a local Ray instance.\n",
      "2024-11-28 19:48:50,532\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-11-28 19:48:50,538\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "[I 2024-11-28 19:48:50,594] A new study created in memory with name: optuna\n",
      "\u001b[36m(train_fn pid=341)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=341)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  early_stopping_epoch</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_0236351a</td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">   -0.0763097  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.51504 </td><td style=\"text-align: right;\">        0.919468</td><td style=\"text-align: right;\">    0.231349</td></tr>\n",
       "<tr><td>train_fn_02e93cef</td><td style=\"text-align: right;\">  0.788552</td><td style=\"text-align: right;\">   -0.0193691  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.531873</td><td style=\"text-align: right;\">        0.930076</td><td style=\"text-align: right;\">    0.198778</td></tr>\n",
       "<tr><td>train_fn_0306faac</td><td style=\"text-align: right;\">  0.79798 </td><td style=\"text-align: right;\">   -0.0126657  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.560282</td><td style=\"text-align: right;\">        0.918721</td><td style=\"text-align: right;\">    0.230959</td></tr>\n",
       "<tr><td>train_fn_0358bae2</td><td style=\"text-align: right;\">  0.544781</td><td style=\"text-align: right;\">    0.165806   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.708856</td><td style=\"text-align: right;\">        0.546093</td><td style=\"text-align: right;\">    0.711005</td></tr>\n",
       "<tr><td>train_fn_0362c7c3</td><td style=\"text-align: right;\">  0.789899</td><td style=\"text-align: right;\">   -0.167303   </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.489279</td><td style=\"text-align: right;\">        0.881667</td><td style=\"text-align: right;\">    0.314412</td></tr>\n",
       "<tr><td>train_fn_07112786</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.00592017 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.542119</td><td style=\"text-align: right;\">        0.94681 </td><td style=\"text-align: right;\">    0.155265</td></tr>\n",
       "<tr><td>train_fn_096911ae</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.129901   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.615462</td><td style=\"text-align: right;\">        0.942627</td><td style=\"text-align: right;\">    0.171634</td></tr>\n",
       "<tr><td>train_fn_0c802637</td><td style=\"text-align: right;\">  0.799327</td><td style=\"text-align: right;\">    0.210864   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.665338</td><td style=\"text-align: right;\">        0.95697 </td><td style=\"text-align: right;\">    0.133277</td></tr>\n",
       "<tr><td>train_fn_0dc55755</td><td style=\"text-align: right;\">  0.761616</td><td style=\"text-align: right;\">    0.0217063  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.536905</td><td style=\"text-align: right;\">        0.925743</td><td style=\"text-align: right;\">    0.208197</td></tr>\n",
       "<tr><td>train_fn_1042cd33</td><td style=\"text-align: right;\">  0.792593</td><td style=\"text-align: right;\">    0.053403   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.570382</td><td style=\"text-align: right;\">        0.940087</td><td style=\"text-align: right;\">    0.166649</td></tr>\n",
       "<tr><td>train_fn_10c0bdbb</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0681172  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.636123</td><td style=\"text-align: right;\">        0.562528</td><td style=\"text-align: right;\">    0.63705 </td></tr>\n",
       "<tr><td>train_fn_13de4bf1</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0670085  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.63645 </td><td style=\"text-align: right;\">        0.565516</td><td style=\"text-align: right;\">    0.637493</td></tr>\n",
       "<tr><td>train_fn_19d9da1a</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">   -0.196825   </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.483564</td><td style=\"text-align: right;\">        0.859107</td><td style=\"text-align: right;\">    0.353952</td></tr>\n",
       "<tr><td>train_fn_231c7eca</td><td style=\"text-align: right;\">  0.715825</td><td style=\"text-align: right;\">   -0.0275544  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.612801</td><td style=\"text-align: right;\">        0.589272</td><td style=\"text-align: right;\">    0.637188</td></tr>\n",
       "<tr><td>train_fn_23e1f770</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.02139    </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.557905</td><td style=\"text-align: right;\">        0.943672</td><td style=\"text-align: right;\">    0.168547</td></tr>\n",
       "<tr><td>train_fn_278611cd</td><td style=\"text-align: right;\">  0.539394</td><td style=\"text-align: right;\">    0.132738   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.652696</td><td style=\"text-align: right;\">        0.56701 </td><td style=\"text-align: right;\">    0.663951</td></tr>\n",
       "<tr><td>train_fn_28927f07</td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">    0.103462   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.607813</td><td style=\"text-align: right;\">        0.939937</td><td style=\"text-align: right;\">    0.170593</td></tr>\n",
       "<tr><td>train_fn_2aa5e8d1</td><td style=\"text-align: right;\">  0.547475</td><td style=\"text-align: right;\">    0.100385   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.63758 </td><td style=\"text-align: right;\">        0.567459</td><td style=\"text-align: right;\">    0.638156</td></tr>\n",
       "<tr><td>train_fn_2da04114</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0690538  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.636268</td><td style=\"text-align: right;\">        0.561034</td><td style=\"text-align: right;\">    0.637284</td></tr>\n",
       "<tr><td>train_fn_31dd1ac7</td><td style=\"text-align: right;\">  0.773737</td><td style=\"text-align: right;\">   -0.133541   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.494371</td><td style=\"text-align: right;\">        0.875243</td><td style=\"text-align: right;\">    0.304225</td></tr>\n",
       "<tr><td>train_fn_32251ed1</td><td style=\"text-align: right;\">  0.793939</td><td style=\"text-align: right;\">    0.0639634  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.574075</td><td style=\"text-align: right;\">        0.947557</td><td style=\"text-align: right;\">    0.160037</td></tr>\n",
       "<tr><td>train_fn_34bd9d6d</td><td style=\"text-align: right;\">  0.793939</td><td style=\"text-align: right;\">    0.0883882  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.601661</td><td style=\"text-align: right;\">        0.938742</td><td style=\"text-align: right;\">    0.185131</td></tr>\n",
       "<tr><td>train_fn_378e06a0</td><td style=\"text-align: right;\">  0.765657</td><td style=\"text-align: right;\">   -0.270855   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.477501</td><td style=\"text-align: right;\">        0.763783</td><td style=\"text-align: right;\">    0.510228</td></tr>\n",
       "<tr><td>train_fn_3c15332a</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.062013   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.577995</td><td style=\"text-align: right;\">        0.935754</td><td style=\"text-align: right;\">    0.188136</td></tr>\n",
       "<tr><td>train_fn_3c5f5295</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">    0.274965   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.689894</td><td style=\"text-align: right;\">        0.958763</td><td style=\"text-align: right;\">    0.129019</td></tr>\n",
       "<tr><td>train_fn_3cf25ecf</td><td style=\"text-align: right;\">  0.799327</td><td style=\"text-align: right;\">    0.0890939  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.601535</td><td style=\"text-align: right;\">        0.939489</td><td style=\"text-align: right;\">    0.167926</td></tr>\n",
       "<tr><td>train_fn_3db80024</td><td style=\"text-align: right;\">  0.79798 </td><td style=\"text-align: right;\">   -0.10513    </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.507201</td><td style=\"text-align: right;\">        0.907366</td><td style=\"text-align: right;\">    0.245288</td></tr>\n",
       "<tr><td>train_fn_426054ea</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.000663332</td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.537551</td><td style=\"text-align: right;\">        0.948454</td><td style=\"text-align: right;\">    0.15372 </td></tr>\n",
       "<tr><td>train_fn_430ec7c0</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0703516  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.637847</td><td style=\"text-align: right;\">        0.560586</td><td style=\"text-align: right;\">    0.637853</td></tr>\n",
       "<tr><td>train_fn_4a6d1d5b</td><td style=\"text-align: right;\">  0.753535</td><td style=\"text-align: right;\">   -0.239015   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.496437</td><td style=\"text-align: right;\">        0.765875</td><td style=\"text-align: right;\">    0.520264</td></tr>\n",
       "<tr><td>train_fn_4f07941d</td><td style=\"text-align: right;\">  0.767003</td><td style=\"text-align: right;\">   -0.242869   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.479096</td><td style=\"text-align: right;\">        0.813537</td><td style=\"text-align: right;\">    0.43555 </td></tr>\n",
       "<tr><td>train_fn_4f2cac6b</td><td style=\"text-align: right;\">  0.788552</td><td style=\"text-align: right;\">    0.11736    </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.605659</td><td style=\"text-align: right;\">        0.94427 </td><td style=\"text-align: right;\">    0.160869</td></tr>\n",
       "<tr><td>train_fn_500ad5ec</td><td style=\"text-align: right;\">  0.555556</td><td style=\"text-align: right;\">    0.116777   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.668664</td><td style=\"text-align: right;\">        0.556253</td><td style=\"text-align: right;\">    0.675305</td></tr>\n",
       "<tr><td>train_fn_56548b4f</td><td style=\"text-align: right;\">  0.789899</td><td style=\"text-align: right;\">    0.0660661  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.589178</td><td style=\"text-align: right;\">        0.928881</td><td style=\"text-align: right;\">    0.194586</td></tr>\n",
       "<tr><td>train_fn_57e1efea</td><td style=\"text-align: right;\">  0.799327</td><td style=\"text-align: right;\">    0.0923517  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.606543</td><td style=\"text-align: right;\">        0.939489</td><td style=\"text-align: right;\">    0.176434</td></tr>\n",
       "<tr><td>train_fn_5952ce93</td><td style=\"text-align: right;\">  0.665993</td><td style=\"text-align: right;\">    0.00763627 </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.62716 </td><td style=\"text-align: right;\">        0.580607</td><td style=\"text-align: right;\">    0.634712</td></tr>\n",
       "<tr><td>train_fn_59adcf4e</td><td style=\"text-align: right;\">  0.569024</td><td style=\"text-align: right;\">    0.0825647  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.642452</td><td style=\"text-align: right;\">        0.561781</td><td style=\"text-align: right;\">    0.653482</td></tr>\n",
       "<tr><td>train_fn_5a266dcd</td><td style=\"text-align: right;\">  0.613468</td><td style=\"text-align: right;\">    0.0543382  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.641847</td><td style=\"text-align: right;\">        0.573734</td><td style=\"text-align: right;\">    0.654031</td></tr>\n",
       "<tr><td>train_fn_61130997</td><td style=\"text-align: right;\">  0.788552</td><td style=\"text-align: right;\">   -0.0226138  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.538873</td><td style=\"text-align: right;\">        0.922606</td><td style=\"text-align: right;\">    0.218797</td></tr>\n",
       "<tr><td>train_fn_6354055f</td><td style=\"text-align: right;\">  0.79798 </td><td style=\"text-align: right;\">   -0.0753097  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.524675</td><td style=\"text-align: right;\">        0.907366</td><td style=\"text-align: right;\">    0.238069</td></tr>\n",
       "<tr><td>train_fn_64ce54e6</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.0666493  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.577391</td><td style=\"text-align: right;\">        0.952488</td><td style=\"text-align: right;\">    0.145302</td></tr>\n",
       "<tr><td>train_fn_65aea343</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0701782  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.63709 </td><td style=\"text-align: right;\">        0.559988</td><td style=\"text-align: right;\">    0.637665</td></tr>\n",
       "<tr><td>train_fn_694b3439</td><td style=\"text-align: right;\">  0.800673</td><td style=\"text-align: right;\">   -0.112733   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.509437</td><td style=\"text-align: right;\">        0.909906</td><td style=\"text-align: right;\">    0.261662</td></tr>\n",
       "<tr><td>train_fn_6a9b6b4b</td><td style=\"text-align: right;\">  0.772391</td><td style=\"text-align: right;\">   -0.24935    </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.480637</td><td style=\"text-align: right;\">        0.814582</td><td style=\"text-align: right;\">    0.43802 </td></tr>\n",
       "<tr><td>train_fn_6ebb71b1</td><td style=\"text-align: right;\">  0.804714</td><td style=\"text-align: right;\">    0.00894424 </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.575959</td><td style=\"text-align: right;\">        0.922307</td><td style=\"text-align: right;\">    0.218154</td></tr>\n",
       "<tr><td>train_fn_71af95d6</td><td style=\"text-align: right;\">  0.792593</td><td style=\"text-align: right;\">    0.226615   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.665334</td><td style=\"text-align: right;\">        0.961004</td><td style=\"text-align: right;\">    0.125997</td></tr>\n",
       "<tr><td>train_fn_7558e645</td><td style=\"text-align: right;\">  0.726599</td><td style=\"text-align: right;\">   -0.167414   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.541306</td><td style=\"text-align: right;\">        0.725385</td><td style=\"text-align: right;\">    0.57585 </td></tr>\n",
       "<tr><td>train_fn_75e375a8</td><td style=\"text-align: right;\">  0.791246</td><td style=\"text-align: right;\">   -0.0917655  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.513844</td><td style=\"text-align: right;\">        0.901539</td><td style=\"text-align: right;\">    0.252863</td></tr>\n",
       "<tr><td>train_fn_7b26c394</td><td style=\"text-align: right;\">  0.800673</td><td style=\"text-align: right;\">   -0.00897058 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.539405</td><td style=\"text-align: right;\">        0.939638</td><td style=\"text-align: right;\">    0.173775</td></tr>\n",
       "<tr><td>train_fn_7cdd0d75</td><td style=\"text-align: right;\">  0.554209</td><td style=\"text-align: right;\">    0.108344   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.64912 </td><td style=\"text-align: right;\">        0.556701</td><td style=\"text-align: right;\">    0.673492</td></tr>\n",
       "<tr><td>train_fn_85e1f9cb</td><td style=\"text-align: right;\">  0.800673</td><td style=\"text-align: right;\">    0.110706   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.602734</td><td style=\"text-align: right;\">        0.953683</td><td style=\"text-align: right;\">    0.138453</td></tr>\n",
       "<tr><td>train_fn_90756efd</td><td style=\"text-align: right;\">  0.776431</td><td style=\"text-align: right;\">    0.0811257  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.582888</td><td style=\"text-align: right;\">        0.935156</td><td style=\"text-align: right;\">    0.192277</td></tr>\n",
       "<tr><td>train_fn_94c3d814</td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">    0.0502149  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.575758</td><td style=\"text-align: right;\">        0.937696</td><td style=\"text-align: right;\">    0.178681</td></tr>\n",
       "<tr><td>train_fn_94f2b157</td><td style=\"text-align: right;\">  0.793939</td><td style=\"text-align: right;\">   -0.0155198  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.548029</td><td style=\"text-align: right;\">        0.925893</td><td style=\"text-align: right;\">    0.219202</td></tr>\n",
       "<tr><td>train_fn_9517f0c5</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.140854   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.705206</td><td style=\"text-align: right;\">        0.56462 </td><td style=\"text-align: right;\">    0.715532</td></tr>\n",
       "<tr><td>train_fn_9c55e964</td><td style=\"text-align: right;\">  0.559596</td><td style=\"text-align: right;\">    0.118668   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.669873</td><td style=\"text-align: right;\">        0.548633</td><td style=\"text-align: right;\">    0.675692</td></tr>\n",
       "<tr><td>train_fn_9d1ac157</td><td style=\"text-align: right;\">  0.784512</td><td style=\"text-align: right;\">   -0.0907679  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.53847 </td><td style=\"text-align: right;\">        0.872852</td><td style=\"text-align: right;\">    0.316263</td></tr>\n",
       "<tr><td>train_fn_9d530c25</td><td style=\"text-align: right;\">  0.779125</td><td style=\"text-align: right;\">   -0.282776   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.456568</td><td style=\"text-align: right;\">        0.821156</td><td style=\"text-align: right;\">    0.41904 </td></tr>\n",
       "<tr><td>train_fn_a5c04bb1</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">   -0.20178    </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.466147</td><td style=\"text-align: right;\">        0.868818</td><td style=\"text-align: right;\">    0.321326</td></tr>\n",
       "<tr><td>train_fn_a8b4cf99</td><td style=\"text-align: right;\">  0.780471</td><td style=\"text-align: right;\">    0.151239   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.629669</td><td style=\"text-align: right;\">        0.93665 </td><td style=\"text-align: right;\">    0.181765</td></tr>\n",
       "<tr><td>train_fn_aa61b758</td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">   -0.0395569  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.542298</td><td style=\"text-align: right;\">        0.910055</td><td style=\"text-align: right;\">    0.230204</td></tr>\n",
       "<tr><td>train_fn_af44c2fa</td><td style=\"text-align: right;\">  0.699663</td><td style=\"text-align: right;\">   -0.039246   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.608453</td><td style=\"text-align: right;\">        0.61512 </td><td style=\"text-align: right;\">    0.627839</td></tr>\n",
       "<tr><td>train_fn_afa2de3a</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.0317234  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.578273</td><td style=\"text-align: right;\">        0.931122</td><td style=\"text-align: right;\">    0.196432</td></tr>\n",
       "<tr><td>train_fn_b25700a8</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">   -0.0652085  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.516759</td><td style=\"text-align: right;\">        0.911549</td><td style=\"text-align: right;\">    0.234668</td></tr>\n",
       "<tr><td>train_fn_b8c7734f</td><td style=\"text-align: right;\">  0.746801</td><td style=\"text-align: right;\">   -0.137544   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.544161</td><td style=\"text-align: right;\">        0.67339 </td><td style=\"text-align: right;\">    0.600942</td></tr>\n",
       "<tr><td>train_fn_bae2a83d</td><td style=\"text-align: right;\">  0.784512</td><td style=\"text-align: right;\">   -0.0362434  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.521175</td><td style=\"text-align: right;\">        0.92664 </td><td style=\"text-align: right;\">    0.209115</td></tr>\n",
       "<tr><td>train_fn_bd0fcf80</td><td style=\"text-align: right;\">  0.776431</td><td style=\"text-align: right;\">   -0.142319   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.501618</td><td style=\"text-align: right;\">        0.86583 </td><td style=\"text-align: right;\">    0.326027</td></tr>\n",
       "<tr><td>train_fn_c1bbca80</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">    0.0575682  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.575634</td><td style=\"text-align: right;\">        0.930524</td><td style=\"text-align: right;\">    0.192794</td></tr>\n",
       "<tr><td>train_fn_c2f44f3f</td><td style=\"text-align: right;\">  0.781818</td><td style=\"text-align: right;\">    0.089417   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.600464</td><td style=\"text-align: right;\">        0.927536</td><td style=\"text-align: right;\">    0.20464 </td></tr>\n",
       "<tr><td>train_fn_c4c450a0</td><td style=\"text-align: right;\">  0.780471</td><td style=\"text-align: right;\">   -0.027459   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.540101</td><td style=\"text-align: right;\">        0.915285</td><td style=\"text-align: right;\">    0.249093</td></tr>\n",
       "<tr><td>train_fn_c6111dd6</td><td style=\"text-align: right;\">  0.547475</td><td style=\"text-align: right;\">    0.145183   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.684108</td><td style=\"text-align: right;\">        0.558942</td><td style=\"text-align: right;\">    0.68974 </td></tr>\n",
       "<tr><td>train_fn_c63c3afa</td><td style=\"text-align: right;\">  0.80202 </td><td style=\"text-align: right;\">    0.0244705  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.567989</td><td style=\"text-align: right;\">        0.93426 </td><td style=\"text-align: right;\">    0.183225</td></tr>\n",
       "<tr><td>train_fn_c73300d5</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">    0.0230714  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.546472</td><td style=\"text-align: right;\">        0.93665 </td><td style=\"text-align: right;\">    0.180428</td></tr>\n",
       "<tr><td>train_fn_c8d7ce42</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.165396   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.642371</td><td style=\"text-align: right;\">        0.93665 </td><td style=\"text-align: right;\">    0.175396</td></tr>\n",
       "<tr><td>train_fn_c933ddf0</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.04904    </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.56391 </td><td style=\"text-align: right;\">        0.937547</td><td style=\"text-align: right;\">    0.173622</td></tr>\n",
       "<tr><td>train_fn_cc73b0b9</td><td style=\"text-align: right;\">  0.679461</td><td style=\"text-align: right;\">   -0.0356985  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.600347</td><td style=\"text-align: right;\">        0.618407</td><td style=\"text-align: right;\">    0.626124</td></tr>\n",
       "<tr><td>train_fn_ce9e6f30</td><td style=\"text-align: right;\">  0.789899</td><td style=\"text-align: right;\">   -0.168074   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.484974</td><td style=\"text-align: right;\">        0.885253</td><td style=\"text-align: right;\">    0.306626</td></tr>\n",
       "<tr><td>train_fn_cf7d2fba</td><td style=\"text-align: right;\">  0.783165</td><td style=\"text-align: right;\">   -0.0264061  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.554415</td><td style=\"text-align: right;\">        0.904677</td><td style=\"text-align: right;\">    0.271239</td></tr>\n",
       "<tr><td>train_fn_d11473b2</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.0748509  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.638093</td><td style=\"text-align: right;\">        0.553115</td><td style=\"text-align: right;\">    0.639135</td></tr>\n",
       "<tr><td>train_fn_d341fefe</td><td style=\"text-align: right;\">  0.547475</td><td style=\"text-align: right;\">    0.099627   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.638415</td><td style=\"text-align: right;\">        0.564022</td><td style=\"text-align: right;\">    0.637588</td></tr>\n",
       "<tr><td>train_fn_d7ea1479</td><td style=\"text-align: right;\">  0.785859</td><td style=\"text-align: right;\">    0.0153566  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.535833</td><td style=\"text-align: right;\">        0.943822</td><td style=\"text-align: right;\">    0.163033</td></tr>\n",
       "<tr><td>train_fn_d7fd1b2d</td><td style=\"text-align: right;\">  0.791246</td><td style=\"text-align: right;\">    0.0755549  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.58029 </td><td style=\"text-align: right;\">        0.946212</td><td style=\"text-align: right;\">    0.162236</td></tr>\n",
       "<tr><td>train_fn_d99627b6</td><td style=\"text-align: right;\">  0.791246</td><td style=\"text-align: right;\">    0.141786   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.626949</td><td style=\"text-align: right;\">        0.939041</td><td style=\"text-align: right;\">    0.16258 </td></tr>\n",
       "<tr><td>train_fn_da33038e</td><td style=\"text-align: right;\">  0.788552</td><td style=\"text-align: right;\">    0.298044   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.712415</td><td style=\"text-align: right;\">        0.956522</td><td style=\"text-align: right;\">    0.132023</td></tr>\n",
       "<tr><td>train_fn_db49847d</td><td style=\"text-align: right;\">  0.544781</td><td style=\"text-align: right;\">    0.100758   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.637036</td><td style=\"text-align: right;\">        0.560586</td><td style=\"text-align: right;\">    0.638238</td></tr>\n",
       "<tr><td>train_fn_e02d58d0</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.110746   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.678749</td><td style=\"text-align: right;\">        0.565367</td><td style=\"text-align: right;\">    0.682522</td></tr>\n",
       "<tr><td>train_fn_e099f78f</td><td style=\"text-align: right;\">  0.781818</td><td style=\"text-align: right;\">   -0.218353   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.461307</td><td style=\"text-align: right;\">        0.860601</td><td style=\"text-align: right;\">    0.335771</td></tr>\n",
       "<tr><td>train_fn_e0aade29</td><td style=\"text-align: right;\">  0.793939</td><td style=\"text-align: right;\">    0.0790193  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.606584</td><td style=\"text-align: right;\">        0.928134</td><td style=\"text-align: right;\">    0.208029</td></tr>\n",
       "<tr><td>train_fn_e2587eeb</td><td style=\"text-align: right;\">  0.804714</td><td style=\"text-align: right;\">   -0.0345765  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.530227</td><td style=\"text-align: right;\">        0.936053</td><td style=\"text-align: right;\">    0.181745</td></tr>\n",
       "<tr><td>train_fn_e28b19e5</td><td style=\"text-align: right;\">  0.550168</td><td style=\"text-align: right;\">    0.134625   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.683257</td><td style=\"text-align: right;\">        0.550426</td><td style=\"text-align: right;\">    0.686072</td></tr>\n",
       "<tr><td>train_fn_e45616c1</td><td style=\"text-align: right;\">  0.543434</td><td style=\"text-align: right;\">    0.141718   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.683463</td><td style=\"text-align: right;\">        0.545047</td><td style=\"text-align: right;\">    0.685229</td></tr>\n",
       "<tr><td>train_fn_e45ea0ba</td><td style=\"text-align: right;\">  0.772391</td><td style=\"text-align: right;\">   -0.153082   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.483298</td><td style=\"text-align: right;\">        0.870611</td><td style=\"text-align: right;\">    0.309496</td></tr>\n",
       "<tr><td>train_fn_e62f3f8c</td><td style=\"text-align: right;\">  0.544781</td><td style=\"text-align: right;\">    0.111028   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.647781</td><td style=\"text-align: right;\">        0.553265</td><td style=\"text-align: right;\">    0.655354</td></tr>\n",
       "<tr><td>train_fn_e7709d97</td><td style=\"text-align: right;\">  0.762963</td><td style=\"text-align: right;\">   -0.259881   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.49057 </td><td style=\"text-align: right;\">        0.782609</td><td style=\"text-align: right;\">    0.495948</td></tr>\n",
       "<tr><td>train_fn_edff25af</td><td style=\"text-align: right;\">  0.691582</td><td style=\"text-align: right;\">   -0.0159713  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.617388</td><td style=\"text-align: right;\">        0.590617</td><td style=\"text-align: right;\">    0.632869</td></tr>\n",
       "<tr><td>train_fn_f35cacf3</td><td style=\"text-align: right;\">  0.791246</td><td style=\"text-align: right;\">   -0.00463229 </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.552941</td><td style=\"text-align: right;\">        0.923054</td><td style=\"text-align: right;\">    0.217404</td></tr>\n",
       "<tr><td>train_fn_f5d6c148</td><td style=\"text-align: right;\">  0.795286</td><td style=\"text-align: right;\">    0.267631   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.716625</td><td style=\"text-align: right;\">        0.939489</td><td style=\"text-align: right;\">    0.168245</td></tr>\n",
       "<tr><td>train_fn_fbc8b7bc</td><td style=\"text-align: right;\">  0.578451</td><td style=\"text-align: right;\">    0.0722161  </td><td style=\"text-align: right;\">                    10</td><td style=\"text-align: right;\">0.644425</td><td style=\"text-align: right;\">        0.570746</td><td style=\"text-align: right;\">    0.649204</td></tr>\n",
       "<tr><td>train_fn_fd47a8b7</td><td style=\"text-align: right;\">  0.784512</td><td style=\"text-align: right;\">    0.267204   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.686817</td><td style=\"text-align: right;\">        0.956671</td><td style=\"text-align: right;\">    0.129177</td></tr>\n",
       "<tr><td>train_fn_ff2f4463</td><td style=\"text-align: right;\">  0.574411</td><td style=\"text-align: right;\">    0.068436   </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.635871</td><td style=\"text-align: right;\">        0.561482</td><td style=\"text-align: right;\">    0.636894</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_fn pid=490)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(train_fn pid=490)\u001b[0m   warnings.warn(\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(train_fn pid=576)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=576)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=668)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=668)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=739)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=739)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=835)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=835)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=910)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=910)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1000)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1000)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1074)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1074)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1160)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1160)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1246)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1246)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1344)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1344)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1436)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1436)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1511)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1511)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1600)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1600)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1681)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1681)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1768)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1768)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1849)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1849)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1926)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1926)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2007)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2007)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2100)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2100)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2181)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2181)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2279)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2279)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2360)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2360)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2442)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2442)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2529)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2529)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2604)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2604)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2687)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2687)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2774)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2774)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2838)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2838)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2933)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2933)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3015)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3015)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3108)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3108)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3182)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3182)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3277)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3277)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3358)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3358)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3446)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3446)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3526)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3526)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3607)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3607)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3705)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3705)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3779)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3779)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3878)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3878)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3952)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3952)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4036)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4036)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4125)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4125)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4197)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4197)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4285)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4285)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4358)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4358)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4446)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4446)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4518)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4518)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4606)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4606)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4678)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4678)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4765)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4765)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4837)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4837)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4933)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4933)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5005)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5005)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5092)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5092)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5164)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5164)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5250)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5250)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5337)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5337)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5415)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5415)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5495)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5495)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5573)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5573)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5669)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5669)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5741)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5741)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5838)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5838)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5916)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5916)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5996)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5996)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6074)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6074)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6161)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6161)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6235)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6235)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6323)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6323)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6406)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6406)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6491)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6491)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6575)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6575)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6660)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6660)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6739)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6739)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6834)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6834)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6913)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6913)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6992)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6992)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7071)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7071)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7160)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7160)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7225)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7225)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7321)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7321)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7394)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7394)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7489)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7489)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7563)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7563)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7651)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7651)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7734)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7734)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7820)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7820)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7892)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7892)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7978)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7978)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8061)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8061)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8149)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8149)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8220)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8220)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8313)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8313)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8387)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8387)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8482)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8482)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8556)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8556)\u001b[0m   warnings.warn(\n",
      "2024-11-28 23:14:44,625\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_fn_2024-11-28_19-48-50' in 0.0436s.\n",
      "2024-11-28 23:14:44,654\tINFO tune.py:1041 -- Total run time: 12354.12 seconds (12346.46 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir /kaggle/working/tensorboard_logs\n",
    "\n",
    "\n",
    "# ray.init(ignore_reinit_error=True)\n",
    "# reporter = CLIReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "#     print_intermediate_tables=False\n",
    "# )\n",
    "\n",
    "reporter = JupyterNotebookReporter(\n",
    "    metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "    print_intermediate_tables=False\n",
    ")\n",
    "\n",
    "# tuner = tune.run(\n",
    "#     train_fn,\n",
    "#     config=search_space,\n",
    "#     num_samples=25,\n",
    "#     progress_reporter=reporter,\n",
    "#     resources_per_trial={\"cpu\": 4, \"gpu\": 2},  # Adjust resources as needed\n",
    "#     scheduler=ASHAScheduler(\n",
    "#         metric=\"accuracy\",\n",
    "#         mode=\"max\",\n",
    "#         max_t=15,\n",
    "#         grace_period=1,\n",
    "#         reduction_factor=2\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# reporter = TensorBoardReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"training_iteration\", \"train_loss\", \"train_accuracy\"]\n",
    "# )\n",
    "\n",
    "\n",
    "result = tune.run(\n",
    "    train_fn,\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "    config=search_space,\n",
    "    num_samples=100,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    search_alg=optuna_search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6772dc3",
   "metadata": {
    "papermill": {
     "duration": 0.022599,
     "end_time": "2024-11-28T23:14:44.827255",
     "exception": false,
     "start_time": "2024-11-28T23:14:44.804656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "648823fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:14:44.876767Z",
     "iopub.status.busy": "2024-11-28T23:14:44.875056Z",
     "iopub.status.idle": "2024-11-28T23:14:44.882499Z",
     "shell.execute_reply": "2024-11-28T23:14:44.881542Z"
    },
    "papermill": {
     "duration": 0.033051,
     "end_time": "2024-11-28T23:14:44.884126",
     "exception": false,
     "start_time": "2024-11-28T23:14:44.851075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'dropout_rate': 0.4, 'batch_size': 64, 'weight_decay': 5e-06, 'lr': 5e-05, 'epochs': 15}\n",
      "Best trial final validation loss: 0.5759588591754436\n",
      "Best trial final validation accuracy: 0.8047138047138047\n",
      "Best trial final training loss: 0.21815357857516834\n",
      "Best trial final training accuracy: 0.9223068877932168\n",
      "Best trial final custom_metric: 0.008944236301482611\n",
      "Best trial final Early Stopping Epoch: 4\n"
     ]
    }
   ],
   "source": [
    "# best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "# best_checkpoint_dir = best_trial.checkpoint.value\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n",
    "print(f\"Best trial final training loss: {best_trial.last_result['train_loss']}\")\n",
    "print(f\"Best trial final training accuracy: {best_trial.last_result['train_accuracy']}\")\n",
    "print(f\"Best trial final custom_metric: {best_trial.last_result['custom_metric']}\")\n",
    "print(f\"Best trial final Early Stopping Epoch: {best_trial.last_result['early_stopping_epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df57821",
   "metadata": {
    "papermill": {
     "duration": 0.022983,
     "end_time": "2024-11-28T23:14:44.930090",
     "exception": false,
     "start_time": "2024-11-28T23:14:44.907107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to Train the Model with the Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66db88a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:14:44.977183Z",
     "iopub.status.busy": "2024-11-28T23:14:44.976839Z",
     "iopub.status.idle": "2024-11-28T23:14:44.994157Z",
     "shell.execute_reply": "2024-11-28T23:14:44.993448Z"
    },
    "papermill": {
     "duration": 0.042901,
     "end_time": "2024-11-28T23:14:44.995726",
     "exception": false,
     "start_time": "2024-11-28T23:14:44.952825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_best_model(config, device, train_dataset = train_ds_pd, val_dataset = validation_ds_pd):\n",
    "    print(f\"\"\"\n",
    "    Tuning Model with:\n",
    "    {config}\n",
    "    \"\"\")\n",
    "#     model = SentimentModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=3,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    model = SentimentModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=3,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     class_weights_tmp = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weight=class_weights_tmp)\n",
    "#     criterion = nn.BCELoss()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    ## DATASET ENCODING\n",
    "    \n",
    "    train_dataset = SentimentDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = SentimentDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = None\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    \n",
    "    ### Running for config epochs +patience+1 for introducing noise. \n",
    "    \n",
    "    for epoch in range((config[\"epochs\"]+patience+1)):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = torch.zeros_like(probabilities)\n",
    "            max_indices = torch.argmax(probabilities, dim=1)\n",
    "            predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "            predictions = predictions.float()\n",
    "                \n",
    "#                 loss = criterion(predictions, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "#             outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "#             predicted_labels = (outputs > 0.5).float()\n",
    "#             correct_train_preds += (predicted_labels == labels).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "            correct_train_preds += (predictions == labels).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predictions = torch.zeros_like(probabilities)\n",
    "                max_indices = torch.argmax(probabilities, dim=1)\n",
    "                predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "                predictions = predictions.float()\n",
    "\n",
    "#                     loss = criterion(predictions, labels)\n",
    "                \n",
    "#                 outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "    \n",
    "#                 predicted_labels = (outputs > 0.5).float()\n",
    "#                 correct_val_preds += (predicted_labels == labels).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "\n",
    "                correct_val_preds += (predictions == labels).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "        checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "#         # Save the best model based on validation loss\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "#             best_model_path = checkpoint_path\n",
    "\n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_since_improvement = 0\n",
    "            best_model_path = checkpoint_path\n",
    "            # Save the model checkpoint with the best validation loss\n",
    "#             checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#             torch.save(model.state_dict(), checkpoint_path)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'config': config  # Save configuration\n",
    "            }, checkpoint_path)\n",
    "    \n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            print(f\"Best Model Epoch Saved: {epoch - patience +1}\")\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "#         if epochs_since_improvement >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "#             print(f\"Best Model Epoch Saved: {epoch - patience}\")\n",
    "#             break\n",
    "            \n",
    "#         custom_metric = calculate_custom_metric(avg_val_loss, avg_train_loss)        \n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "        print(f\"\"\"\n",
    "        Validation Loss: {avg_val_loss},\n",
    "        Training Loss: {avg_train_loss},\n",
    "        Argmax Binary Validation Accuracy: {val_accuracy},\n",
    "        Argmax Binary Training Accuracy: {train_accuracy},\n",
    "        Custom Metric: {custom_metric},\n",
    "        Epochs: {epoch+1}\n",
    "        \"\"\")\n",
    "    \n",
    "    print(f\"Best Validation Loss: {best_val_loss}, Best Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec939bf1",
   "metadata": {
    "papermill": {
     "duration": 0.030229,
     "end_time": "2024-11-28T23:14:45.051448",
     "exception": false,
     "start_time": "2024-11-28T23:14:45.021219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BEST MODEL AFTER FINAL TRAINING & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d8e60e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:14:45.099420Z",
     "iopub.status.busy": "2024-11-28T23:14:45.098649Z",
     "iopub.status.idle": "2024-11-28T23:22:39.460767Z",
     "shell.execute_reply": "2024-11-28T23:22:39.459775Z"
    },
    "papermill": {
     "duration": 474.411832,
     "end_time": "2024-11-28T23:22:39.486104",
     "exception": false,
     "start_time": "2024-11-28T23:14:45.074272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Tuning Model with:\n",
      "    {'dropout_rate': 0.4, 'batch_size': 64, 'weight_decay': 5e-06, 'lr': 5e-05, 'epochs': 15}\n",
      "    \n",
      "\n",
      "        Validation Loss: 0.4849970042705536,\n",
      "        Training Loss: 0.5900834023952484,\n",
      "        Argmax Binary Validation Accuracy: 0.7858585858585858,\n",
      "        Argmax Binary Training Accuracy: 0.6553115194979829,\n",
      "        Custom Metric: -0.1830448493453834,\n",
      "        Epochs: 1\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.4809865280985832,\n",
      "        Training Loss: 0.42321851551532746,\n",
      "        Argmax Binary Validation Accuracy: 0.7925925925925926,\n",
      "        Argmax Binary Training Accuracy: 0.8129388913790527,\n",
      "        Custom Metric: -0.27254890880915145,\n",
      "        Epochs: 2\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.49057844653725624,\n",
      "        Training Loss: 0.3384008049964905,\n",
      "        Argmax Binary Validation Accuracy: 0.7858585858585858,\n",
      "        Argmax Binary Training Accuracy: 0.8608994471836247,\n",
      "        Custom Metric: -0.18167088788842728,\n",
      "        Epochs: 3\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.46363722905516624,\n",
      "        Training Loss: 0.25341048538684846,\n",
      "        Argmax Binary Validation Accuracy: 0.8127946127946128,\n",
      "        Argmax Binary Training Accuracy: 0.9037800687285223,\n",
      "        Custom Metric: -0.19855128393833296,\n",
      "        Epochs: 4\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.5807408392429352,\n",
      "        Training Loss: 0.1811453990638256,\n",
      "        Argmax Binary Validation Accuracy: 0.8006734006734006,\n",
      "        Argmax Binary Training Accuracy: 0.9367996414164051,\n",
      "        Custom Metric: 0.047928279030591575,\n",
      "        Epochs: 5\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.5986241102218628,\n",
      "        Training Loss: 0.1389286964067391,\n",
      "        Argmax Binary Validation Accuracy: 0.7952861952861953,\n",
      "        Argmax Binary Training Accuracy: 0.9518900343642611,\n",
      "        Custom Metric: 0.1114875413822623,\n",
      "        Epochs: 6\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.6711282953619957,\n",
      "        Training Loss: 0.09407265042620046,\n",
      "        Argmax Binary Validation Accuracy: 0.7952861952861953,\n",
      "        Argmax Binary Training Accuracy: 0.9707156730912894,\n",
      "        Custom Metric: 0.2520846614462451,\n",
      "        Epochs: 7\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.714928638190031,\n",
      "        Training Loss: 0.05374053321512682,\n",
      "        Argmax Binary Validation Accuracy: 0.7993265993265993,\n",
      "        Argmax Binary Training Accuracy: 0.9861048857014791,\n",
      "        Custom Metric: 0.33958523453832373,\n",
      "        Epochs: 8\n",
      "        \n",
      "Early stopping at epoch 9\n",
      "Best Model Epoch Saved: 4\n",
      "Best Validation Loss: 0.46363722905516624, Best Validation accuracy: 0.7912457912457912\n"
     ]
    }
   ],
   "source": [
    "best_config = best_trial.config\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model with the best configuration\n",
    "best_model, best_model_path = train_best_model(best_config, device, train_ds_pd, validation_ds_pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8fc0a",
   "metadata": {
    "papermill": {
     "duration": 0.023327,
     "end_time": "2024-11-28T23:22:39.533246",
     "exception": false,
     "start_time": "2024-11-28T23:22:39.509919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94f74914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:22:39.581483Z",
     "iopub.status.busy": "2024-11-28T23:22:39.581199Z",
     "iopub.status.idle": "2024-11-28T23:22:40.796414Z",
     "shell.execute_reply": "2024-11-28T23:22:40.795423Z"
    },
    "papermill": {
     "duration": 1.241713,
     "end_time": "2024-11-28T23:22:40.798231",
     "exception": false,
     "start_time": "2024-11-28T23:22:39.556518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: /kaggle/working/final_best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "# final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path) \n",
    "\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path)\n",
    "torch.save({'model_state_dict': best_model.state_dict(),'config': best_config}, final_model_path)\n",
    "\n",
    "print(f\"Best model saved at: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd0942",
   "metadata": {
    "papermill": {
     "duration": 0.023131,
     "end_time": "2024-11-28T23:22:40.845497",
     "exception": false,
     "start_time": "2024-11-28T23:22:40.822366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ecc8fe70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:22:40.893461Z",
     "iopub.status.busy": "2024-11-28T23:22:40.893190Z",
     "iopub.status.idle": "2024-11-28T23:22:42.620708Z",
     "shell.execute_reply": "2024-11-28T23:22:42.619816Z"
    },
    "papermill": {
     "duration": 1.753562,
     "end_time": "2024-11-28T23:22:42.622376",
     "exception": false,
     "start_time": "2024-11-28T23:22:40.868814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /kaggle/working/final_best_model.pt for inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# final_model_path = \"/kaggle/input/tachygraphy-lv2-emotion-moodtags-v1/transformers/default/1/final_best_model.pt\"\n",
    "\n",
    "\n",
    "checkpoint = torch.load(final_model_path)\n",
    "config = checkpoint['config']\n",
    "\n",
    "# loaded_model = SentimentModel(\n",
    "#     roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#     n_classes=3,\n",
    "#     dropout_rate=config[\"dropout_rate\"]\n",
    "# )\n",
    "loaded_model = SentimentModel(\n",
    "    roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "    n_classes=3,\n",
    "    dropout_rate=config[\"dropout_rate\"]\n",
    ")\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(f\"Loaded model from {final_model_path} for inference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e0b11",
   "metadata": {
    "papermill": {
     "duration": 0.023314,
     "end_time": "2024-11-28T23:22:42.669620",
     "exception": false,
     "start_time": "2024-11-28T23:22:42.646306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PREDICT ON RANDOM INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c578a",
   "metadata": {
    "papermill": {
     "duration": 0.023003,
     "end_time": "2024-11-28T23:22:42.715908",
     "exception": false,
     "start_time": "2024-11-28T23:22:42.692905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "33625337",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:22:42.763832Z",
     "iopub.status.busy": "2024-11-28T23:22:42.763562Z",
     "iopub.status.idle": "2024-11-28T23:22:42.769359Z",
     "shell.execute_reply": "2024-11-28T23:22:42.768514Z"
    },
    "papermill": {
     "duration": 0.031734,
     "end_time": "2024-11-28T23:22:42.770953",
     "exception": false,
     "start_time": "2024-11-28T23:22:42.739219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, device, max_len=128):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    return torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "#     # Convert logits to probabilities using sigmoid\n",
    "#     probabilities = torch.sigmoid(logits)\n",
    "    \n",
    "#     # Convert probabilities to binary predictions\n",
    "#     predictions = torch.zeros_like(probabilities)\n",
    "#     max_indices = torch.argmax(probabilities, dim=1)\n",
    "#     predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "    \n",
    "#     # Move predictions to CPU and convert to numpy for easy manipulation\n",
    "#     predictions_array = predictions.cpu().numpy().squeeze()\n",
    "\n",
    "#     return predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bdd0c9f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:22:42.818660Z",
     "iopub.status.busy": "2024-11-28T23:22:42.818423Z",
     "iopub.status.idle": "2024-11-28T23:22:42.825422Z",
     "shell.execute_reply": "2024-11-28T23:22:42.824799Z"
    },
    "papermill": {
     "duration": 0.032334,
     "end_time": "2024-11-28T23:22:42.826921",
     "exception": false,
     "start_time": "2024-11-28T23:22:42.794587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = loaded_model\n",
    "best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "993a61c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:22:42.874644Z",
     "iopub.status.busy": "2024-11-28T23:22:42.874419Z",
     "iopub.status.idle": "2024-11-28T23:22:43.354513Z",
     "shell.execute_reply": "2024-11-28T23:22:43.353776Z"
    },
    "papermill": {
     "duration": 0.506425,
     "end_time": "2024-11-28T23:22:43.356397",
     "exception": false,
     "start_time": "2024-11-28T23:22:42.849972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb8be1",
   "metadata": {
    "papermill": {
     "duration": 0.023293,
     "end_time": "2024-11-28T23:22:43.405508",
     "exception": false,
     "start_time": "2024-11-28T23:22:43.382215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Samples & Random Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "570e568e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:22:43.453249Z",
     "iopub.status.busy": "2024-11-28T23:22:43.452968Z",
     "iopub.status.idle": "2024-11-28T23:22:45.142234Z",
     "shell.execute_reply": "2024-11-28T23:22:45.141092Z"
    },
    "papermill": {
     "duration": 1.715358,
     "end_time": "2024-11-28T23:22:45.144120",
     "exception": false,
     "start_time": "2024-11-28T23:22:43.428762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'hey! hru, wanna ply valo toni8?': [[0.0028797  0.9945649  0.00609209]]\n",
      "NEAGTIVE: 0.0, NEUTRAL: 1.0, POSITIVE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"ace5d0f6-61be-47eb-859d-f67248c87b95\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ace5d0f6-61be-47eb-859d-f67248c87b95\")) {                    Plotly.newPlot(                        \"ace5d0f6-61be-47eb-859d-f67248c87b95\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.0028797018,0.9945649,0.006092091,0.0028797018],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ace5d0f6-61be-47eb-859d-f67248c87b95');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"hey! hru, wanna ply valo toni8?\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c8b8e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:22:45.195042Z",
     "iopub.status.busy": "2024-11-28T23:22:45.194706Z",
     "iopub.status.idle": "2024-11-28T23:22:45.393114Z",
     "shell.execute_reply": "2024-11-28T23:22:45.392150Z"
    },
    "papermill": {
     "duration": 0.226103,
     "end_time": "2024-11-28T23:22:45.395028",
     "exception": false,
     "start_time": "2024-11-28T23:22:45.168925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'what a badass char is arthur, he is the best game char ever made, i luv rdr2': [[0.00166242 0.00625853 0.99487054]]\n",
      "NEAGTIVE: 0.0, NEUTRAL: 0.0, POSITIVE: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"1b69484e-ed9b-4965-ada1-736a68580372\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1b69484e-ed9b-4965-ada1-736a68580372\")) {                    Plotly.newPlot(                        \"1b69484e-ed9b-4965-ada1-736a68580372\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.00166242,0.0062585277,0.99487054,0.00166242],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1b69484e-ed9b-4965-ada1-736a68580372');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"what a badass char is arthur, he is the best game char ever made, i luv rdr2\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b017df44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-28T23:22:45.450928Z",
     "iopub.status.busy": "2024-11-28T23:22:45.450645Z",
     "iopub.status.idle": "2024-11-28T23:22:45.698039Z",
     "shell.execute_reply": "2024-11-28T23:22:45.696936Z"
    },
    "papermill": {
     "duration": 0.280285,
     "end_time": "2024-11-28T23:22:45.700774",
     "exception": false,
     "start_time": "2024-11-28T23:22:45.420489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'I don't no fr y hes sooo sad.': [[0.99298793 0.00368886 0.00628316]]\n",
      "NEAGTIVE: 1.0, NEUTRAL: 0.0, POSITIVE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"b33262a5-a094-4f68-9223-a433a74562e7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b33262a5-a094-4f68-9223-a433a74562e7\")) {                    Plotly.newPlot(                        \"b33262a5-a094-4f68-9223-a433a74562e7\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.99298793,0.0036888572,0.006283164,0.99298793],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b33262a5-a094-4f68-9223-a433a74562e7');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"I don't no fr y hes sooo sad.\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5557640,
     "sourceId": 9500773,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12876.551905,
   "end_time": "2024-11-28T23:22:51.067686",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-28T19:48:14.515781",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01e84383a0ad4368987c28f2877328a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "05cd943fbaaa4f87b0e3c2b565f423aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4da1b9e6944442b2a31a0169eb7040d9",
        "IPY_MODEL_ebbf2b4a350f45f79d99e0d3c3f469fd",
        "IPY_MODEL_53e3571346404968836917f82ff0352a"
       ],
       "layout": "IPY_MODEL_32f6fbfead334c26bc4e903ec4395911"
      }
     },
     "08d1ddf452a049f5805e3127ac6c7a3f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a3d11b5d6d847049e808a84806943ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5c533d0a982b4ffa9b78ee02f627c489",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b5578667ccdc467dbc14a05fb4ba956b",
       "value": 579.0
      }
     },
     "0ba1216bfccd494fb9405bad8eabcb32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "32f6fbfead334c26bc4e903ec4395911": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3702ea668111457a88eb436958ccbfa5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_65e2469907254e01bb5af87043f9c6b6",
       "placeholder": "​",
       "style": "IPY_MODEL_0ba1216bfccd494fb9405bad8eabcb32",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "4da1b9e6944442b2a31a0169eb7040d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_71959f573a0649cbb61ca38bf196eca1",
       "placeholder": "​",
       "style": "IPY_MODEL_f43d34ac74c84c1cb4f7f3f1c6d5c413",
       "value": "spm.model: 100%"
      }
     },
     "52429464bd09479bbba62f82bd37a2e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6466104ac31b4131a60773c930c047e9",
       "placeholder": "​",
       "style": "IPY_MODEL_f968a6b03932412c88db944ccd3f62b6",
       "value": " 52.0/52.0 [00:00&lt;00:00, 5.49kB/s]"
      }
     },
     "5269a536873848799870a4fc4c5d0303": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5ce3c75b95b342038ab49ae64713ab9b",
       "placeholder": "​",
       "style": "IPY_MODEL_01e84383a0ad4368987c28f2877328a9",
       "value": " 579/579 [00:00&lt;00:00, 62.2kB/s]"
      }
     },
     "52d95c612f7b4a67b4910a359f5da2e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53e3571346404968836917f82ff0352a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_751471583a4c4ee6b51ac3982ba0d43a",
       "placeholder": "​",
       "style": "IPY_MODEL_59964743733046dfb7b6dc9444fa8bf4",
       "value": " 2.46M/2.46M [00:00&lt;00:00, 38.7MB/s]"
      }
     },
     "59964743733046dfb7b6dc9444fa8bf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5c533d0a982b4ffa9b78ee02f627c489": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ce3c75b95b342038ab49ae64713ab9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6466104ac31b4131a60773c930c047e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65e2469907254e01bb5af87043f9c6b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68631f950b834c90ae154a108f629341": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_74e6c7cc54bc45578092b1d6609293fa",
       "placeholder": "​",
       "style": "IPY_MODEL_c72237d9941045249df7bef63889d627",
       "value": "config.json: 100%"
      }
     },
     "71959f573a0649cbb61ca38bf196eca1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74e6c7cc54bc45578092b1d6609293fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "751471583a4c4ee6b51ac3982ba0d43a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bf1693296a14ff788aa6a8929fcef52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3702ea668111457a88eb436958ccbfa5",
        "IPY_MODEL_dfa6ca16bd82499887554d3832f39cd8",
        "IPY_MODEL_52429464bd09479bbba62f82bd37a2e5"
       ],
       "layout": "IPY_MODEL_08d1ddf452a049f5805e3127ac6c7a3f"
      }
     },
     "ab16ea6c619245c59004640e8afbc1c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b5578667ccdc467dbc14a05fb4ba956b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b76c71e29eb5489bb0fa4f99b21fc102": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c72237d9941045249df7bef63889d627": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d265b14e6dc844e795619b440ae9aa77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_68631f950b834c90ae154a108f629341",
        "IPY_MODEL_0a3d11b5d6d847049e808a84806943ec",
        "IPY_MODEL_5269a536873848799870a4fc4c5d0303"
       ],
       "layout": "IPY_MODEL_52d95c612f7b4a67b4910a359f5da2e6"
      }
     },
     "dfa6ca16bd82499887554d3832f39cd8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b76c71e29eb5489bb0fa4f99b21fc102",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ab16ea6c619245c59004640e8afbc1c3",
       "value": 52.0
      }
     },
     "e86be1886ed949558a1c355d59009508": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea789f71d47641b7969c0d7faa9db2c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ebbf2b4a350f45f79d99e0d3c3f469fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e86be1886ed949558a1c355d59009508",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ea789f71d47641b7969c0d7faa9db2c9",
       "value": 2464616.0
      }
     },
     "f43d34ac74c84c1cb4f7f3f1c6d5c413": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f968a6b03932412c88db944ccd3f62b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
