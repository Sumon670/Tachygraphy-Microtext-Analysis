{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5d64b36",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:48.736140Z",
     "iopub.status.busy": "2024-08-31T20:56:48.735459Z",
     "iopub.status.idle": "2024-08-31T20:56:49.497671Z",
     "shell.execute_reply": "2024-08-31T20:56:49.496736Z"
    },
    "papermill": {
     "duration": 0.794174,
     "end_time": "2024-08-31T20:56:49.500124",
     "exception": false,
     "start_time": "2024-08-31T20:56:48.705950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_EmotionMoodtags_Dataset.csv\n",
      "/kaggle/input/dataset-tachygraphy/Tachygraphy_dataset_main.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a505a",
   "metadata": {
    "papermill": {
     "duration": 0.02702,
     "end_time": "2024-08-31T20:56:49.555877",
     "exception": false,
     "start_time": "2024-08-31T20:56:49.528857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET & PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acfa5d5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:49.610271Z",
     "iopub.status.busy": "2024-08-31T20:56:49.609872Z",
     "iopub.status.idle": "2024-08-31T20:56:49.851621Z",
     "shell.execute_reply": "2024-08-31T20:56:49.850622Z"
    },
    "papermill": {
     "duration": 0.271346,
     "end_time": "2024-08-31T20:56:49.853911",
     "exception": false,
     "start_time": "2024-08-31T20:56:49.582565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For emoji cleaning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "\n",
    "'''For emoji cleaning'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb94f625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:49.911371Z",
     "iopub.status.busy": "2024-08-31T20:56:49.910911Z",
     "iopub.status.idle": "2024-08-31T20:56:49.951674Z",
     "shell.execute_reply": "2024-08-31T20:56:49.950954Z"
    },
    "papermill": {
     "duration": 0.071705,
     "end_time": "2024-08-31T20:56:49.953679",
     "exception": false,
     "start_time": "2024-08-31T20:56:49.881974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/kaggle/input/dataset-tachygraphy/Tachygraphy_dataset_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcdce650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.008964Z",
     "iopub.status.busy": "2024-08-31T20:56:50.008687Z",
     "iopub.status.idle": "2024-08-31T20:56:50.012411Z",
     "shell.execute_reply": "2024-08-31T20:56:50.011607Z"
    },
    "papermill": {
     "duration": 0.033338,
     "end_time": "2024-08-31T20:56:50.014414",
     "exception": false,
     "start_time": "2024-08-31T20:56:49.981076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf27d030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.069705Z",
     "iopub.status.busy": "2024-08-31T20:56:50.069407Z",
     "iopub.status.idle": "2024-08-31T20:56:50.078099Z",
     "shell.execute_reply": "2024-08-31T20:56:50.077080Z"
    },
    "papermill": {
     "duration": 0.038679,
     "end_time": "2024-08-31T20:56:50.080285",
     "exception": false,
     "start_time": "2024-08-31T20:56:50.041606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text         1\n",
      "Meaning      1\n",
      "Sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db02883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.135641Z",
     "iopub.status.busy": "2024-08-31T20:56:50.135299Z",
     "iopub.status.idle": "2024-08-31T20:56:50.159091Z",
     "shell.execute_reply": "2024-08-31T20:56:50.158166Z"
    },
    "papermill": {
     "duration": 0.053806,
     "end_time": "2024-08-31T20:56:50.160986",
     "exception": false,
     "start_time": "2024-08-31T20:56:50.107180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n",
    "                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n",
    "                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n",
    "                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n",
    "                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n",
    "                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n",
    "                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n",
    "                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n",
    "                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n",
    "                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n",
    "                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n",
    "                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n",
    "                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n",
    "                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n",
    "                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n",
    "                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n",
    "                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n",
    "\n",
    "punct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n",
    "                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n",
    "                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '}\n",
    "\n",
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n",
    "                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n",
    "                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n",
    "                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n",
    "                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n",
    "                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n",
    "                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n",
    "                'demonetisation': 'demonetization'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c39b072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.215559Z",
     "iopub.status.busy": "2024-08-31T20:56:50.215279Z",
     "iopub.status.idle": "2024-08-31T20:56:50.227870Z",
     "shell.execute_reply": "2024-08-31T20:56:50.227042Z"
    },
    "papermill": {
     "duration": 0.042117,
     "end_time": "2024-08-31T20:56:50.229758",
     "exception": false,
     "start_time": "2024-08-31T20:56:50.187641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Clean emoji, Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\:(.*?)\\:','',text)\n",
    "    text = str(text).lower()    #Making Text Lowercase\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    #The next 2 lines remove html text\n",
    "    text = BeautifulSoup(text, 'lxml').get_text()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\", \"'\")\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿']+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    '''Clean contraction using contraction mapping'''    \n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    for word in mapping.keys():\n",
    "        if \"\"+word+\"\" in text:\n",
    "            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n",
    "    #Remove Punctuations\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "    return text\n",
    "\n",
    "def clean_special_chars(text, punct, mapping):\n",
    "    '''Cleans special characters present(if any)'''   \n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    \n",
    "    for p in punct:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    \n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def correct_spelling(x, dic):\n",
    "    '''Corrects common spelling errors'''   \n",
    "    for word in dic.keys():\n",
    "        x = x.replace(word, dic[word])\n",
    "    return x\n",
    "\n",
    "def remove_space(text):\n",
    "    '''Removes awkward spaces'''   \n",
    "    #Removes awkward spaces \n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "854fdffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.284762Z",
     "iopub.status.busy": "2024-08-31T20:56:50.284434Z",
     "iopub.status.idle": "2024-08-31T20:56:50.289307Z",
     "shell.execute_reply": "2024-08-31T20:56:50.288558Z"
    },
    "papermill": {
     "duration": 0.034307,
     "end_time": "2024-08-31T20:56:50.291270",
     "exception": false,
     "start_time": "2024-08-31T20:56:50.256963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing_pipeline(text):\n",
    "    '''Cleaning and parsing the text.'''\n",
    "    text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_text(text)\n",
    "    text = clean_contractions(text, contraction_mapping)\n",
    "    text = clean_special_chars(text, punct, punct_mapping)\n",
    "#     text = correct_spelling(text, mispell_dict)\n",
    "    text = remove_space(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ea9aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.347126Z",
     "iopub.status.busy": "2024-08-31T20:56:50.346862Z",
     "iopub.status.idle": "2024-08-31T20:56:50.355113Z",
     "shell.execute_reply": "2024-08-31T20:56:50.354195Z"
    },
    "papermill": {
     "duration": 0.038482,
     "end_time": "2024-08-31T20:56:50.356948",
     "exception": false,
     "start_time": "2024-08-31T20:56:50.318466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'Text':'text', 'Sentiment':'sentiment_polarity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d273fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.412820Z",
     "iopub.status.busy": "2024-08-31T20:56:50.412550Z",
     "iopub.status.idle": "2024-08-31T20:56:50.421257Z",
     "shell.execute_reply": "2024-08-31T20:56:50.420474Z"
    },
    "papermill": {
     "duration": 0.038277,
     "end_time": "2024-08-31T20:56:50.423051",
     "exception": false,
     "start_time": "2024-08-31T20:56:50.384774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Meaning'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ca7937f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.477976Z",
     "iopub.status.busy": "2024-08-31T20:56:50.477430Z",
     "iopub.status.idle": "2024-08-31T20:56:50.485996Z",
     "shell.execute_reply": "2024-08-31T20:56:50.485197Z"
    },
    "papermill": {
     "duration": 0.03838,
     "end_time": "2024-08-31T20:56:50.488167",
     "exception": false,
     "start_time": "2024-08-31T20:56:50.449787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['text', 'sentiment_polarity'], inplace=True) # Dropping NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23d8336a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.547648Z",
     "iopub.status.busy": "2024-08-31T20:56:50.546937Z",
     "iopub.status.idle": "2024-08-31T20:56:50.563977Z",
     "shell.execute_reply": "2024-08-31T20:56:50.563063Z"
    },
    "papermill": {
     "duration": 0.047599,
     "end_time": "2024-08-31T20:56:50.565873",
     "exception": false,
     "start_time": "2024-08-31T20:56:50.518274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4957 entries, 0 to 4957\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   text                4957 non-null   object\n",
      " 1   sentiment_polarity  4957 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 116.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# df['text'] = df['text'].astype('str')\n",
    "# df['sentiment_polarity'] = df['sentiment_polarity'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa5b79a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:50.620441Z",
     "iopub.status.busy": "2024-08-31T20:56:50.620185Z",
     "iopub.status.idle": "2024-08-31T20:56:54.829757Z",
     "shell.execute_reply": "2024-08-31T20:56:54.828940Z"
    },
    "papermill": {
     "duration": 4.239705,
     "end_time": "2024-08-31T20:56:54.832025",
     "exception": false,
     "start_time": "2024-08-31T20:56:50.592320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: text_preprocessing_pipeline(x))\n",
    "df['sentiment_polarity'] = df['sentiment_polarity'].apply(lambda x: text_preprocessing_pipeline(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23cdd537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:54.890777Z",
     "iopub.status.busy": "2024-08-31T20:56:54.890006Z",
     "iopub.status.idle": "2024-08-31T20:56:54.903609Z",
     "shell.execute_reply": "2024-08-31T20:56:54.902699Z"
    },
    "papermill": {
     "duration": 0.045008,
     "end_time": "2024-08-31T20:56:54.905668",
     "exception": false,
     "start_time": "2024-08-31T20:56:54.860660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>make a pet face wtf wrong with me tonight haha</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>i dnt care anymore boyz is not worth d drama</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>no relationship is perfect tho me bae goo from...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>over here tryna get my nail polishes and shit lol</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>no one was loved d way i luv u</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment_polarity\n",
       "0                               last session of the day            neutral\n",
       "1     shanghai is also really exciting precisely sky...           positive\n",
       "2                                submit the report asap           negative\n",
       "3                                            happy bday           positive\n",
       "4                                     the ogs i like it           positive\n",
       "...                                                 ...                ...\n",
       "4953     make a pet face wtf wrong with me tonight haha           negative\n",
       "4954       i dnt care anymore boyz is not worth d drama           negative\n",
       "4955  no relationship is perfect tho me bae goo from...           negative\n",
       "4956  over here tryna get my nail polishes and shit lol           negative\n",
       "4957                     no one was loved d way i luv u           positive\n",
       "\n",
       "[4957 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52bcd56a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:54.960836Z",
     "iopub.status.busy": "2024-08-31T20:56:54.960533Z",
     "iopub.status.idle": "2024-08-31T20:56:54.968570Z",
     "shell.execute_reply": "2024-08-31T20:56:54.967886Z"
    },
    "papermill": {
     "duration": 0.038026,
     "end_time": "2024-08-31T20:56:54.970543",
     "exception": false,
     "start_time": "2024-08-31T20:56:54.932517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_polar = pd.get_dummies(df['sentiment_polarity'], prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af5c829d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.026561Z",
     "iopub.status.busy": "2024-08-31T20:56:55.025880Z",
     "iopub.status.idle": "2024-08-31T20:56:55.029822Z",
     "shell.execute_reply": "2024-08-31T20:56:55.029047Z"
    },
    "papermill": {
     "duration": 0.034114,
     "end_time": "2024-08-31T20:56:55.031731",
     "exception": false,
     "start_time": "2024-08-31T20:56:54.997617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bin_polar = bin_polar.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68afe1a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.122355Z",
     "iopub.status.busy": "2024-08-31T20:56:55.121689Z",
     "iopub.status.idle": "2024-08-31T20:56:55.133306Z",
     "shell.execute_reply": "2024-08-31T20:56:55.132441Z"
    },
    "papermill": {
     "duration": 0.041839,
     "end_time": "2024-08-31T20:56:55.135520",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.093681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4957 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      negative  neutral  positive\n",
       "0            0        1         0\n",
       "1            0        0         1\n",
       "2            1        0         0\n",
       "3            0        0         1\n",
       "4            0        0         1\n",
       "...        ...      ...       ...\n",
       "4953         1        0         0\n",
       "4954         1        0         0\n",
       "4955         1        0         0\n",
       "4956         1        0         0\n",
       "4957         0        0         1\n",
       "\n",
       "[4957 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_polar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17f123c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.192866Z",
     "iopub.status.busy": "2024-08-31T20:56:55.192579Z",
     "iopub.status.idle": "2024-08-31T20:56:55.204695Z",
     "shell.execute_reply": "2024-08-31T20:56:55.203643Z"
    },
    "papermill": {
     "duration": 0.042197,
     "end_time": "2024-08-31T20:56:55.206669",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.164472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            last session of the day            neutral   \n",
       "1  shanghai is also really exciting precisely sky...           positive   \n",
       "2                             submit the report asap           negative   \n",
       "3                                         happy bday           positive   \n",
       "4                                  the ogs i like it           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, bin_polar], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ef2c1b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.263219Z",
     "iopub.status.busy": "2024-08-31T20:56:55.262912Z",
     "iopub.status.idle": "2024-08-31T20:56:55.272991Z",
     "shell.execute_reply": "2024-08-31T20:56:55.272162Z"
    },
    "papermill": {
     "duration": 0.040572,
     "end_time": "2024-08-31T20:56:55.274920",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.234348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0                            last session of the day            neutral   \n",
       "1  shanghai is also really exciting precisely sky...           positive   \n",
       "2                             submit the report asap           negative   \n",
       "3                                         happy bday           positive   \n",
       "4                                  the ogs i like it           positive   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        1         0  \n",
       "1         0        0         1  \n",
       "2         1        0         0  \n",
       "3         0        0         1  \n",
       "4         0        0         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.drop(columns=['sentiment_polarity'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fec8a439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.331450Z",
     "iopub.status.busy": "2024-08-31T20:56:55.331129Z",
     "iopub.status.idle": "2024-08-31T20:56:55.341430Z",
     "shell.execute_reply": "2024-08-31T20:56:55.340540Z"
    },
    "papermill": {
     "duration": 0.041084,
     "end_time": "2024-08-31T20:56:55.343828",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.302744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4957 entries, 0 to 4957\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   text                4957 non-null   object\n",
      " 1   sentiment_polarity  4957 non-null   object\n",
      " 2   negative            4957 non-null   int64 \n",
      " 3   neutral             4957 non-null   int64 \n",
      " 4   positive            4957 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 232.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8fc7927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.401160Z",
     "iopub.status.busy": "2024-08-31T20:56:55.400845Z",
     "iopub.status.idle": "2024-08-31T20:56:55.404815Z",
     "shell.execute_reply": "2024-08-31T20:56:55.403890Z"
    },
    "papermill": {
     "duration": 0.034767,
     "end_time": "2024-08-31T20:56:55.406738",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.371971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_polarity_label_mapping = {\n",
    "    0: \"negative\", 1: \"neutral\", 2: \"positive\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dd07df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.463961Z",
     "iopub.status.busy": "2024-08-31T20:56:55.463459Z",
     "iopub.status.idle": "2024-08-31T20:56:55.467555Z",
     "shell.execute_reply": "2024-08-31T20:56:55.466705Z"
    },
    "papermill": {
     "duration": 0.034355,
     "end_time": "2024-08-31T20:56:55.469478",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.435123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_polarity_label_mapping_rev = {\n",
    "    'negative': 0, 'neutral': 1, 'positive': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "489d4988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.529071Z",
     "iopub.status.busy": "2024-08-31T20:56:55.528780Z",
     "iopub.status.idle": "2024-08-31T20:56:55.532592Z",
     "shell.execute_reply": "2024-08-31T20:56:55.531777Z"
    },
    "papermill": {
     "duration": 0.035709,
     "end_time": "2024-08-31T20:56:55.534730",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.499021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SENTIMENT_POLARITY_LABELS = [\n",
    "    \"negative\", \"neutral\", \"positive\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ca10084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.591076Z",
     "iopub.status.busy": "2024-08-31T20:56:55.590796Z",
     "iopub.status.idle": "2024-08-31T20:56:55.595144Z",
     "shell.execute_reply": "2024-08-31T20:56:55.594227Z"
    },
    "papermill": {
     "duration": 0.034744,
     "end_time": "2024-08-31T20:56:55.597116",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.562372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_train_split(dataset, test_ratio=0.1):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "947e4aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.653792Z",
     "iopub.status.busy": "2024-08-31T20:56:55.653503Z",
     "iopub.status.idle": "2024-08-31T20:56:55.660303Z",
     "shell.execute_reply": "2024-08-31T20:56:55.659224Z"
    },
    "papermill": {
     "duration": 0.037088,
     "end_time": "2024-08-31T20:56:55.662390",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.625302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4447 examples in training, 510 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "train_ds_pd, validation_ds_pd = test_train_split(df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_ds_pd), len(validation_ds_pd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e84307e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.723321Z",
     "iopub.status.busy": "2024-08-31T20:56:55.722964Z",
     "iopub.status.idle": "2024-08-31T20:56:55.728555Z",
     "shell.execute_reply": "2024-08-31T20:56:55.727840Z"
    },
    "papermill": {
     "duration": 0.038127,
     "end_time": "2024-08-31T20:56:55.730415",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.692288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd = train_ds_pd.reset_index(drop=True)\n",
    "validation_ds_pd = validation_ds_pd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e5cef44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.788798Z",
     "iopub.status.busy": "2024-08-31T20:56:55.788071Z",
     "iopub.status.idle": "2024-08-31T20:56:55.798499Z",
     "shell.execute_reply": "2024-08-31T20:56:55.797547Z"
    },
    "papermill": {
     "duration": 0.040975,
     "end_time": "2024-08-31T20:56:55.800374",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.759399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that is great weee visitors</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think everyone hates me on here lol</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_polarity  \\\n",
       "0  shanghai is also really exciting precisely sky...           positive   \n",
       "1                                         happy bday           positive   \n",
       "2                                  the ogs i like it           positive   \n",
       "3                        that is great weee visitors           positive   \n",
       "4              i think everyone hates me on here lol           negative   \n",
       "\n",
       "   negative  neutral  positive  \n",
       "0         0        0         1  \n",
       "1         0        0         1  \n",
       "2         0        0         1  \n",
       "3         0        0         1  \n",
       "4         1        0         0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c98d1704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.859002Z",
     "iopub.status.busy": "2024-08-31T20:56:55.858487Z",
     "iopub.status.idle": "2024-08-31T20:56:55.864813Z",
     "shell.execute_reply": "2024-08-31T20:56:55.863782Z"
    },
    "papermill": {
     "duration": 0.038307,
     "end_time": "2024-08-31T20:56:55.866836",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.828529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', ..., 'negative', 'negative',\n",
       "       'positive'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_labels = np.array(train_ds_pd['sentiment_polarity'])\n",
    "sentiment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d30bba1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.924918Z",
     "iopub.status.busy": "2024-08-31T20:56:55.924631Z",
     "iopub.status.idle": "2024-08-31T20:56:55.930182Z",
     "shell.execute_reply": "2024-08-31T20:56:55.929456Z"
    },
    "papermill": {
     "duration": 0.036972,
     "end_time": "2024-08-31T20:56:55.932258",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.895286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds_pd.drop(columns=['sentiment_polarity'], inplace=True)\n",
    "validation_ds_pd.drop(columns=['sentiment_polarity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe55b0e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:55.992452Z",
     "iopub.status.busy": "2024-08-31T20:56:55.992167Z",
     "iopub.status.idle": "2024-08-31T20:56:56.001578Z",
     "shell.execute_reply": "2024-08-31T20:56:56.000696Z"
    },
    "papermill": {
     "duration": 0.040968,
     "end_time": "2024-08-31T20:56:56.003925",
     "exception": false,
     "start_time": "2024-08-31T20:56:55.962957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy bday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the ogs i like it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that is great weee visitors</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think everyone hates me on here lol</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  neutral  \\\n",
       "0  shanghai is also really exciting precisely sky...         0        0   \n",
       "1                                         happy bday         0        0   \n",
       "2                                  the ogs i like it         0        0   \n",
       "3                        that is great weee visitors         0        0   \n",
       "4              i think everyone hates me on here lol         1        0   \n",
       "\n",
       "   positive  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc6d337b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:56.065465Z",
     "iopub.status.busy": "2024-08-31T20:56:56.064887Z",
     "iopub.status.idle": "2024-08-31T20:56:56.074007Z",
     "shell.execute_reply": "2024-08-31T20:56:56.073197Z"
    },
    "papermill": {
     "duration": 0.041013,
     "end_time": "2024-08-31T20:56:56.076281",
     "exception": false,
     "start_time": "2024-08-31T20:56:56.035268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>last session of the day</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>submit the report asap</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stupid storm no river for us tonight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u from u tweet too much</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hi there i agree small children should be runn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative  neutral  \\\n",
       "0                            last session of the day         0        1   \n",
       "1                             submit the report asap         1        0   \n",
       "2               stupid storm no river for us tonight         1        0   \n",
       "3                            u from u tweet too much         1        0   \n",
       "4  hi there i agree small children should be runn...         0        0   \n",
       "\n",
       "   positive  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_ds_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ceec220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:56.137564Z",
     "iopub.status.busy": "2024-08-31T20:56:56.137251Z",
     "iopub.status.idle": "2024-08-31T20:56:56.144998Z",
     "shell.execute_reply": "2024-08-31T20:56:56.143996Z"
    },
    "papermill": {
     "duration": 0.039803,
     "end_time": "2024-08-31T20:56:56.146921",
     "exception": false,
     "start_time": "2024-08-31T20:56:56.107118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_indexed_labels = np.array([sentiment_polarity_label_mapping_rev[label] for label in sentiment_labels])\n",
    "sentiment_indexed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc9e01a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:56.207263Z",
     "iopub.status.busy": "2024-08-31T20:56:56.206962Z",
     "iopub.status.idle": "2024-08-31T20:56:59.520051Z",
     "shell.execute_reply": "2024-08-31T20:56:59.519173Z"
    },
    "papermill": {
     "duration": 3.345867,
     "end_time": "2024-08-31T20:56:59.522436",
     "exception": false,
     "start_time": "2024-08-31T20:56:56.176569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c95d1",
   "metadata": {
    "papermill": {
     "duration": 0.028935,
     "end_time": "2024-08-31T20:56:59.581476",
     "exception": false,
     "start_time": "2024-08-31T20:56:59.552541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Calculating Class Weights for each labels to avoid imbalanced distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "592caae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:59.641319Z",
     "iopub.status.busy": "2024-08-31T20:56:59.640839Z",
     "iopub.status.idle": "2024-08-31T20:56:59.726730Z",
     "shell.execute_reply": "2024-08-31T20:56:59.725873Z"
    },
    "papermill": {
     "duration": 0.118362,
     "end_time": "2024-08-31T20:56:59.728659",
     "exception": false,
     "start_time": "2024-08-31T20:56:59.610297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3484, 0.3169, 0.3347])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = np.bincount(sentiment_indexed_labels)\n",
    "total_samples = len(sentiment_labels)\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d88fc3",
   "metadata": {
    "papermill": {
     "duration": 0.028715,
     "end_time": "2024-08-31T20:56:59.786515",
     "exception": false,
     "start_time": "2024-08-31T20:56:59.757800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class Weight NOTE\n",
    "### This class weights are for the training dataset and are to be used while training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1650b0",
   "metadata": {
    "papermill": {
     "duration": 0.028784,
     "end_time": "2024-08-31T20:56:59.844225",
     "exception": false,
     "start_time": "2024-08-31T20:56:59.815441",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SETTING CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47d6877f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:56:59.906087Z",
     "iopub.status.busy": "2024-08-31T20:56:59.905772Z",
     "iopub.status.idle": "2024-08-31T20:56:59.992183Z",
     "shell.execute_reply": "2024-08-31T20:56:59.991291Z"
    },
    "papermill": {
     "duration": 0.119351,
     "end_time": "2024-08-31T20:56:59.994110",
     "exception": false,
     "start_time": "2024-08-31T20:56:59.874759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "578fe8db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:00.053705Z",
     "iopub.status.busy": "2024-08-31T20:57:00.053379Z",
     "iopub.status.idle": "2024-08-31T20:57:02.314425Z",
     "shell.execute_reply": "2024-08-31T20:57:02.313631Z"
    },
    "papermill": {
     "duration": 2.293094,
     "end_time": "2024-08-31T20:57:02.316792",
     "exception": false,
     "start_time": "2024-08-31T20:57:00.023698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import DebertaV2Model, DebertaV2Tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5331845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:02.377088Z",
     "iopub.status.busy": "2024-08-31T20:57:02.376613Z",
     "iopub.status.idle": "2024-08-31T20:57:04.099210Z",
     "shell.execute_reply": "2024-08-31T20:57:04.098208Z"
    },
    "papermill": {
     "duration": 1.754623,
     "end_time": "2024-08-31T20:57:04.101370",
     "exception": false,
     "start_time": "2024-08-31T20:57:02.346747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe491bc733a468290f12483f2b3d01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856aade1245842ed816c83632d17b8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47a0c5239844f9f8bb8b6f78d10ec60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306a804",
   "metadata": {
    "papermill": {
     "duration": 0.029321,
     "end_time": "2024-08-31T20:57:04.160982",
     "exception": false,
     "start_time": "2024-08-31T20:57:04.131661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TORCH IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c691ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:04.223218Z",
     "iopub.status.busy": "2024-08-31T20:57:04.222359Z",
     "iopub.status.idle": "2024-08-31T20:57:20.094169Z",
     "shell.execute_reply": "2024-08-31T20:57:20.093195Z"
    },
    "papermill": {
     "duration": 15.905514,
     "end_time": "2024-08-31T20:57:20.096568",
     "exception": false,
     "start_time": "2024-08-31T20:57:04.191054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 20:57:06,155\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-08-31 20:57:06,678\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "# from optuna.integration import PyTorchLightningPruner\n",
    "from ray import tune\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from ray.tune.integration.pytorch import TuneReportCallback\n",
    "from torch.amp import GradScaler, autocast\n",
    "# from ray.tune.integration.optuna import OptunaSearch\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from torch import autocast\n",
    "# from ray import tune\n",
    "# from ray.tune.integration.tensorboard import TensorBoardReporter\n",
    "from ray.tune.logger import TBXLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ray.train import report\n",
    "# from ray.tune.integration.jupyter import JupyterNotebookReporter\n",
    "from ray.tune import JupyterNotebookReporter\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from ray.tune.schedulers import HyperBandScheduler, AsyncHyperBandScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a55697",
   "metadata": {
    "papermill": {
     "duration": 0.029652,
     "end_time": "2024-08-31T20:57:20.156194",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.126542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATASET CONFIG & ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dabad52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:20.217640Z",
     "iopub.status.busy": "2024-08-31T20:57:20.216376Z",
     "iopub.status.idle": "2024-08-31T20:57:20.225480Z",
     "shell.execute_reply": "2024-08-31T20:57:20.224469Z"
    },
    "papermill": {
     "duration": 0.041902,
     "end_time": "2024-08-31T20:57:20.227667",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.185765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         text = self.data.iloc[index, 0]\n",
    "#         labels = self.data.iloc[index, 1:].values.astype(float)\n",
    "        text = str(self.data.iloc[index]['text'])\n",
    "        labels = self.data.iloc[index][['negative', 'neutral', 'positive']].values.astype(np.float32)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a43a69e",
   "metadata": {
    "papermill": {
     "duration": 0.029758,
     "end_time": "2024-08-31T20:57:20.287104",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.257346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c96e9556",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:20.348285Z",
     "iopub.status.busy": "2024-08-31T20:57:20.347971Z",
     "iopub.status.idle": "2024-08-31T20:57:20.355213Z",
     "shell.execute_reply": "2024-08-31T20:57:20.354339Z"
    },
    "papermill": {
     "duration": 0.040735,
     "end_time": "2024-08-31T20:57:20.357389",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.316654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        self.roberta = roberta_model\n",
    "        self.drop = nn.Dropout(p=dropout_rate)\n",
    "        self.fc1 = nn.Linear(self.roberta.config.hidden_size, 256)  # Reduced neurons\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(256, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get the RoBERTa output\n",
    "        output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_token_state = output.last_hidden_state[:, 0, :]\n",
    "        # Pass through the custom layers\n",
    "        output = self.drop(cls_token_state)\n",
    "        output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c579469",
   "metadata": {
    "papermill": {
     "duration": 0.029562,
     "end_time": "2024-08-31T20:57:20.417149",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.387587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Other Models to try out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "071655e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:20.478143Z",
     "iopub.status.busy": "2024-08-31T20:57:20.477843Z",
     "iopub.status.idle": "2024-08-31T20:57:20.482700Z",
     "shell.execute_reply": "2024-08-31T20:57:20.481867Z"
    },
    "papermill": {
     "duration": 0.037462,
     "end_time": "2024-08-31T20:57:20.484635",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.447173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class SentimentModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(SentimentModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size, 512)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.out = nn.Linear(256, n_classes)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         # Get the RoBERTa output\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         cls_token_state = output.last_hidden_state[:, 0, :]\n",
    "#         # Pass through the custom layers\n",
    "#         output = self.drop(cls_token_state)\n",
    "# #         output = cls_token_state\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "# #         output = self.drop(output)\n",
    "#         return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "741d46bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:20.548343Z",
     "iopub.status.busy": "2024-08-31T20:57:20.548062Z",
     "iopub.status.idle": "2024-08-31T20:57:20.552872Z",
     "shell.execute_reply": "2024-08-31T20:57:20.552122Z"
    },
    "papermill": {
     "duration": 0.03887,
     "end_time": "2024-08-31T20:57:20.554732",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.515862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class AdvancedPooling(nn.Module):\n",
    "#     def __init__(self, hidden_size):\n",
    "#         super(AdvancedPooling, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#     def forward(self, hidden_states):\n",
    "#         cls_output = hidden_states[:, 0, :]  # [CLS] token output\n",
    "#         mean_output = hidden_states.mean(dim=1)  # Mean pooling over sequence\n",
    "#         max_output, _ = hidden_states.max(dim=1)  # Max pooling over sequence\n",
    "#         combined_output = torch.cat([cls_output, mean_output, max_output], dim=1)\n",
    "#         return combined_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f52a6fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:20.615521Z",
     "iopub.status.busy": "2024-08-31T20:57:20.614963Z",
     "iopub.status.idle": "2024-08-31T20:57:20.619846Z",
     "shell.execute_reply": "2024-08-31T20:57:20.619011Z"
    },
    "papermill": {
     "duration": 0.037264,
     "end_time": "2024-08-31T20:57:20.621830",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.584566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class SentimentModel(nn.Module):\n",
    "#     def __init__(self, roberta_model, n_classes, dropout_rate):\n",
    "#         super(SentimentModel, self).__init__()\n",
    "#         self.roberta = roberta_model\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.fc1 = nn.Linear(self.roberta.config.hidden_size * 3, 512)\n",
    "#         self.attention_pooling = AdvancedPooling(hidden_size=self.roberta.config.hidden_size)\n",
    "#         self.drop = nn.Dropout(p=dropout_rate)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.out = nn.Linear(256, n_classes)\n",
    "#         self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask):\n",
    "#         output = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         cls_output = output.last_hidden_state[:, 0, :]  # Extract [CLS] token representation\n",
    "#         hidden_states = output.last_hidden_state  # Sequence hidden states\n",
    "#         pooled_output = self.attention_pooling(hidden_states)  # Attention pooling  # Combine CLS and attention pooling\n",
    "#         output = self.drop(pooled_output)\n",
    "#         output = self.relu(self.fc1(output))\n",
    "#         output = self.drop(output)\n",
    "#         output = self.relu(self.fc2(output))\n",
    "#         output = self.drop(output)\n",
    "#         return self.out(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01860fee",
   "metadata": {
    "papermill": {
     "duration": 0.03044,
     "end_time": "2024-08-31T20:57:20.681673",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.651233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRAIN & VALIDATION\n",
    "### Custom metric is a metric for determining the best model free from any overfitting, underfitting. ```custom_metric = (avg_val_loss−val_accuracy) + α × ∣avg_train_loss−avg_val_loss∣ + β × ∣val_accuracy-train_accuracy∣``` This metric balances between low validation loss, high validation accuracy, and penalizing large discrepancies between training and validation loss. Note that, in the model selection we have used ```α = β = 0.5```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd3a3c",
   "metadata": {
    "papermill": {
     "duration": 0.029726,
     "end_time": "2024-08-31T20:57:20.741342",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.711616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### But, if we have probabilistic values as input and output we cannot directly calculate the accuracy, infact we need to rely on loss only. ```custom_metric = avg_val_loss + α × ∣avg_train_loss−avg_val_loss∣```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a6766fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:20.802750Z",
     "iopub.status.busy": "2024-08-31T20:57:20.802007Z",
     "iopub.status.idle": "2024-08-31T20:57:20.807198Z",
     "shell.execute_reply": "2024-08-31T20:57:20.806292Z"
    },
    "papermill": {
     "duration": 0.037725,
     "end_time": "2024-08-31T20:57:20.809050",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.771325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom metric calculation function\n",
    "def calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy, alpha=0.5, beta=0.5):\n",
    "    loss_diff = abs(avg_train_loss - avg_val_loss)\n",
    "    accuracy_diff = abs(train_accuracy - val_accuracy)\n",
    "    custom_metric = avg_val_loss - val_accuracy + alpha * loss_diff + beta * accuracy_diff\n",
    "    return custom_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e3e0f",
   "metadata": {
    "papermill": {
     "duration": 0.029613,
     "end_time": "2024-08-31T20:57:20.868527",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.838914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8759cae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:20.930541Z",
     "iopub.status.busy": "2024-08-31T20:57:20.930265Z",
     "iopub.status.idle": "2024-08-31T20:57:20.937403Z",
     "shell.execute_reply": "2024-08-31T20:57:20.936469Z"
    },
    "papermill": {
     "duration": 0.040471,
     "end_time": "2024-08-31T20:57:20.939460",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.898989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        EarlyStopping to stop training when a metric has stopped improving.\n",
    "\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "            delta (float): Minimum change to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss improved to {val_loss:.4f}')\n",
    "#             torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        else:\n",
    "            self.counter += 1\n",
    "#             if self.verbose:\n",
    "#                 print(f'Validation loss did not improve. Patience: {self.patience}, Counter: {self.counter}')\n",
    "        \n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ddcda5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:21.011616Z",
     "iopub.status.busy": "2024-08-31T20:57:21.011171Z",
     "iopub.status.idle": "2024-08-31T20:57:21.036634Z",
     "shell.execute_reply": "2024-08-31T20:57:21.035788Z"
    },
    "papermill": {
     "duration": 0.058826,
     "end_time": "2024-08-31T20:57:21.038702",
     "exception": false,
     "start_time": "2024-08-31T20:57:20.979876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training function with variable parameters\n",
    "def train_model(config, train_dataset, val_dataset, device):\n",
    "#     model = SentimentModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=3,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    \n",
    "    model = SentimentModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=3,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     class_weights_tmp = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weight=class_weights_tmp)\n",
    "#     criterion = nn.BCELoss()\n",
    "    scaler = GradScaler()  # Initialize GradScaler\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "    \n",
    "    for epoch in range(config[\"epochs\"]):  # Ensure epochs are passed from config\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):  # Mixed precision\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = torch.zeros_like(probabilities)\n",
    "            max_indices = torch.argmax(probabilities, dim=1)\n",
    "            predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "            predictions = predictions.float()\n",
    "                \n",
    "#                 loss = criterion(predictions, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "#             outputs = torch.sigmoid(outputs)  \n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "#             predicted_labels = (outputs > 0.5).float()\n",
    "#             correct_train_preds += (predicted_labels == labels).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "            correct_train_preds += (predictions == labels).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "                \n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predictions = torch.zeros_like(probabilities)\n",
    "                max_indices = torch.argmax(probabilities, dim=1)\n",
    "                predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "                predictions = predictions.float()\n",
    "                \n",
    "#                     loss = criterion(predictions, labels)\n",
    "                    \n",
    "#                 outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "    \n",
    "#                 predicted_labels = (outputs > 0.5).float()\n",
    "#                 correct_val_preds += (predicted_labels == labels).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "\n",
    "                correct_val_preds += (predictions == labels).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "#         custom_metric = avg_val_loss - val_accuracy\n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "\n",
    "        # Report metrics using ray.train.report\n",
    "        report({\n",
    "            \"loss\": avg_val_loss,\n",
    "            \"accuracy\": val_accuracy,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"custom_metric\": custom_metric,\n",
    "            \"early_stopping_epoch\": epoch + 1,\n",
    "        })\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Check for early stopping\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "#         trial_dir = os.path.join(os.environ[\"TUNE_TRIAL_DIR\"], \"checkpoint.pt\")\n",
    "#         torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "#         checkpoint_path = f\"/kaggle/working/checkpoint_epoch_{epoch}.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_fn(config):\n",
    "    # Load your data here\n",
    "#     tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "    train_dataset = SentimentDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = SentimentDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_model(config, train_dataset, val_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1bdc85",
   "metadata": {
    "papermill": {
     "duration": 0.031179,
     "end_time": "2024-08-31T20:57:21.100823",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.069644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64389559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:21.162894Z",
     "iopub.status.busy": "2024-08-31T20:57:21.162620Z",
     "iopub.status.idle": "2024-08-31T20:57:21.168739Z",
     "shell.execute_reply": "2024-08-31T20:57:21.167912Z"
    },
    "papermill": {
     "duration": 0.039133,
     "end_time": "2024-08-31T20:57:21.170656",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.131523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'dropout_rate': tune.choice([0.2, 0.25, 0.27, 0.3, 0.32, 0.35, 0.4]),\n",
    "    'batch_size': tune.choice([32, 64]),\n",
    "    'weight_decay': tune.choice([1e-6, 2e-6, 1e-5, 2e-5, 1e-4, 2e-4, 5e-5, 5e-6, 1e-2, 1e-3]),\n",
    "    'lr': tune.choice([1e-6, 1e-5, 2e-5, 1e-4, 2e-4, 2e-6, 3e-6, 5e-6, 3e-5, 5e-5, 2e-7, 1e-7, 1e-3, 5e-7]),\n",
    "    'epochs': tune.choice([5, 7, 10, 12, 15, 20])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2b98661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:21.231910Z",
     "iopub.status.busy": "2024-08-31T20:57:21.231601Z",
     "iopub.status.idle": "2024-08-31T20:57:21.235506Z",
     "shell.execute_reply": "2024-08-31T20:57:21.234652Z"
    },
    "papermill": {
     "duration": 0.036857,
     "end_time": "2024-08-31T20:57:21.237470",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.200613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     'dropout_rate': tune.uniform(0.1, 0.5),\n",
    "#     'batch_size': tune.choice([16, 32, 64]),\n",
    "#     'weight_decay': tune.loguniform(1e-6, 1e-1),\n",
    "#     'lr': tune.loguniform(1e-6, 1e-1),\n",
    "#     'epochs': tune.choice([5, 7, 10, 12, 15, 20])\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5cfffd",
   "metadata": {
    "papermill": {
     "duration": 0.029531,
     "end_time": "2024-08-31T20:57:21.296835",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.267304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SEARCH ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f30f9267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:21.357134Z",
     "iopub.status.busy": "2024-08-31T20:57:21.356824Z",
     "iopub.status.idle": "2024-08-31T20:57:21.361265Z",
     "shell.execute_reply": "2024-08-31T20:57:21.360212Z"
    },
    "papermill": {
     "duration": 0.037315,
     "end_time": "2024-08-31T20:57:21.363546",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.326231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna_search = OptunaSearch(\n",
    "    metric=[\"accuracy\",\"custom_metric\"],\n",
    "    mode=[\"max\",\"min\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d039c635",
   "metadata": {
    "papermill": {
     "duration": 0.032101,
     "end_time": "2024-08-31T20:57:21.427491",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.395390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SCHEDULER ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ef2894c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:21.494293Z",
     "iopub.status.busy": "2024-08-31T20:57:21.493759Z",
     "iopub.status.idle": "2024-08-31T20:57:21.498827Z",
     "shell.execute_reply": "2024-08-31T20:57:21.497733Z"
    },
    "papermill": {
     "duration": 0.041385,
     "end_time": "2024-08-31T20:57:21.501188",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.459803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric='accuracy',\n",
    "    mode='max',\n",
    "    max_t=22,\n",
    "    grace_period=3,\n",
    "    reduction_factor=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f4678",
   "metadata": {
    "papermill": {
     "duration": 0.030361,
     "end_time": "2024-08-31T20:57:21.567241",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.536880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39da5127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:21.627413Z",
     "iopub.status.busy": "2024-08-31T20:57:21.627110Z",
     "iopub.status.idle": "2024-08-31T20:57:21.631266Z",
     "shell.execute_reply": "2024-08-31T20:57:21.630380Z"
    },
    "papermill": {
     "duration": 0.036324,
     "end_time": "2024-08-31T20:57:21.633094",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.596770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To ignore warinings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "699a1f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T20:57:21.695066Z",
     "iopub.status.busy": "2024-08-31T20:57:21.694504Z",
     "iopub.status.idle": "2024-09-01T00:15:09.939669Z",
     "shell.execute_reply": "2024-09-01T00:15:09.938639Z"
    },
    "papermill": {
     "duration": 11868.278723,
     "end_time": "2024-09-01T00:15:09.942269",
     "exception": false,
     "start_time": "2024-08-31T20:57:21.663546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-09-01 00:15:09</td></tr>\n",
       "<tr><td>Running for: </td><td>03:17:31.50        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.1/31.4 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=59<br>Bracket: Iter 12.000: None | Iter 6.000: 0.7849673202614379 | Iter 3.000: 0.7660130718954248<br>Logical resource usage: 2.0/4 CPUs, 1.0/2 GPUs (0.0/1.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  training_iteration</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  early_stopping_epoch</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_bd0bf4fc</td><td>TERMINATED</td><td>172.19.2.2:340 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.507556</td><td style=\"text-align: right;\">  0.8     </td><td style=\"text-align: right;\">   -0.157776   </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.315742</td><td style=\"text-align: right;\">        0.87752 </td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_3140c869</td><td>TERMINATED</td><td>172.19.2.2:376 </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.648282</td><td style=\"text-align: right;\">  0.54902 </td><td style=\"text-align: right;\">    0.111842   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.661259</td><td style=\"text-align: right;\">        0.561202</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_7d401cee</td><td>TERMINATED</td><td>172.19.2.2:481 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.639943</td><td style=\"text-align: right;\">  0.762092</td><td style=\"text-align: right;\">    0.19969    </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.175858</td><td style=\"text-align: right;\">        0.941684</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_cf688369</td><td>TERMINATED</td><td>172.19.2.2:569 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.699943</td><td style=\"text-align: right;\">  0.572549</td><td style=\"text-align: right;\">    0.136156   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.706869</td><td style=\"text-align: right;\">        0.561952</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_0446ada0</td><td>TERMINATED</td><td>172.19.2.2:648 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.567829</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">   -0.0120958  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.285532</td><td style=\"text-align: right;\">        0.887265</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_33176fbb</td><td>TERMINATED</td><td>172.19.2.2:726 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.571281</td><td style=\"text-align: right;\">  0.786928</td><td style=\"text-align: right;\">    0.0278714  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.220561</td><td style=\"text-align: right;\">        0.923244</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_e6f71f4b</td><td>TERMINATED</td><td>172.19.2.2:810 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.661842</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">    0.206633   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.181234</td><td style=\"text-align: right;\">        0.938385</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_5b1b9378</td><td>TERMINATED</td><td>172.19.2.2:893 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.637853</td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.0882486  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638064</td><td style=\"text-align: right;\">        0.559403</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_7e03d7e9</td><td>TERMINATED</td><td>172.19.2.2:979 </td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.710609</td><td style=\"text-align: right;\">  0.555556</td><td style=\"text-align: right;\">    0.156531   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.713216</td><td style=\"text-align: right;\">        0.555206</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_5a36815b</td><td>TERMINATED</td><td>172.19.2.2:1051</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.486226</td><td style=\"text-align: right;\">  0.777778</td><td style=\"text-align: right;\">   -0.18273    </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.353785</td><td style=\"text-align: right;\">        0.862979</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_3a7a1582</td><td>TERMINATED</td><td>172.19.2.2:1137</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.636329</td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">    0.150485   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.199081</td><td style=\"text-align: right;\">        0.932239</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_c17c8212</td><td>TERMINATED</td><td>172.19.2.2:1225</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.534582</td><td style=\"text-align: right;\">  0.734641</td><td style=\"text-align: right;\">   -0.149681   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.589025</td><td style=\"text-align: right;\">        0.688329</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f75b372a</td><td>TERMINATED</td><td>172.19.2.2:1307</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.520215</td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">   -0.0683958  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.261666</td><td style=\"text-align: right;\">        0.905404</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_c40ffedf</td><td>TERMINATED</td><td>172.19.2.2:1383</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.510478</td><td style=\"text-align: right;\">  0.784314</td><td style=\"text-align: right;\">   -0.120605   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.301571</td><td style=\"text-align: right;\">        0.881868</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_7320921d</td><td>TERMINATED</td><td>172.19.2.2:1488</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.506175</td><td style=\"text-align: right;\">  0.783007</td><td style=\"text-align: right;\">   -0.135159   </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.317645</td><td style=\"text-align: right;\">        0.87782 </td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_eabbcd11</td><td>TERMINATED</td><td>172.19.2.2:1553</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.503446</td><td style=\"text-align: right;\">  0.784314</td><td style=\"text-align: right;\">   -0.10867    </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.274146</td><td style=\"text-align: right;\">        0.899408</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_56f195ae</td><td>TERMINATED</td><td>172.19.2.2:1661</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.636338</td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.0900988  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637433</td><td style=\"text-align: right;\">        0.56525 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f3032c36</td><td>TERMINATED</td><td>172.19.2.2:1735</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.515955</td><td style=\"text-align: right;\">  0.750327</td><td style=\"text-align: right;\">   -0.210268   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.54564 </td><td style=\"text-align: right;\">        0.731804</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_4ba0d650</td><td>TERMINATED</td><td>172.19.2.2:1818</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.694831</td><td style=\"text-align: right;\">  0.554248</td><td style=\"text-align: right;\">    0.14559    </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.693305</td><td style=\"text-align: right;\">        0.545761</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e9edae33</td><td>TERMINATED</td><td>172.19.2.2:1892</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.598575</td><td style=\"text-align: right;\">  0.792157</td><td style=\"text-align: right;\">    0.077694   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.196255</td><td style=\"text-align: right;\">        0.932389</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_635edd39</td><td>TERMINATED</td><td>172.19.2.2:1975</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.543745</td><td style=\"text-align: right;\">  0.734641</td><td style=\"text-align: right;\">   -0.144883   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.593356</td><td style=\"text-align: right;\">        0.692227</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_80b95c4a</td><td>TERMINATED</td><td>172.19.2.2:2060</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.471523</td><td style=\"text-align: right;\">  0.781699</td><td style=\"text-align: right;\">   -0.207028   </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.348007</td><td style=\"text-align: right;\">        0.864478</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_ecce7b9f</td><td>TERMINATED</td><td>172.19.2.2:2132</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.512104</td><td style=\"text-align: right;\">  0.786928</td><td style=\"text-align: right;\">   -0.124415   </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.306675</td><td style=\"text-align: right;\">        0.882318</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_71299120</td><td>TERMINATED</td><td>172.19.2.2:2242</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.517706</td><td style=\"text-align: right;\">  0.747712</td><td style=\"text-align: right;\">   -0.202548   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.555964</td><td style=\"text-align: right;\">        0.731055</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_5f06f1bf</td><td>TERMINATED</td><td>172.19.2.2:2320</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.512766</td><td style=\"text-align: right;\">  0.745098</td><td style=\"text-align: right;\">   -0.2229     </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.529729</td><td style=\"text-align: right;\">        0.743198</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_ea791363</td><td>TERMINATED</td><td>172.19.2.2:2399</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.493197</td><td style=\"text-align: right;\">  0.769935</td><td style=\"text-align: right;\">   -0.244517   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.537648</td><td style=\"text-align: right;\">        0.749944</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_c8fac80c</td><td>TERMINATED</td><td>172.19.2.2:2479</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.630048</td><td style=\"text-align: right;\">  0.581699</td><td style=\"text-align: right;\">    0.0566529  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638602</td><td style=\"text-align: right;\">        0.573645</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_02101ade</td><td>TERMINATED</td><td>172.19.2.2:2558</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-06 </td><td style=\"text-align: right;\">        5e-06 </td><td style=\"text-align: right;\">0.500899</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">   -0.17319    </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.367653</td><td style=\"text-align: right;\">        0.847987</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_577b54a8</td><td>TERMINATED</td><td>172.19.2.2:2638</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.62851 </td><td style=\"text-align: right;\">  0.613072</td><td style=\"text-align: right;\">    0.0389739  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.636455</td><td style=\"text-align: right;\">        0.573945</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_1f9d4aca</td><td>TERMINATED</td><td>172.19.2.2:2727</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.597863</td><td style=\"text-align: right;\">  0.789542</td><td style=\"text-align: right;\">    0.0881504  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.184647</td><td style=\"text-align: right;\">        0.935987</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_8fdc5005</td><td>TERMINATED</td><td>172.19.2.2:2806</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.518293</td><td style=\"text-align: right;\">  0.76732 </td><td style=\"text-align: right;\">   -0.137775   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.366112</td><td style=\"text-align: right;\">        0.837643</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_3d09d379</td><td>TERMINATED</td><td>172.19.2.2:2894</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.663488</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0948962  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.669374</td><td style=\"text-align: right;\">        0.566599</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_1508bcc4</td><td>TERMINATED</td><td>172.19.2.2:2968</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.643058</td><td style=\"text-align: right;\">  0.556863</td><td style=\"text-align: right;\">    0.0950022  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.656317</td><td style=\"text-align: right;\">        0.552507</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_75a43c9c</td><td>TERMINATED</td><td>172.19.2.2:3054</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.645558</td><td style=\"text-align: right;\">  0.559477</td><td style=\"text-align: right;\">    0.0961193  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.657166</td><td style=\"text-align: right;\">        0.551008</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_17c207f6</td><td>TERMINATED</td><td>172.19.2.2:3127</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.506314</td><td style=\"text-align: right;\">  0.74902 </td><td style=\"text-align: right;\">   -0.216485   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.545439</td><td style=\"text-align: right;\">        0.735702</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_251553d0</td><td>TERMINATED</td><td>172.19.2.2:3213</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.596506</td><td style=\"text-align: right;\">  0.781699</td><td style=\"text-align: right;\">    0.0894772  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.198754</td><td style=\"text-align: right;\">        0.933288</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_9d626e8d</td><td>TERMINATED</td><td>172.19.2.2:3286</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.471066</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">   -0.246247   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.405828</td><td style=\"text-align: right;\">        0.829548</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_547b5fdd</td><td>TERMINATED</td><td>172.19.2.2:3388</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.546518</td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">   -0.0184292  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.244689</td><td style=\"text-align: right;\">        0.909452</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_95f8e155</td><td>TERMINATED</td><td>172.19.2.2:3462</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.637094</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0714295  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637741</td><td style=\"text-align: right;\">        0.555506</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_6c5e1b43</td><td>TERMINATED</td><td>172.19.2.2:3551</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.516826</td><td style=\"text-align: right;\">  0.738562</td><td style=\"text-align: right;\">   -0.196705   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.555033</td><td style=\"text-align: right;\">        0.726707</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_2004b749</td><td>TERMINATED</td><td>172.19.2.2:3630</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.466673</td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">   -0.261373   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.410987</td><td style=\"text-align: right;\">        0.829398</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_4818526e</td><td>TERMINATED</td><td>172.19.2.2:3710</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.504029</td><td style=\"text-align: right;\">  0.74902 </td><td style=\"text-align: right;\">   -0.21774    </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.550909</td><td style=\"text-align: right;\">        0.741399</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_a3d2b9be</td><td>TERMINATED</td><td>172.19.2.2:3799</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.63719 </td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.0897957  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637624</td><td style=\"text-align: right;\">        0.563601</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_77e96092</td><td>TERMINATED</td><td>172.19.2.2:3876</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.01  </td><td style=\"text-align: right;\">0.636641</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0706089  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638053</td><td style=\"text-align: right;\">        0.557005</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_79f404b2</td><td>TERMINATED</td><td>172.19.2.2:3956</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.636097</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0658168  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637707</td><td style=\"text-align: right;\">        0.5657  </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_383e11c1</td><td>TERMINATED</td><td>172.19.2.2:4034</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.620049</td><td style=\"text-align: right;\">  0.704575</td><td style=\"text-align: right;\">   -0.0261227  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.631112</td><td style=\"text-align: right;\">        0.598831</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_ecec64cc</td><td>TERMINATED</td><td>172.19.2.2:4113</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.657661</td><td style=\"text-align: right;\">  0.786928</td><td style=\"text-align: right;\">    0.182305   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.182226</td><td style=\"text-align: right;\">        0.934638</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_2230bb7b</td><td>TERMINATED</td><td>172.19.2.2:4191</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.602744</td><td style=\"text-align: right;\">  0.781699</td><td style=\"text-align: right;\">    0.0593666  </td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">    0.249056</td><td style=\"text-align: right;\">        0.904655</td><td style=\"text-align: right;\">                     4</td></tr>\n",
       "<tr><td>train_fn_37f97e1a</td><td>TERMINATED</td><td>172.19.2.2:4280</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.622562</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">    0.148882   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.175446</td><td style=\"text-align: right;\">        0.934937</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_84024322</td><td>TERMINATED</td><td>172.19.2.2:4353</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.651216</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0845093  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.658174</td><td style=\"text-align: right;\">        0.563901</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_42cfc512</td><td>TERMINATED</td><td>172.19.2.2:4442</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.674265</td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.125673   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.682498</td><td style=\"text-align: right;\">        0.553407</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_8c531cb5</td><td>TERMINATED</td><td>172.19.2.2:4522</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.47812 </td><td style=\"text-align: right;\">  0.788235</td><td style=\"text-align: right;\">   -0.195027   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.329584</td><td style=\"text-align: right;\">        0.869875</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_e131ffde</td><td>TERMINATED</td><td>172.19.2.2:4601</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.47946 </td><td style=\"text-align: right;\">  0.793464</td><td style=\"text-align: right;\">   -0.197837   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.324585</td><td style=\"text-align: right;\">        0.870924</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_85cd8f48</td><td>TERMINATED</td><td>172.19.2.2:4692</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.469733</td><td style=\"text-align: right;\">  0.801307</td><td style=\"text-align: right;\">   -0.243327   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.351613</td><td style=\"text-align: right;\">        0.859681</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_140e5ba7</td><td>TERMINATED</td><td>172.19.2.2:4771</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.50141 </td><td style=\"text-align: right;\">  0.798693</td><td style=\"text-align: right;\">   -0.17748    </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.333734</td><td style=\"text-align: right;\">        0.870624</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_35bd53cc</td><td>TERMINATED</td><td>172.19.2.2:4864</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.572697</td><td style=\"text-align: right;\">  0.783007</td><td style=\"text-align: right;\">    0.00711802 </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.254244</td><td style=\"text-align: right;\">        0.899408</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_c5bd5782</td><td>TERMINATED</td><td>172.19.2.2:4941</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.482541</td><td style=\"text-align: right;\">  0.779085</td><td style=\"text-align: right;\">   -0.197671   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.363292</td><td style=\"text-align: right;\">        0.857582</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_a3730fd0</td><td>TERMINATED</td><td>172.19.2.2:5034</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.494408</td><td style=\"text-align: right;\">  0.789542</td><td style=\"text-align: right;\">   -0.152284   </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.30358 </td><td style=\"text-align: right;\">        0.884416</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_b6528c05</td><td>TERMINATED</td><td>172.19.2.2:5113</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.489888</td><td style=\"text-align: right;\">  0.784314</td><td style=\"text-align: right;\">   -0.194946   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.361648</td><td style=\"text-align: right;\">        0.855033</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_4449f7cd</td><td>TERMINATED</td><td>172.19.2.2:5214</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.495432</td><td style=\"text-align: right;\">  0.794771</td><td style=\"text-align: right;\">   -0.153925   </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.299345</td><td style=\"text-align: right;\">        0.889514</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_afef07f4</td><td>TERMINATED</td><td>172.19.2.2:5285</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.593565</td><td style=\"text-align: right;\">  0.703268</td><td style=\"text-align: right;\">   -0.0523986  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.622925</td><td style=\"text-align: right;\">        0.61802 </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e806ebaf</td><td>TERMINATED</td><td>172.19.2.2:5372</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.595333</td><td style=\"text-align: right;\">  0.721569</td><td style=\"text-align: right;\">   -0.0536657  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.627779</td><td style=\"text-align: right;\">        0.608875</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_a969891a</td><td>TERMINATED</td><td>172.19.2.2:5459</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.625283</td><td style=\"text-align: right;\">  0.633987</td><td style=\"text-align: right;\">    0.0130309  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.632997</td><td style=\"text-align: right;\">        0.598231</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_6b4b5c30</td><td>TERMINATED</td><td>172.19.2.2:5537</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.485357</td><td style=\"text-align: right;\">  0.763399</td><td style=\"text-align: right;\">   -0.270004   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.493001</td><td style=\"text-align: right;\">        0.771831</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_3cd67208</td><td>TERMINATED</td><td>172.19.2.2:5616</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.599731</td><td style=\"text-align: right;\">  0.626144</td><td style=\"text-align: right;\">    0.000141761</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.616982</td><td style=\"text-align: right;\">        0.590286</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_823b7e25</td><td>TERMINATED</td><td>172.19.2.2:5694</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.646251</td><td style=\"text-align: right;\">  0.76732 </td><td style=\"text-align: right;\">    0.180843   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.19835 </td><td style=\"text-align: right;\">        0.923244</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_fbef7b28</td><td>TERMINATED</td><td>172.19.2.2:5773</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.3 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.500352</td><td style=\"text-align: right;\">  0.750327</td><td style=\"text-align: right;\">   -0.228447   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.529833</td><td style=\"text-align: right;\">        0.736751</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_aa1a65a0</td><td>TERMINATED</td><td>172.19.2.2:5860</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.491186</td><td style=\"text-align: right;\">  0.79085 </td><td style=\"text-align: right;\">   -0.176765   </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.327413</td><td style=\"text-align: right;\">        0.872873</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_5b88e4bd</td><td>TERMINATED</td><td>172.19.2.2:5931</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.47515 </td><td style=\"text-align: right;\">  0.760784</td><td style=\"text-align: right;\">   -0.271387   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.501144</td><td style=\"text-align: right;\">        0.763286</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f6f9ae36</td><td>TERMINATED</td><td>172.19.2.2:6019</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.513682</td><td style=\"text-align: right;\">  0.794771</td><td style=\"text-align: right;\">   -0.122998   </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.296889</td><td style=\"text-align: right;\">        0.894161</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_8ea8b100</td><td>TERMINATED</td><td>172.19.2.2:6107</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.481543</td><td style=\"text-align: right;\">  0.796078</td><td style=\"text-align: right;\">   -0.196654   </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.327073</td><td style=\"text-align: right;\">        0.877371</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_7f950825</td><td>TERMINATED</td><td>172.19.2.2:6200</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.601924</td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">    0.101553   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.185688</td><td style=\"text-align: right;\">        0.939885</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_62234124</td><td>TERMINATED</td><td>172.19.2.2:6284</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.7334  </td><td style=\"text-align: right;\">  0.537255</td><td style=\"text-align: right;\">    0.200994   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.734443</td><td style=\"text-align: right;\">        0.545911</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_9c558e3f</td><td>TERMINATED</td><td>172.19.2.2:6370</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-07 </td><td style=\"text-align: right;\">        5e-05 </td><td style=\"text-align: right;\">0.684928</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.114536   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.685416</td><td style=\"text-align: right;\">        0.5648  </td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_5cf80e46</td><td>TERMINATED</td><td>172.19.2.2:6441</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.636344</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0683594  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.638048</td><td style=\"text-align: right;\">        0.561202</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_6dbd8896</td><td>TERMINATED</td><td>172.19.2.2:6527</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.586108</td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">    0.0444367  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.229235</td><td style=\"text-align: right;\">        0.916648</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_e5f3be6d</td><td>TERMINATED</td><td>172.19.2.2:6599</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.25</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">3e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.626385</td><td style=\"text-align: right;\">  0.775163</td><td style=\"text-align: right;\">    0.123461   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.222491</td><td style=\"text-align: right;\">        0.915748</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_e0e6d071</td><td>TERMINATED</td><td>172.19.2.2:6694</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.640483</td><td style=\"text-align: right;\">  0.593464</td><td style=\"text-align: right;\">    0.0680504  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.651783</td><td style=\"text-align: right;\">        0.562701</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_e043f686</td><td>TERMINATED</td><td>172.19.2.2:6766</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      15</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.636427</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0710704  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.650133</td><td style=\"text-align: right;\">        0.567948</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_a7a06212</td><td>TERMINATED</td><td>172.19.2.2:6851</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">1e-06 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.639068</td><td style=\"text-align: right;\">  0.543791</td><td style=\"text-align: right;\">    0.106252   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.647654</td><td style=\"text-align: right;\">        0.557155</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_684c7f04</td><td>TERMINATED</td><td>172.19.2.2:6923</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        0.0002</td><td style=\"text-align: right;\">0.665134</td><td style=\"text-align: right;\">  0.573856</td><td style=\"text-align: right;\">    0.101463   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.670452</td><td style=\"text-align: right;\">        0.558804</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f64cb067</td><td>TERMINATED</td><td>172.19.2.2:7009</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">       7</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.488723</td><td style=\"text-align: right;\">  0.789542</td><td style=\"text-align: right;\">   -0.210232   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.365994</td><td style=\"text-align: right;\">        0.847987</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_09736a8f</td><td>TERMINATED</td><td>172.19.2.2:7080</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.32</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-07 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.652346</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.088618   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.661363</td><td style=\"text-align: right;\">        0.560003</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_f3bae7c3</td><td>TERMINATED</td><td>172.19.2.2:7167</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        2e-05 </td><td style=\"text-align: right;\">0.473303</td><td style=\"text-align: right;\">  0.783007</td><td style=\"text-align: right;\">   -0.212487   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.353744</td><td style=\"text-align: right;\">        0.857882</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_6ecf7d5f</td><td>TERMINATED</td><td>172.19.2.2:7251</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.517265</td><td style=\"text-align: right;\">  0.788235</td><td style=\"text-align: right;\">   -0.0845326  </td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">    0.264257</td><td style=\"text-align: right;\">        0.908103</td><td style=\"text-align: right;\">                     9</td></tr>\n",
       "<tr><td>train_fn_1b09a8ad</td><td>TERMINATED</td><td>172.19.2.2:7339</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.504985</td><td style=\"text-align: right;\">  0.792157</td><td style=\"text-align: right;\">   -0.147593   </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">    0.314339</td><td style=\"text-align: right;\">        0.880669</td><td style=\"text-align: right;\">                     7</td></tr>\n",
       "<tr><td>train_fn_9da6d1e1</td><td>TERMINATED</td><td>172.19.2.2:7437</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.508996</td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">   -0.0995646  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.270012</td><td style=\"text-align: right;\">        0.900757</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_606489f8</td><td>TERMINATED</td><td>172.19.2.2:7516</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        0.001 </td><td style=\"text-align: right;\">0.531048</td><td style=\"text-align: right;\">  0.789542</td><td style=\"text-align: right;\">   -0.0551299  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.247076</td><td style=\"text-align: right;\">        0.9123  </td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_4e35e700</td><td>TERMINATED</td><td>172.19.2.2:7609</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.35</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">1e-05 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.562871</td><td style=\"text-align: right;\">  0.777778</td><td style=\"text-align: right;\">    0.0229281  </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.22757 </td><td style=\"text-align: right;\">        0.918147</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_4d8c9540</td><td>TERMINATED</td><td>172.19.2.2:7686</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        1e-06 </td><td style=\"text-align: right;\">0.667871</td><td style=\"text-align: right;\">  0.537255</td><td style=\"text-align: right;\">    0.142665   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.674468</td><td style=\"text-align: right;\">        0.554756</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_fe98dfc2</td><td>TERMINATED</td><td>172.19.2.2:7775</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">2e-07 </td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.669834</td><td style=\"text-align: right;\">  0.560784</td><td style=\"text-align: right;\">    0.10986    </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.671274</td><td style=\"text-align: right;\">        0.560603</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_981239f6</td><td>TERMINATED</td><td>172.19.2.2:7857</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.635913</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0685812  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637573</td><td style=\"text-align: right;\">        0.559853</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_1b4e77fe</td><td>TERMINATED</td><td>172.19.2.2:7935</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0002</td><td style=\"text-align: right;\">        0.0001</td><td style=\"text-align: right;\">0.636004</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0686025  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637375</td><td style=\"text-align: right;\">        0.559703</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_b893840f</td><td>TERMINATED</td><td>172.19.2.2:8017</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.493943</td><td style=\"text-align: right;\">  0.792157</td><td style=\"text-align: right;\">   -0.156853   </td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">    0.30153 </td><td style=\"text-align: right;\">        0.882468</td><td style=\"text-align: right;\">                     8</td></tr>\n",
       "<tr><td>train_fn_32d7d8e3</td><td>TERMINATED</td><td>172.19.2.2:8092</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.27</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.494398</td><td style=\"text-align: right;\">  0.784314</td><td style=\"text-align: right;\">   -0.186989   </td><td style=\"text-align: right;\">                   6</td><td style=\"text-align: right;\">    0.358967</td><td style=\"text-align: right;\">        0.854734</td><td style=\"text-align: right;\">                     6</td></tr>\n",
       "<tr><td>train_fn_90f8954a</td><td>TERMINATED</td><td>172.19.2.2:8194</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        1e-05 </td><td style=\"text-align: right;\">0.480507</td><td style=\"text-align: right;\">  0.75817 </td><td style=\"text-align: right;\">   -0.263388   </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.478061</td><td style=\"text-align: right;\">        0.784274</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "<tr><td>train_fn_0c38a16c</td><td>TERMINATED</td><td>172.19.2.2:8269</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.46998 </td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">   -0.243955   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.383278</td><td style=\"text-align: right;\">        0.842291</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_3449c45b</td><td>TERMINATED</td><td>172.19.2.2:8352</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">5e-06 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.461303</td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">   -0.252279   </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.376744</td><td style=\"text-align: right;\">        0.845139</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_e2e4985c</td><td>TERMINATED</td><td>172.19.2.2:8437</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">          0.4 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">2e-05 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.56566 </td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">    0.0181031  </td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">    0.235345</td><td style=\"text-align: right;\">        0.915748</td><td style=\"text-align: right;\">                     5</td></tr>\n",
       "<tr><td>train_fn_ae28e9f0</td><td>TERMINATED</td><td>172.19.2.2:8520</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">          0.2 </td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">0.001 </td><td style=\"text-align: right;\">        2e-06 </td><td style=\"text-align: right;\">0.638172</td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.0902507  </td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">    0.637593</td><td style=\"text-align: right;\">        0.562402</td><td style=\"text-align: right;\">                     3</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-31 20:57:25,934\tINFO worker.py:1753 -- Started a local Ray instance.\n",
      "2024-08-31 20:57:27,180\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-08-31 20:57:27,184\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "[I 2024-08-31 20:57:27,244] A new study created in memory with name: optuna\n",
      "\u001b[36m(train_fn pid=340)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=340)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=376)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=376)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">  custom_metric</th><th style=\"text-align: right;\">  early_stopping_epoch</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  train_accuracy</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_02101ade</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">   -0.17319    </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.500899</td><td style=\"text-align: right;\">        0.847987</td><td style=\"text-align: right;\">    0.367653</td></tr>\n",
       "<tr><td>train_fn_0446ada0</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">   -0.0120958  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.567829</td><td style=\"text-align: right;\">        0.887265</td><td style=\"text-align: right;\">    0.285532</td></tr>\n",
       "<tr><td>train_fn_09736a8f</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.088618   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.652346</td><td style=\"text-align: right;\">        0.560003</td><td style=\"text-align: right;\">    0.661363</td></tr>\n",
       "<tr><td>train_fn_0c38a16c</td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">   -0.243955   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.46998 </td><td style=\"text-align: right;\">        0.842291</td><td style=\"text-align: right;\">    0.383278</td></tr>\n",
       "<tr><td>train_fn_140e5ba7</td><td style=\"text-align: right;\">  0.798693</td><td style=\"text-align: right;\">   -0.17748    </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.50141 </td><td style=\"text-align: right;\">        0.870624</td><td style=\"text-align: right;\">    0.333734</td></tr>\n",
       "<tr><td>train_fn_1508bcc4</td><td style=\"text-align: right;\">  0.556863</td><td style=\"text-align: right;\">    0.0950022  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.643058</td><td style=\"text-align: right;\">        0.552507</td><td style=\"text-align: right;\">    0.656317</td></tr>\n",
       "<tr><td>train_fn_17c207f6</td><td style=\"text-align: right;\">  0.74902 </td><td style=\"text-align: right;\">   -0.216485   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.506314</td><td style=\"text-align: right;\">        0.735702</td><td style=\"text-align: right;\">    0.545439</td></tr>\n",
       "<tr><td>train_fn_1b09a8ad</td><td style=\"text-align: right;\">  0.792157</td><td style=\"text-align: right;\">   -0.147593   </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.504985</td><td style=\"text-align: right;\">        0.880669</td><td style=\"text-align: right;\">    0.314339</td></tr>\n",
       "<tr><td>train_fn_1b4e77fe</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0686025  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636004</td><td style=\"text-align: right;\">        0.559703</td><td style=\"text-align: right;\">    0.637375</td></tr>\n",
       "<tr><td>train_fn_1f9d4aca</td><td style=\"text-align: right;\">  0.789542</td><td style=\"text-align: right;\">    0.0881504  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.597863</td><td style=\"text-align: right;\">        0.935987</td><td style=\"text-align: right;\">    0.184647</td></tr>\n",
       "<tr><td>train_fn_2004b749</td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">   -0.261373   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.466673</td><td style=\"text-align: right;\">        0.829398</td><td style=\"text-align: right;\">    0.410987</td></tr>\n",
       "<tr><td>train_fn_2230bb7b</td><td style=\"text-align: right;\">  0.781699</td><td style=\"text-align: right;\">    0.0593666  </td><td style=\"text-align: right;\">                     4</td><td style=\"text-align: right;\">0.602744</td><td style=\"text-align: right;\">        0.904655</td><td style=\"text-align: right;\">    0.249056</td></tr>\n",
       "<tr><td>train_fn_251553d0</td><td style=\"text-align: right;\">  0.781699</td><td style=\"text-align: right;\">    0.0894772  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.596506</td><td style=\"text-align: right;\">        0.933288</td><td style=\"text-align: right;\">    0.198754</td></tr>\n",
       "<tr><td>train_fn_3140c869</td><td style=\"text-align: right;\">  0.54902 </td><td style=\"text-align: right;\">    0.111842   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.648282</td><td style=\"text-align: right;\">        0.561202</td><td style=\"text-align: right;\">    0.661259</td></tr>\n",
       "<tr><td>train_fn_32d7d8e3</td><td style=\"text-align: right;\">  0.784314</td><td style=\"text-align: right;\">   -0.186989   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.494398</td><td style=\"text-align: right;\">        0.854734</td><td style=\"text-align: right;\">    0.358967</td></tr>\n",
       "<tr><td>train_fn_33176fbb</td><td style=\"text-align: right;\">  0.786928</td><td style=\"text-align: right;\">    0.0278714  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.571281</td><td style=\"text-align: right;\">        0.923244</td><td style=\"text-align: right;\">    0.220561</td></tr>\n",
       "<tr><td>train_fn_3449c45b</td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">   -0.252279   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.461303</td><td style=\"text-align: right;\">        0.845139</td><td style=\"text-align: right;\">    0.376744</td></tr>\n",
       "<tr><td>train_fn_35bd53cc</td><td style=\"text-align: right;\">  0.783007</td><td style=\"text-align: right;\">    0.00711802 </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.572697</td><td style=\"text-align: right;\">        0.899408</td><td style=\"text-align: right;\">    0.254244</td></tr>\n",
       "<tr><td>train_fn_37f97e1a</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">    0.148882   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.622562</td><td style=\"text-align: right;\">        0.934937</td><td style=\"text-align: right;\">    0.175446</td></tr>\n",
       "<tr><td>train_fn_383e11c1</td><td style=\"text-align: right;\">  0.704575</td><td style=\"text-align: right;\">   -0.0261227  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.620049</td><td style=\"text-align: right;\">        0.598831</td><td style=\"text-align: right;\">    0.631112</td></tr>\n",
       "<tr><td>train_fn_3a7a1582</td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">    0.150485   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.636329</td><td style=\"text-align: right;\">        0.932239</td><td style=\"text-align: right;\">    0.199081</td></tr>\n",
       "<tr><td>train_fn_3cd67208</td><td style=\"text-align: right;\">  0.626144</td><td style=\"text-align: right;\">    0.000141761</td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.599731</td><td style=\"text-align: right;\">        0.590286</td><td style=\"text-align: right;\">    0.616982</td></tr>\n",
       "<tr><td>train_fn_3d09d379</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0948962  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.663488</td><td style=\"text-align: right;\">        0.566599</td><td style=\"text-align: right;\">    0.669374</td></tr>\n",
       "<tr><td>train_fn_42cfc512</td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.125673   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.674265</td><td style=\"text-align: right;\">        0.553407</td><td style=\"text-align: right;\">    0.682498</td></tr>\n",
       "<tr><td>train_fn_4449f7cd</td><td style=\"text-align: right;\">  0.794771</td><td style=\"text-align: right;\">   -0.153925   </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.495432</td><td style=\"text-align: right;\">        0.889514</td><td style=\"text-align: right;\">    0.299345</td></tr>\n",
       "<tr><td>train_fn_4818526e</td><td style=\"text-align: right;\">  0.74902 </td><td style=\"text-align: right;\">   -0.21774    </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.504029</td><td style=\"text-align: right;\">        0.741399</td><td style=\"text-align: right;\">    0.550909</td></tr>\n",
       "<tr><td>train_fn_4ba0d650</td><td style=\"text-align: right;\">  0.554248</td><td style=\"text-align: right;\">    0.14559    </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.694831</td><td style=\"text-align: right;\">        0.545761</td><td style=\"text-align: right;\">    0.693305</td></tr>\n",
       "<tr><td>train_fn_4d8c9540</td><td style=\"text-align: right;\">  0.537255</td><td style=\"text-align: right;\">    0.142665   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.667871</td><td style=\"text-align: right;\">        0.554756</td><td style=\"text-align: right;\">    0.674468</td></tr>\n",
       "<tr><td>train_fn_4e35e700</td><td style=\"text-align: right;\">  0.777778</td><td style=\"text-align: right;\">    0.0229281  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.562871</td><td style=\"text-align: right;\">        0.918147</td><td style=\"text-align: right;\">    0.22757 </td></tr>\n",
       "<tr><td>train_fn_547b5fdd</td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">   -0.0184292  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.546518</td><td style=\"text-align: right;\">        0.909452</td><td style=\"text-align: right;\">    0.244689</td></tr>\n",
       "<tr><td>train_fn_56f195ae</td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.0900988  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636338</td><td style=\"text-align: right;\">        0.56525 </td><td style=\"text-align: right;\">    0.637433</td></tr>\n",
       "<tr><td>train_fn_577b54a8</td><td style=\"text-align: right;\">  0.613072</td><td style=\"text-align: right;\">    0.0389739  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.62851 </td><td style=\"text-align: right;\">        0.573945</td><td style=\"text-align: right;\">    0.636455</td></tr>\n",
       "<tr><td>train_fn_5a36815b</td><td style=\"text-align: right;\">  0.777778</td><td style=\"text-align: right;\">   -0.18273    </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.486226</td><td style=\"text-align: right;\">        0.862979</td><td style=\"text-align: right;\">    0.353785</td></tr>\n",
       "<tr><td>train_fn_5b1b9378</td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.0882486  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.637853</td><td style=\"text-align: right;\">        0.559403</td><td style=\"text-align: right;\">    0.638064</td></tr>\n",
       "<tr><td>train_fn_5b88e4bd</td><td style=\"text-align: right;\">  0.760784</td><td style=\"text-align: right;\">   -0.271387   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.47515 </td><td style=\"text-align: right;\">        0.763286</td><td style=\"text-align: right;\">    0.501144</td></tr>\n",
       "<tr><td>train_fn_5cf80e46</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0683594  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636344</td><td style=\"text-align: right;\">        0.561202</td><td style=\"text-align: right;\">    0.638048</td></tr>\n",
       "<tr><td>train_fn_5f06f1bf</td><td style=\"text-align: right;\">  0.745098</td><td style=\"text-align: right;\">   -0.2229     </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.512766</td><td style=\"text-align: right;\">        0.743198</td><td style=\"text-align: right;\">    0.529729</td></tr>\n",
       "<tr><td>train_fn_606489f8</td><td style=\"text-align: right;\">  0.789542</td><td style=\"text-align: right;\">   -0.0551299  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.531048</td><td style=\"text-align: right;\">        0.9123  </td><td style=\"text-align: right;\">    0.247076</td></tr>\n",
       "<tr><td>train_fn_62234124</td><td style=\"text-align: right;\">  0.537255</td><td style=\"text-align: right;\">    0.200994   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.7334  </td><td style=\"text-align: right;\">        0.545911</td><td style=\"text-align: right;\">    0.734443</td></tr>\n",
       "<tr><td>train_fn_635edd39</td><td style=\"text-align: right;\">  0.734641</td><td style=\"text-align: right;\">   -0.144883   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.543745</td><td style=\"text-align: right;\">        0.692227</td><td style=\"text-align: right;\">    0.593356</td></tr>\n",
       "<tr><td>train_fn_684c7f04</td><td style=\"text-align: right;\">  0.573856</td><td style=\"text-align: right;\">    0.101463   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.665134</td><td style=\"text-align: right;\">        0.558804</td><td style=\"text-align: right;\">    0.670452</td></tr>\n",
       "<tr><td>train_fn_6b4b5c30</td><td style=\"text-align: right;\">  0.763399</td><td style=\"text-align: right;\">   -0.270004   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.485357</td><td style=\"text-align: right;\">        0.771831</td><td style=\"text-align: right;\">    0.493001</td></tr>\n",
       "<tr><td>train_fn_6c5e1b43</td><td style=\"text-align: right;\">  0.738562</td><td style=\"text-align: right;\">   -0.196705   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.516826</td><td style=\"text-align: right;\">        0.726707</td><td style=\"text-align: right;\">    0.555033</td></tr>\n",
       "<tr><td>train_fn_6dbd8896</td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">    0.0444367  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.586108</td><td style=\"text-align: right;\">        0.916648</td><td style=\"text-align: right;\">    0.229235</td></tr>\n",
       "<tr><td>train_fn_6ecf7d5f</td><td style=\"text-align: right;\">  0.788235</td><td style=\"text-align: right;\">   -0.0845326  </td><td style=\"text-align: right;\">                     9</td><td style=\"text-align: right;\">0.517265</td><td style=\"text-align: right;\">        0.908103</td><td style=\"text-align: right;\">    0.264257</td></tr>\n",
       "<tr><td>train_fn_71299120</td><td style=\"text-align: right;\">  0.747712</td><td style=\"text-align: right;\">   -0.202548   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.517706</td><td style=\"text-align: right;\">        0.731055</td><td style=\"text-align: right;\">    0.555964</td></tr>\n",
       "<tr><td>train_fn_7320921d</td><td style=\"text-align: right;\">  0.783007</td><td style=\"text-align: right;\">   -0.135159   </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.506175</td><td style=\"text-align: right;\">        0.87782 </td><td style=\"text-align: right;\">    0.317645</td></tr>\n",
       "<tr><td>train_fn_75a43c9c</td><td style=\"text-align: right;\">  0.559477</td><td style=\"text-align: right;\">    0.0961193  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.645558</td><td style=\"text-align: right;\">        0.551008</td><td style=\"text-align: right;\">    0.657166</td></tr>\n",
       "<tr><td>train_fn_77e96092</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0706089  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636641</td><td style=\"text-align: right;\">        0.557005</td><td style=\"text-align: right;\">    0.638053</td></tr>\n",
       "<tr><td>train_fn_79f404b2</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0658168  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636097</td><td style=\"text-align: right;\">        0.5657  </td><td style=\"text-align: right;\">    0.637707</td></tr>\n",
       "<tr><td>train_fn_7d401cee</td><td style=\"text-align: right;\">  0.762092</td><td style=\"text-align: right;\">    0.19969    </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.639943</td><td style=\"text-align: right;\">        0.941684</td><td style=\"text-align: right;\">    0.175858</td></tr>\n",
       "<tr><td>train_fn_7e03d7e9</td><td style=\"text-align: right;\">  0.555556</td><td style=\"text-align: right;\">    0.156531   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.710609</td><td style=\"text-align: right;\">        0.555206</td><td style=\"text-align: right;\">    0.713216</td></tr>\n",
       "<tr><td>train_fn_7f950825</td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">    0.101553   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.601924</td><td style=\"text-align: right;\">        0.939885</td><td style=\"text-align: right;\">    0.185688</td></tr>\n",
       "<tr><td>train_fn_80b95c4a</td><td style=\"text-align: right;\">  0.781699</td><td style=\"text-align: right;\">   -0.207028   </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.471523</td><td style=\"text-align: right;\">        0.864478</td><td style=\"text-align: right;\">    0.348007</td></tr>\n",
       "<tr><td>train_fn_823b7e25</td><td style=\"text-align: right;\">  0.76732 </td><td style=\"text-align: right;\">    0.180843   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.646251</td><td style=\"text-align: right;\">        0.923244</td><td style=\"text-align: right;\">    0.19835 </td></tr>\n",
       "<tr><td>train_fn_84024322</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0845093  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.651216</td><td style=\"text-align: right;\">        0.563901</td><td style=\"text-align: right;\">    0.658174</td></tr>\n",
       "<tr><td>train_fn_85cd8f48</td><td style=\"text-align: right;\">  0.801307</td><td style=\"text-align: right;\">   -0.243327   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.469733</td><td style=\"text-align: right;\">        0.859681</td><td style=\"text-align: right;\">    0.351613</td></tr>\n",
       "<tr><td>train_fn_8c531cb5</td><td style=\"text-align: right;\">  0.788235</td><td style=\"text-align: right;\">   -0.195027   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.47812 </td><td style=\"text-align: right;\">        0.869875</td><td style=\"text-align: right;\">    0.329584</td></tr>\n",
       "<tr><td>train_fn_8ea8b100</td><td style=\"text-align: right;\">  0.796078</td><td style=\"text-align: right;\">   -0.196654   </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.481543</td><td style=\"text-align: right;\">        0.877371</td><td style=\"text-align: right;\">    0.327073</td></tr>\n",
       "<tr><td>train_fn_8fdc5005</td><td style=\"text-align: right;\">  0.76732 </td><td style=\"text-align: right;\">   -0.137775   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.518293</td><td style=\"text-align: right;\">        0.837643</td><td style=\"text-align: right;\">    0.366112</td></tr>\n",
       "<tr><td>train_fn_90f8954a</td><td style=\"text-align: right;\">  0.75817 </td><td style=\"text-align: right;\">   -0.263388   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.480507</td><td style=\"text-align: right;\">        0.784274</td><td style=\"text-align: right;\">    0.478061</td></tr>\n",
       "<tr><td>train_fn_95f8e155</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0714295  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.637094</td><td style=\"text-align: right;\">        0.555506</td><td style=\"text-align: right;\">    0.637741</td></tr>\n",
       "<tr><td>train_fn_981239f6</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0685812  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.635913</td><td style=\"text-align: right;\">        0.559853</td><td style=\"text-align: right;\">    0.637573</td></tr>\n",
       "<tr><td>train_fn_9c558e3f</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.114536   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.684928</td><td style=\"text-align: right;\">        0.5648  </td><td style=\"text-align: right;\">    0.685416</td></tr>\n",
       "<tr><td>train_fn_9d626e8d</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">   -0.246247   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.471066</td><td style=\"text-align: right;\">        0.829548</td><td style=\"text-align: right;\">    0.405828</td></tr>\n",
       "<tr><td>train_fn_9da6d1e1</td><td style=\"text-align: right;\">  0.785621</td><td style=\"text-align: right;\">   -0.0995646  </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.508996</td><td style=\"text-align: right;\">        0.900757</td><td style=\"text-align: right;\">    0.270012</td></tr>\n",
       "<tr><td>train_fn_a3730fd0</td><td style=\"text-align: right;\">  0.789542</td><td style=\"text-align: right;\">   -0.152284   </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.494408</td><td style=\"text-align: right;\">        0.884416</td><td style=\"text-align: right;\">    0.30358 </td></tr>\n",
       "<tr><td>train_fn_a3d2b9be</td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.0897957  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.63719 </td><td style=\"text-align: right;\">        0.563601</td><td style=\"text-align: right;\">    0.637624</td></tr>\n",
       "<tr><td>train_fn_a7a06212</td><td style=\"text-align: right;\">  0.543791</td><td style=\"text-align: right;\">    0.106252   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.639068</td><td style=\"text-align: right;\">        0.557155</td><td style=\"text-align: right;\">    0.647654</td></tr>\n",
       "<tr><td>train_fn_a969891a</td><td style=\"text-align: right;\">  0.633987</td><td style=\"text-align: right;\">    0.0130309  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.625283</td><td style=\"text-align: right;\">        0.598231</td><td style=\"text-align: right;\">    0.632997</td></tr>\n",
       "<tr><td>train_fn_aa1a65a0</td><td style=\"text-align: right;\">  0.79085 </td><td style=\"text-align: right;\">   -0.176765   </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.491186</td><td style=\"text-align: right;\">        0.872873</td><td style=\"text-align: right;\">    0.327413</td></tr>\n",
       "<tr><td>train_fn_ae28e9f0</td><td style=\"text-align: right;\">  0.552941</td><td style=\"text-align: right;\">    0.0902507  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.638172</td><td style=\"text-align: right;\">        0.562402</td><td style=\"text-align: right;\">    0.637593</td></tr>\n",
       "<tr><td>train_fn_afef07f4</td><td style=\"text-align: right;\">  0.703268</td><td style=\"text-align: right;\">   -0.0523986  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.593565</td><td style=\"text-align: right;\">        0.61802 </td><td style=\"text-align: right;\">    0.622925</td></tr>\n",
       "<tr><td>train_fn_b6528c05</td><td style=\"text-align: right;\">  0.784314</td><td style=\"text-align: right;\">   -0.194946   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.489888</td><td style=\"text-align: right;\">        0.855033</td><td style=\"text-align: right;\">    0.361648</td></tr>\n",
       "<tr><td>train_fn_b893840f</td><td style=\"text-align: right;\">  0.792157</td><td style=\"text-align: right;\">   -0.156853   </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.493943</td><td style=\"text-align: right;\">        0.882468</td><td style=\"text-align: right;\">    0.30153 </td></tr>\n",
       "<tr><td>train_fn_bd0bf4fc</td><td style=\"text-align: right;\">  0.8     </td><td style=\"text-align: right;\">   -0.157776   </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.507556</td><td style=\"text-align: right;\">        0.87752 </td><td style=\"text-align: right;\">    0.315742</td></tr>\n",
       "<tr><td>train_fn_c17c8212</td><td style=\"text-align: right;\">  0.734641</td><td style=\"text-align: right;\">   -0.149681   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.534582</td><td style=\"text-align: right;\">        0.688329</td><td style=\"text-align: right;\">    0.589025</td></tr>\n",
       "<tr><td>train_fn_c40ffedf</td><td style=\"text-align: right;\">  0.784314</td><td style=\"text-align: right;\">   -0.120605   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.510478</td><td style=\"text-align: right;\">        0.881868</td><td style=\"text-align: right;\">    0.301571</td></tr>\n",
       "<tr><td>train_fn_c5bd5782</td><td style=\"text-align: right;\">  0.779085</td><td style=\"text-align: right;\">   -0.197671   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.482541</td><td style=\"text-align: right;\">        0.857582</td><td style=\"text-align: right;\">    0.363292</td></tr>\n",
       "<tr><td>train_fn_c8fac80c</td><td style=\"text-align: right;\">  0.581699</td><td style=\"text-align: right;\">    0.0566529  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.630048</td><td style=\"text-align: right;\">        0.573645</td><td style=\"text-align: right;\">    0.638602</td></tr>\n",
       "<tr><td>train_fn_cf688369</td><td style=\"text-align: right;\">  0.572549</td><td style=\"text-align: right;\">    0.136156   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.699943</td><td style=\"text-align: right;\">        0.561952</td><td style=\"text-align: right;\">    0.706869</td></tr>\n",
       "<tr><td>train_fn_e043f686</td><td style=\"text-align: right;\">  0.576471</td><td style=\"text-align: right;\">    0.0710704  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.636427</td><td style=\"text-align: right;\">        0.567948</td><td style=\"text-align: right;\">    0.650133</td></tr>\n",
       "<tr><td>train_fn_e0e6d071</td><td style=\"text-align: right;\">  0.593464</td><td style=\"text-align: right;\">    0.0680504  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.640483</td><td style=\"text-align: right;\">        0.562701</td><td style=\"text-align: right;\">    0.651783</td></tr>\n",
       "<tr><td>train_fn_e131ffde</td><td style=\"text-align: right;\">  0.793464</td><td style=\"text-align: right;\">   -0.197837   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.47946 </td><td style=\"text-align: right;\">        0.870924</td><td style=\"text-align: right;\">    0.324585</td></tr>\n",
       "<tr><td>train_fn_e2e4985c</td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">    0.0181031  </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.56566 </td><td style=\"text-align: right;\">        0.915748</td><td style=\"text-align: right;\">    0.235345</td></tr>\n",
       "<tr><td>train_fn_e5f3be6d</td><td style=\"text-align: right;\">  0.775163</td><td style=\"text-align: right;\">    0.123461   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.626385</td><td style=\"text-align: right;\">        0.915748</td><td style=\"text-align: right;\">    0.222491</td></tr>\n",
       "<tr><td>train_fn_e6f71f4b</td><td style=\"text-align: right;\">  0.776471</td><td style=\"text-align: right;\">    0.206633   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.661842</td><td style=\"text-align: right;\">        0.938385</td><td style=\"text-align: right;\">    0.181234</td></tr>\n",
       "<tr><td>train_fn_e806ebaf</td><td style=\"text-align: right;\">  0.721569</td><td style=\"text-align: right;\">   -0.0536657  </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.595333</td><td style=\"text-align: right;\">        0.608875</td><td style=\"text-align: right;\">    0.627779</td></tr>\n",
       "<tr><td>train_fn_e9edae33</td><td style=\"text-align: right;\">  0.792157</td><td style=\"text-align: right;\">    0.077694   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.598575</td><td style=\"text-align: right;\">        0.932389</td><td style=\"text-align: right;\">    0.196255</td></tr>\n",
       "<tr><td>train_fn_ea791363</td><td style=\"text-align: right;\">  0.769935</td><td style=\"text-align: right;\">   -0.244517   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.493197</td><td style=\"text-align: right;\">        0.749944</td><td style=\"text-align: right;\">    0.537648</td></tr>\n",
       "<tr><td>train_fn_eabbcd11</td><td style=\"text-align: right;\">  0.784314</td><td style=\"text-align: right;\">   -0.10867    </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.503446</td><td style=\"text-align: right;\">        0.899408</td><td style=\"text-align: right;\">    0.274146</td></tr>\n",
       "<tr><td>train_fn_ecce7b9f</td><td style=\"text-align: right;\">  0.786928</td><td style=\"text-align: right;\">   -0.124415   </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.512104</td><td style=\"text-align: right;\">        0.882318</td><td style=\"text-align: right;\">    0.306675</td></tr>\n",
       "<tr><td>train_fn_ecec64cc</td><td style=\"text-align: right;\">  0.786928</td><td style=\"text-align: right;\">    0.182305   </td><td style=\"text-align: right;\">                     5</td><td style=\"text-align: right;\">0.657661</td><td style=\"text-align: right;\">        0.934638</td><td style=\"text-align: right;\">    0.182226</td></tr>\n",
       "<tr><td>train_fn_f3032c36</td><td style=\"text-align: right;\">  0.750327</td><td style=\"text-align: right;\">   -0.210268   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.515955</td><td style=\"text-align: right;\">        0.731804</td><td style=\"text-align: right;\">    0.54564 </td></tr>\n",
       "<tr><td>train_fn_f3bae7c3</td><td style=\"text-align: right;\">  0.783007</td><td style=\"text-align: right;\">   -0.212487   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.473303</td><td style=\"text-align: right;\">        0.857882</td><td style=\"text-align: right;\">    0.353744</td></tr>\n",
       "<tr><td>train_fn_f64cb067</td><td style=\"text-align: right;\">  0.789542</td><td style=\"text-align: right;\">   -0.210232   </td><td style=\"text-align: right;\">                     6</td><td style=\"text-align: right;\">0.488723</td><td style=\"text-align: right;\">        0.847987</td><td style=\"text-align: right;\">    0.365994</td></tr>\n",
       "<tr><td>train_fn_f6f9ae36</td><td style=\"text-align: right;\">  0.794771</td><td style=\"text-align: right;\">   -0.122998   </td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">0.513682</td><td style=\"text-align: right;\">        0.894161</td><td style=\"text-align: right;\">    0.296889</td></tr>\n",
       "<tr><td>train_fn_f75b372a</td><td style=\"text-align: right;\">  0.780392</td><td style=\"text-align: right;\">   -0.0683958  </td><td style=\"text-align: right;\">                     7</td><td style=\"text-align: right;\">0.520215</td><td style=\"text-align: right;\">        0.905404</td><td style=\"text-align: right;\">    0.261666</td></tr>\n",
       "<tr><td>train_fn_fbef7b28</td><td style=\"text-align: right;\">  0.750327</td><td style=\"text-align: right;\">   -0.228447   </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.500352</td><td style=\"text-align: right;\">        0.736751</td><td style=\"text-align: right;\">    0.529833</td></tr>\n",
       "<tr><td>train_fn_fe98dfc2</td><td style=\"text-align: right;\">  0.560784</td><td style=\"text-align: right;\">    0.10986    </td><td style=\"text-align: right;\">                     3</td><td style=\"text-align: right;\">0.669834</td><td style=\"text-align: right;\">        0.560603</td><td style=\"text-align: right;\">    0.671274</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(train_fn pid=481)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=481)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=569)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=569)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=648)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=648)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=726)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=726)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=810)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=810)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=893)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=893)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=979)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=979)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1051)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1051)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1137)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1137)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1225)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1225)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1307)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1307)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1383)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1383)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1488)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1488)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1553)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1553)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1661)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1661)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1735)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1735)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1818)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1818)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1892)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1892)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=1975)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=1975)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2060)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2060)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2132)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2132)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2242)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2242)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2320)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2320)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2399)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2399)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2479)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2479)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2558)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2558)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2638)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2638)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2727)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2727)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2806)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2806)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2894)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2894)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=2968)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=2968)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3054)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3054)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3127)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3127)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3213)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3213)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3286)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3286)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3388)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3388)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3462)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3462)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3551)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3551)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3630)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3630)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3710)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3710)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3799)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3799)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3876)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3876)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=3956)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=3956)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4034)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4034)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4113)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4113)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4191)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4191)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4280)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4280)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4353)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4353)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4442)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4442)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4522)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4522)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4601)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4601)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4692)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4692)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4771)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4771)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4864)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4864)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=4941)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=4941)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5034)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5034)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5113)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5113)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5214)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5214)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5285)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5285)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5372)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5372)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5459)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5459)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5537)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5537)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5616)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5616)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5694)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5694)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5773)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5773)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5860)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5860)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=5931)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=5931)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6019)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6019)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6107)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6107)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6200)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6200)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6284)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6284)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6370)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6370)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6441)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6441)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6527)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6527)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6599)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6599)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6694)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6694)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6766)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6766)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6851)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6851)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=6923)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=6923)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7009)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7009)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7080)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7080)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7167)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7167)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7251)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7251)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7339)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7339)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7437)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7437)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7516)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7516)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7609)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7609)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7686)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7686)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7775)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7775)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7857)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7857)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=7935)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=7935)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8017)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8017)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8092)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8092)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8194)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8194)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8269)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8269)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8352)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8352)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8437)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8437)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(train_fn pid=8520)\u001b[0m /opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "\u001b[36m(train_fn pid=8520)\u001b[0m   warnings.warn(\n",
      "2024-09-01 00:15:09,660\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_fn_2024-08-31_20-57-27' in 0.0528s.\n",
      "2024-09-01 00:15:09,720\tINFO tune.py:1041 -- Total run time: 11862.54 seconds (11851.45 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir /kaggle/working/tensorboard_logs\n",
    "\n",
    "\n",
    "# ray.init(ignore_reinit_error=True)\n",
    "# reporter = CLIReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "#     print_intermediate_tables=False\n",
    "# )\n",
    "\n",
    "reporter = JupyterNotebookReporter(\n",
    "    metric_columns=[\"loss\", \"accuracy\", \"custom_metric\", \"training_iteration\", \"train_loss\", \"train_accuracy\", \"early_stopping_epoch\"],\n",
    "    print_intermediate_tables=False\n",
    ")\n",
    "\n",
    "# tuner = tune.run(\n",
    "#     train_fn,\n",
    "#     config=search_space,\n",
    "#     num_samples=25,\n",
    "#     progress_reporter=reporter,\n",
    "#     resources_per_trial={\"cpu\": 4, \"gpu\": 2},  # Adjust resources as needed\n",
    "#     scheduler=ASHAScheduler(\n",
    "#         metric=\"accuracy\",\n",
    "#         mode=\"max\",\n",
    "#         max_t=15,\n",
    "#         grace_period=1,\n",
    "#         reduction_factor=2\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# reporter = TensorBoardReporter(\n",
    "#     metric_columns=[\"loss\", \"accuracy\", \"training_iteration\", \"train_loss\", \"train_accuracy\"]\n",
    "# )\n",
    "\n",
    "\n",
    "result = tune.run(\n",
    "    train_fn,\n",
    "    resources_per_trial={\"cpu\": 2, \"gpu\": 1},\n",
    "    config=search_space,\n",
    "    num_samples=100,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    search_alg=optuna_search\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b91a3",
   "metadata": {
    "papermill": {
     "duration": 0.044916,
     "end_time": "2024-09-01T00:15:10.031809",
     "exception": false,
     "start_time": "2024-09-01T00:15:09.986893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## REPORTER RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9756f86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:15:10.123958Z",
     "iopub.status.busy": "2024-09-01T00:15:10.122461Z",
     "iopub.status.idle": "2024-09-01T00:15:10.132225Z",
     "shell.execute_reply": "2024-09-01T00:15:10.131091Z"
    },
    "papermill": {
     "duration": 0.058449,
     "end_time": "2024-09-01T00:15:10.134475",
     "exception": false,
     "start_time": "2024-09-01T00:15:10.076026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'dropout_rate': 0.27, 'batch_size': 64, 'weight_decay': 0.001, 'lr': 5e-06, 'epochs': 20}\n",
      "Best trial final validation loss: 0.46973327547311783\n",
      "Best trial final validation accuracy: 0.8013071895424837\n",
      "Best trial final training loss: 0.3516126449619021\n",
      "Best trial final training accuracy: 0.8596806836069261\n",
      "Best trial final custom_metric: -0.24332685178153685\n",
      "Best trial final Early Stopping Epoch: 6\n"
     ]
    }
   ],
   "source": [
    "# best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "best_trial = result.get_best_trial(\"accuracy\", \"max\", \"last\")\n",
    "# best_checkpoint_dir = best_trial.checkpoint.value\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n",
    "print(f\"Best trial final training loss: {best_trial.last_result['train_loss']}\")\n",
    "print(f\"Best trial final training accuracy: {best_trial.last_result['train_accuracy']}\")\n",
    "print(f\"Best trial final custom_metric: {best_trial.last_result['custom_metric']}\")\n",
    "print(f\"Best trial final Early Stopping Epoch: {best_trial.last_result['early_stopping_epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da284472",
   "metadata": {
    "papermill": {
     "duration": 0.046848,
     "end_time": "2024-09-01T00:15:10.229244",
     "exception": false,
     "start_time": "2024-09-01T00:15:10.182396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to Train the Model with the Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80a58212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:15:10.322856Z",
     "iopub.status.busy": "2024-09-01T00:15:10.322432Z",
     "iopub.status.idle": "2024-09-01T00:15:10.351344Z",
     "shell.execute_reply": "2024-09-01T00:15:10.350314Z"
    },
    "papermill": {
     "duration": 0.07787,
     "end_time": "2024-09-01T00:15:10.353603",
     "exception": false,
     "start_time": "2024-09-01T00:15:10.275733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_best_model(config, device, train_dataset = train_ds_pd, val_dataset = validation_ds_pd):\n",
    "    print(f\"\"\"\n",
    "    Tuning Model with:\n",
    "    {config}\n",
    "    \"\"\")\n",
    "#     model = SentimentModel(\n",
    "#         roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#         n_classes=3,\n",
    "#         dropout_rate=config[\"dropout_rate\"]\n",
    "#     )\n",
    "    model = SentimentModel(\n",
    "        roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "        n_classes=3,\n",
    "        dropout_rate=config[\"dropout_rate\"]\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "#     class_weights_tmp = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "#     criterion = nn.CrossEntropyLoss(weight=class_weights_tmp)\n",
    "#     criterion = nn.BCELoss()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    ## DATASET ENCODING\n",
    "    \n",
    "    train_dataset = SentimentDataset(train_ds_pd, tokenizer, max_len=128)\n",
    "    val_dataset = SentimentDataset(validation_ds_pd, tokenizer, max_len=128)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_path = None\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 5\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_since_improvement = 0\n",
    "\n",
    "    \n",
    "    ### Running for config epochs +patience+1 for introducing noise. \n",
    "    \n",
    "    for epoch in range((config[\"epochs\"]+patience+1)):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        correct_train_preds = 0\n",
    "        total_train_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "            with autocast(device_type=device.type):\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            predictions = torch.zeros_like(probabilities)\n",
    "            max_indices = torch.argmax(probabilities, dim=1)\n",
    "            predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "            predictions = predictions.float()\n",
    "                \n",
    "#                 loss = criterion(predictions, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "#             outputs = torch.sigmoid(outputs)\n",
    "            \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "#             predicted_labels = (outputs > 0.5).float()\n",
    "#             correct_train_preds += (predicted_labels == labels).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#             total_train_preds += labels.numel()\n",
    "\n",
    "#             correct_train_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#             total_train_preds += labels.size(0)\n",
    "\n",
    "            correct_train_preds += (predictions == labels).sum().item()\n",
    "            total_train_preds += labels.numel()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_accuracy = correct_train_preds / total_train_preds\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        correct_val_preds = 0\n",
    "        total_val_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#                 outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "                with autocast(device_type=device.type):\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                probabilities = torch.sigmoid(outputs)\n",
    "                predictions = torch.zeros_like(probabilities)\n",
    "                max_indices = torch.argmax(probabilities, dim=1)\n",
    "                predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "                predictions = predictions.float()\n",
    "\n",
    "#                     loss = criterion(predictions, labels)\n",
    "                \n",
    "#                 outputs = torch.sigmoid(outputs)\n",
    "                \n",
    "# NOTE: Apply the sigmoid fn to outputs after BCEWithLogitsLoss because the loss fn already comes with sigmoid applied, so passing the sigmoid applied ouput will give erraneous results.\n",
    "# If we use BCELoss then pass the sigmoid applied output.\n",
    "                \n",
    "                total_val_loss += loss.item()\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).sum().item()\n",
    "# #                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "    \n",
    "#                 predicted_labels = (outputs > 0.5).float()\n",
    "#                 correct_val_preds += (predicted_labels == labels).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += ((outputs > 0.5) == (labels > 0.5)).sum().item()\n",
    "#                 total_val_preds += labels.numel()\n",
    "\n",
    "#                 correct_val_preds += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "#                 total_val_preds += labels.size(0)\n",
    "\n",
    "                correct_val_preds += (predictions == labels).sum().item()\n",
    "                total_val_preds += labels.numel()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct_val_preds / total_val_preds\n",
    "\n",
    "        # Save the model checkpoint after each epoch\n",
    "        checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#         torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "#         # Save the best model based on validation loss\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "#             best_model_path = checkpoint_path\n",
    "\n",
    "        # Learning rate scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_since_improvement = 0\n",
    "            best_model_path = checkpoint_path\n",
    "            # Save the model checkpoint with the best validation loss\n",
    "#             checkpoint_path = f\"/kaggle/working/best_checkpoint.pt\"\n",
    "#             torch.save(model.state_dict(), checkpoint_path)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'config': config  # Save configuration\n",
    "            }, checkpoint_path)\n",
    "    \n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "        early_stopping(avg_val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            print(f\"Best Model Epoch Saved: {epoch - patience +1}\")\n",
    "#             print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "#         if epochs_since_improvement >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "#             print(f\"Best Model Epoch Saved: {epoch - patience}\")\n",
    "#             break\n",
    "            \n",
    "#         custom_metric = calculate_custom_metric(avg_val_loss, avg_train_loss)        \n",
    "        custom_metric = calculate_custom_metric(avg_val_loss, val_accuracy, avg_train_loss, train_accuracy)\n",
    "        print(f\"\"\"\n",
    "        Validation Loss: {avg_val_loss},\n",
    "        Training Loss: {avg_train_loss},\n",
    "        Argmax Binary Validation Accuracy: {val_accuracy},\n",
    "        Argmax Binary Training Accuracy: {train_accuracy},\n",
    "        Custom Metric: {custom_metric},\n",
    "        Epochs: {epoch+1}\n",
    "        \"\"\")\n",
    "    \n",
    "    print(f\"Best Validation Loss: {best_val_loss}, Best Validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df5ea69",
   "metadata": {
    "papermill": {
     "duration": 0.043076,
     "end_time": "2024-09-01T00:15:10.441677",
     "exception": false,
     "start_time": "2024-09-01T00:15:10.398601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BEST MODEL AFTER FINAL TRAINING & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da1c11ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:15:10.533365Z",
     "iopub.status.busy": "2024-09-01T00:15:10.532945Z",
     "iopub.status.idle": "2024-09-01T00:22:32.571334Z",
     "shell.execute_reply": "2024-09-01T00:22:32.570130Z"
    },
    "papermill": {
     "duration": 442.131824,
     "end_time": "2024-09-01T00:22:32.618212",
     "exception": false,
     "start_time": "2024-09-01T00:15:10.486388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Tuning Model with:\n",
      "    {'dropout_rate': 0.27, 'batch_size': 64, 'weight_decay': 0.001, 'lr': 5e-06, 'epochs': 20}\n",
      "    \n",
      "\n",
      "        Validation Loss: 0.6305736973881721,\n",
      "        Training Loss: 0.6618401025022779,\n",
      "        Argmax Binary Validation Accuracy: 0.5830065359477125,\n",
      "        Argmax Binary Training Accuracy: 0.5576043774829473,\n",
      "        Custom Metric: 0.07590144322989512,\n",
      "        Epochs: 1\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.5190964788198471,\n",
      "        Training Loss: 0.5940516757113593,\n",
      "        Argmax Binary Validation Accuracy: 0.7503267973856209,\n",
      "        Argmax Binary Training Accuracy: 0.6776853309347125,\n",
      "        Custom Metric: -0.1574319868945635,\n",
      "        Epochs: 2\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.46462612971663475,\n",
      "        Training Loss: 0.4789854096514838,\n",
      "        Argmax Binary Validation Accuracy: 0.7790849673202614,\n",
      "        Argmax Binary Training Accuracy: 0.7851735252229968,\n",
      "        Custom Metric: -0.3042349186848345,\n",
      "        Epochs: 3\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.4575534760951996,\n",
      "        Training Loss: 0.41745075796331677,\n",
      "        Argmax Binary Validation Accuracy: 0.7934640522875817,\n",
      "        Argmax Binary Training Accuracy: 0.8252005097069185,\n",
      "        Custom Metric: -0.29999098841677224,\n",
      "        Epochs: 4\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.465589240193367,\n",
      "        Training Loss: 0.38276089557579585,\n",
      "        Argmax Binary Validation Accuracy: 0.796078431372549,\n",
      "        Argmax Binary Training Accuracy: 0.8425905104564875,\n",
      "        Custom Metric: -0.26581897932842713,\n",
      "        Epochs: 5\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.4628063663840294,\n",
      "        Training Loss: 0.3473822649036135,\n",
      "        Argmax Binary Validation Accuracy: 0.7986928104575164,\n",
      "        Argmax Binary Training Accuracy: 0.8653774079904055,\n",
      "        Custom Metric: -0.24483209456683452,\n",
      "        Epochs: 6\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.47443003952503204,\n",
      "        Training Loss: 0.31247044035366606,\n",
      "        Argmax Binary Validation Accuracy: 0.803921568627451,\n",
      "        Argmax Binary Training Accuracy: 0.8823176673412788,\n",
      "        Custom Metric: -0.20931368015982207,\n",
      "        Epochs: 7\n",
      "        \n",
      "\n",
      "        Validation Loss: 0.47625773400068283,\n",
      "        Training Loss: 0.28413797936269214,\n",
      "        Argmax Binary Validation Accuracy: 0.7973856209150327,\n",
      "        Argmax Binary Training Accuracy: 0.8979087024960648,\n",
      "        Custom Metric: -0.17480646880483852,\n",
      "        Epochs: 8\n",
      "        \n",
      "Early stopping at epoch 9\n",
      "Best Model Epoch Saved: 4\n",
      "Best Validation Loss: 0.4575534760951996, Best Validation accuracy: 0.7947712418300653\n"
     ]
    }
   ],
   "source": [
    "best_config = best_trial.config\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model with the best configuration\n",
    "best_model, best_model_path = train_best_model(best_config, device, train_ds_pd, validation_ds_pd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72eca39",
   "metadata": {
    "papermill": {
     "duration": 0.041833,
     "end_time": "2024-09-01T00:22:32.702761",
     "exception": false,
     "start_time": "2024-09-01T00:22:32.660928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f9dae90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:22:32.786293Z",
     "iopub.status.busy": "2024-09-01T00:22:32.785864Z",
     "iopub.status.idle": "2024-09-01T00:22:34.028641Z",
     "shell.execute_reply": "2024-09-01T00:22:34.027696Z"
    },
    "papermill": {
     "duration": 1.287565,
     "end_time": "2024-09-01T00:22:34.031121",
     "exception": false,
     "start_time": "2024-09-01T00:22:32.743556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved at: /kaggle/working/final_best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "# final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path) \n",
    "\n",
    "#### Comment when wanting to select the model which is stopped early to avoid over or under fitting\n",
    "\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# torch.save(best_model.state_dict(), final_model_path)\n",
    "torch.save({'model_state_dict': best_model.state_dict(),'config': best_config}, final_model_path)\n",
    "\n",
    "print(f\"Best model saved at: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f14de7",
   "metadata": {
    "papermill": {
     "duration": 0.041003,
     "end_time": "2024-09-01T00:22:34.116838",
     "exception": false,
     "start_time": "2024-09-01T00:22:34.075835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a699877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:22:34.200751Z",
     "iopub.status.busy": "2024-09-01T00:22:34.200005Z",
     "iopub.status.idle": "2024-09-01T00:22:35.826019Z",
     "shell.execute_reply": "2024-09-01T00:22:35.824934Z"
    },
    "papermill": {
     "duration": 1.670793,
     "end_time": "2024-09-01T00:22:35.828400",
     "exception": false,
     "start_time": "2024-09-01T00:22:34.157607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /kaggle/working/final_best_model.pt for inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "final_model_path = \"/kaggle/working/final_best_model.pt\"\n",
    "# final_model_path = \"/kaggle/input/tachygraphy-lv2-emotion-moodtags-v1/transformers/default/1/final_best_model.pt\"\n",
    "\n",
    "\n",
    "checkpoint = torch.load(final_model_path)\n",
    "config = checkpoint['config']\n",
    "\n",
    "# loaded_model = SentimentModel(\n",
    "#     roberta_model=RobertaModel.from_pretrained(\"roberta-base\"),\n",
    "#     n_classes=3,\n",
    "#     dropout_rate=config[\"dropout_rate\"]\n",
    "# )\n",
    "loaded_model = SentimentModel(\n",
    "    roberta_model=DebertaV2Model.from_pretrained('microsoft/deberta-v3-base'),\n",
    "    n_classes=3,\n",
    "    dropout_rate=config[\"dropout_rate\"]\n",
    ")\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(f\"Loaded model from {final_model_path} for inference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c451fb",
   "metadata": {
    "papermill": {
     "duration": 0.04584,
     "end_time": "2024-09-01T00:22:35.919397",
     "exception": false,
     "start_time": "2024-09-01T00:22:35.873557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PREDICT ON RANDOM INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a261e",
   "metadata": {
    "papermill": {
     "duration": 0.044067,
     "end_time": "2024-09-01T00:22:36.008121",
     "exception": false,
     "start_time": "2024-09-01T00:22:35.964054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1687a875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:22:36.100658Z",
     "iopub.status.busy": "2024-09-01T00:22:36.100238Z",
     "iopub.status.idle": "2024-09-01T00:22:36.108253Z",
     "shell.execute_reply": "2024-09-01T00:22:36.107265Z"
    },
    "papermill": {
     "duration": 0.055636,
     "end_time": "2024-09-01T00:22:36.110213",
     "exception": false,
     "start_time": "2024-09-01T00:22:36.054577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer, device, max_len=128):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    return torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "#     # Convert logits to probabilities using sigmoid\n",
    "#     probabilities = torch.sigmoid(logits)\n",
    "    \n",
    "#     # Convert probabilities to binary predictions\n",
    "#     predictions = torch.zeros_like(probabilities)\n",
    "#     max_indices = torch.argmax(probabilities, dim=1)\n",
    "#     predictions.scatter_(1, max_indices.unsqueeze(1), 1)\n",
    "    \n",
    "#     # Move predictions to CPU and convert to numpy for easy manipulation\n",
    "#     predictions_array = predictions.cpu().numpy().squeeze()\n",
    "\n",
    "#     return predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13f25229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:22:36.199628Z",
     "iopub.status.busy": "2024-09-01T00:22:36.199242Z",
     "iopub.status.idle": "2024-09-01T00:22:36.209768Z",
     "shell.execute_reply": "2024-09-01T00:22:36.208981Z"
    },
    "papermill": {
     "duration": 0.05751,
     "end_time": "2024-09-01T00:22:36.211855",
     "exception": false,
     "start_time": "2024-09-01T00:22:36.154345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = loaded_model\n",
    "best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c56aee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:22:36.305979Z",
     "iopub.status.busy": "2024-09-01T00:22:36.305211Z",
     "iopub.status.idle": "2024-09-01T00:22:36.878743Z",
     "shell.execute_reply": "2024-09-01T00:22:36.877905Z"
    },
    "papermill": {
     "duration": 0.62265,
     "end_time": "2024-09-01T00:22:36.881162",
     "exception": false,
     "start_time": "2024-09-01T00:22:36.258512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb18d09",
   "metadata": {
    "papermill": {
     "duration": 0.040789,
     "end_time": "2024-09-01T00:22:36.964337",
     "exception": false,
     "start_time": "2024-09-01T00:22:36.923548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Samples & Random Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "741180ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:22:37.048159Z",
     "iopub.status.busy": "2024-09-01T00:22:37.047842Z",
     "iopub.status.idle": "2024-09-01T00:22:38.929111Z",
     "shell.execute_reply": "2024-09-01T00:22:38.928039Z"
    },
    "papermill": {
     "duration": 1.925901,
     "end_time": "2024-09-01T00:22:38.931549",
     "exception": false,
     "start_time": "2024-09-01T00:22:37.005648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'hey! hru, wanna ply valo toni8?': [[0.03144173 0.7496201  0.21723984]]\n",
      "NEAGTIVE: 0.0, NEUTRAL: 1.0, POSITIVE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"915b045a-b572-4ca4-993d-bd3312ac3c12\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"915b045a-b572-4ca4-993d-bd3312ac3c12\")) {                    Plotly.newPlot(                        \"915b045a-b572-4ca4-993d-bd3312ac3c12\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.03144173,0.7496201,0.21723984,0.03144173],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('915b045a-b572-4ca4-993d-bd3312ac3c12');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"hey! hru, wanna ply valo toni8?\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93b95573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:22:39.026343Z",
     "iopub.status.busy": "2024-09-01T00:22:39.025348Z",
     "iopub.status.idle": "2024-09-01T00:22:39.391690Z",
     "shell.execute_reply": "2024-09-01T00:22:39.390585Z"
    },
    "papermill": {
     "duration": 0.417076,
     "end_time": "2024-09-01T00:22:39.394080",
     "exception": false,
     "start_time": "2024-09-01T00:22:38.977004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'what a badass char is arthur, he is the best game char ever made, i luv rdr2': [[0.02675105 0.04900789 0.94499636]]\n",
      "NEAGTIVE: 0.0, NEUTRAL: 0.0, POSITIVE: 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"f1aedaca-107d-4869-aeb2-cdbb71ec7419\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f1aedaca-107d-4869-aeb2-cdbb71ec7419\")) {                    Plotly.newPlot(                        \"f1aedaca-107d-4869-aeb2-cdbb71ec7419\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.026751045,0.049007893,0.94499636,0.026751045],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f1aedaca-107d-4869-aeb2-cdbb71ec7419');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"what a badass char is arthur, he is the best game char ever made, i luv rdr2\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7240284e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T00:22:39.492423Z",
     "iopub.status.busy": "2024-09-01T00:22:39.491868Z",
     "iopub.status.idle": "2024-09-01T00:22:39.858049Z",
     "shell.execute_reply": "2024-09-01T00:22:39.857029Z"
    },
    "papermill": {
     "duration": 0.417887,
     "end_time": "2024-09-01T00:22:39.860451",
     "exception": false,
     "start_time": "2024-09-01T00:22:39.442564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment polarities for 'I don't no fr y hes sooo sad.': [[0.9185543  0.05055473 0.07316567]]\n",
      "NEAGTIVE: 1.0, NEUTRAL: 0.0, POSITIVE: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"266b1a02-5f52-42ab-a0e2-7857bf02506b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"266b1a02-5f52-42ab-a0e2-7857bf02506b\")) {                    Plotly.newPlot(                        \"266b1a02-5f52-42ab-a0e2-7857bf02506b\",                        [{\"hovertemplate\":\"r=%{r}\\u003cbr\\u003etheta=%{theta}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"r\":[0.9185543,0.050554726,0.07316567,0.9185543],\"showlegend\":false,\"subplot\":\"polar\",\"theta\":[\"negative\",\"neutral\",\"positive\",\"negative\"],\"type\":\"scatterpolar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"polar\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"angularaxis\":{\"direction\":\"clockwise\",\"rotation\":90}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('266b1a02-5f52-42ab-a0e2-7857bf02506b');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_text = \"I don't no fr y hes sooo sad.\"\n",
    "predictions = predict(sample_text, best_model, tokenizer, device, max_len=128)\n",
    "print(f\"Predicted sentiment polarities for '{sample_text}': {predictions}\")\n",
    "\n",
    "\n",
    "predictions_array = predictions.squeeze()\n",
    "binary_predictions = np.zeros_like(predictions_array)\n",
    "max_indices = np.argmax(predictions_array)\n",
    "binary_predictions[max_indices] = 1\n",
    "\n",
    "print(f\"NEAGTIVE: {binary_predictions[0]}, NEUTRAL: {binary_predictions[1]}, POSITIVE: {binary_predictions[2]}\")\n",
    "\n",
    "# labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "\n",
    "sentiment_polarities = []\n",
    "for items in predictions_array:\n",
    "    sentiment_polarities.append(items)\n",
    "\n",
    "fig = px.line_polar(pd.DataFrame(dict(r=sentiment_polarities, theta=SENTIMENT_POLARITY_LABELS)), r='r', theta='theta', line_close=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "normalized_predictions = predictions_array / predictions_array.sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "left = 0\n",
    "for i in range(len(normalized_predictions)):\n",
    "    ax.barh(0, normalized_predictions[i], color=plt.cm.tab10(i), left=left, label=SENTIMENT_POLARITY_LABELS[i])\n",
    "    left += normalized_predictions[i]\n",
    "\n",
    "# Add legend\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=len(SENTIMENT_POLARITY_LABELS))\n",
    "\n",
    "# Add title\n",
    "plt.title('Sentiment Polarity Prediction Distribution')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5557640,
     "sourceId": 9273793,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12359.337839,
   "end_time": "2024-09-01T00:22:45.236505",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-31T20:56:45.898666",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00780f5762254afbb13c4e5d7fa1aaf7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03825f62175d42afbaaf0d3f187c2e8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d1affc1a27a475ebec536a3832c1102": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_959ab516082f474da5cdcabe8c47420f",
       "placeholder": "​",
       "style": "IPY_MODEL_7b4302e12b6b45ebafacd789dbd5da62",
       "value": "spm.model: 100%"
      }
     },
     "147160178e854b96bab5cbfb225c5105": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2cfc170929354d8a83abdda2b05cc324": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "378ef5000bc94052bb4d2a7c22f26fa7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3880dcf546c24e04800a2b51608c721a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d96333291af4743a23c0ac30cb8e0fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4881ccbe1f93475f82bc4d4f305030ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5522c2dd6d014e9abb23646dbb6780e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6641e5e1abf14c55a7035c497a7aaa01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "68da16dec72946f982fa4db66045534e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_03825f62175d42afbaaf0d3f187c2e8c",
       "placeholder": "​",
       "style": "IPY_MODEL_147160178e854b96bab5cbfb225c5105",
       "value": "tokenizer_config.json: 100%"
      }
     },
     "6d5bd51a4679499d8b8e6d43173155da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d73e8a714532495a9a4547dce30e5a16",
       "placeholder": "​",
       "style": "IPY_MODEL_dfc58c6f54be4a2eae80b751d6281810",
       "value": " 52.0/52.0 [00:00&lt;00:00, 3.77kB/s]"
      }
     },
     "7b4302e12b6b45ebafacd789dbd5da62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "856aade1245842ed816c83632d17b8bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0d1affc1a27a475ebec536a3832c1102",
        "IPY_MODEL_d72bae35ba16498c9834e6ca92cbc902",
        "IPY_MODEL_af8d66d93a5c4104969602defed5034f"
       ],
       "layout": "IPY_MODEL_9fec4e3641c944eebede889d92e842b5"
      }
     },
     "8c3a75f1f26047a6bf556d7cffd32530": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8fe491bc733a468290f12483f2b3d01d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_68da16dec72946f982fa4db66045534e",
        "IPY_MODEL_fd8fb03494d64a869a1804b508169ca9",
        "IPY_MODEL_6d5bd51a4679499d8b8e6d43173155da"
       ],
       "layout": "IPY_MODEL_00780f5762254afbb13c4e5d7fa1aaf7"
      }
     },
     "959ab516082f474da5cdcabe8c47420f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9fec4e3641c944eebede889d92e842b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af8638bda6af4747903da99a7f4a730a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af8d66d93a5c4104969602defed5034f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2cfc170929354d8a83abdda2b05cc324",
       "placeholder": "​",
       "style": "IPY_MODEL_c5b137e291b54ff6917cfdb05438ceda",
       "value": " 2.46M/2.46M [00:00&lt;00:00, 18.3MB/s]"
      }
     },
     "bc4ea83f513d41ba89128c4964820863": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bcd8dc4f3aa74159b37edf0dfab61479": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3880dcf546c24e04800a2b51608c721a",
       "placeholder": "​",
       "style": "IPY_MODEL_8c3a75f1f26047a6bf556d7cffd32530",
       "value": " 579/579 [00:00&lt;00:00, 43.4kB/s]"
      }
     },
     "c47a0c5239844f9f8bb8b6f78d10ec60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ec2365361fab45c5bcc639623874f897",
        "IPY_MODEL_fcb39d49a36c4c9b996164c150d8326c",
        "IPY_MODEL_bcd8dc4f3aa74159b37edf0dfab61479"
       ],
       "layout": "IPY_MODEL_af8638bda6af4747903da99a7f4a730a"
      }
     },
     "c5b137e291b54ff6917cfdb05438ceda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d21485f4c02a461bb73dfed001bd2f5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d72bae35ba16498c9834e6ca92cbc902": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d21485f4c02a461bb73dfed001bd2f5c",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4881ccbe1f93475f82bc4d4f305030ee",
       "value": 2464616.0
      }
     },
     "d73e8a714532495a9a4547dce30e5a16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfc58c6f54be4a2eae80b751d6281810": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ec2365361fab45c5bcc639623874f897": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bc4ea83f513d41ba89128c4964820863",
       "placeholder": "​",
       "style": "IPY_MODEL_3d96333291af4743a23c0ac30cb8e0fa",
       "value": "config.json: 100%"
      }
     },
     "f5b104fcce1f41f6baca40eeea52bd31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fcb39d49a36c4c9b996164c150d8326c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f5b104fcce1f41f6baca40eeea52bd31",
       "max": 579.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5522c2dd6d014e9abb23646dbb6780e2",
       "value": 579.0
      }
     },
     "fd8fb03494d64a869a1804b508169ca9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_378ef5000bc94052bb4d2a7c22f26fa7",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6641e5e1abf14c55a7035c497a7aaa01",
       "value": 52.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
