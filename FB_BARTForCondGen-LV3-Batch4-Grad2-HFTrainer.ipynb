{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5609069,"sourceId":10906063,"sourceType":"datasetVersion"}],"dockerImageVersionId":30919,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"papermill":{"default_parameters":{},"duration":2126.637895,"end_time":"2025-03-05T12:26:20.327517","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-03-05T11:50:53.689622","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"00038f3926de4721994cf9b7e9aa9657":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ecef513d654432a8d53410d35dadea2","IPY_MODEL_7a7b8600f71341479de4ee4670716f6b","IPY_MODEL_d3bdb2b6fe4a43c89430deecbc86dc6e"],"layout":"IPY_MODEL_766bb63f183b40a79db566f74df27c1e","tabbable":null,"tooltip":null}},"0101cd357c1949bda2f882c2b0e74c57":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02efe895751844dab170c3467b76cd19":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03879d6253a74052815d19f4ca776aa2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"0677a80af9bf4270bcbaac8a7c5a9f03":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"0794ea0d3f954088a764a5ea961043c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6a97f5a184d4c23b1745c35d318456f","IPY_MODEL_f231a90435b34d6ba99d1ffdb9bd9f49","IPY_MODEL_e8e2685ccba74e6682a52e996de5b8dd"],"layout":"IPY_MODEL_9d168829da64442ab9644b31c26bd071","tabbable":null,"tooltip":null}},"134a5e18b95e4a528b7837760dabb51b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_31164b5804794a9baac6ee03e54f0514","max":557912620,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae958e51405c40d0b5b015cc467717fc","tabbable":null,"tooltip":null,"value":557912620}},"141ab5b4f674450097f92fe870f704ba":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16a1958995ed497b98904cb5be0d7ece":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c3b058d772941998c82eccb8908439e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e50dbff470242ecab6bdb1a4761136b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_3cc0ad9018b947f0baaa962c43e02348","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a761f68de4f4c2cad249cbd04fadde4","tabbable":null,"tooltip":null,"value":456318}},"1f527be401f846d89a4cb4eb0c9983de":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6d5ec840777a4def927068d523f12a79","placeholder":"​","style":"IPY_MODEL_0677a80af9bf4270bcbaac8a7c5a9f03","tabbable":null,"tooltip":null,"value":"tokenizer.json: 100%"}},"25d77e5225f24943926422f5f47ffdd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba479d5dcd744118b7c90c358f99f9db","IPY_MODEL_1e50dbff470242ecab6bdb1a4761136b","IPY_MODEL_6cdbc87391d7424292130288f988c765"],"layout":"IPY_MODEL_552af5586a934f2e838c26f272877c27","tabbable":null,"tooltip":null}},"26d484dd4def4c4a9f1a65324192c407":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"26fd4da2583b4f85a3f9a48579292c3a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29616f1438774fc0af6be2f0d35117f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"2a4ec45e5de145ea9dce779a4cf5d0b8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30577ab7a8764c21a4f8ba1695cfd59d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31164b5804794a9baac6ee03e54f0514":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329ae44614704447b313dba0c369c275":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6fd3478c3a2b459da81508677f15b22b","placeholder":"​","style":"IPY_MODEL_d678ca01c48143b582f86e1de9c7e5e9","tabbable":null,"tooltip":null,"value":" 1.36M/1.36M [00:00&lt;00:00, 7.76MB/s]"}},"38ae831ccf0a40cf8981b298d75e0d83":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39aef897a86446bcbb52275a8390851a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c5a7019d13047b4b4d5ce775061c2ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_141ab5b4f674450097f92fe870f704ba","placeholder":"​","style":"IPY_MODEL_8c6edad9181540d89ec08c3b53a55895","tabbable":null,"tooltip":null,"value":" 10280/10280 [00:03&lt;00:00, 2697.34 examples/s]"}},"3cc0ad9018b947f0baaa962c43e02348":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d535a23d4884a8dadf7aeb76b631b1d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4026ce472e494977a4dbde4cba09d49e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45d5eac619404684937407d60feb6c53":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_4026ce472e494977a4dbde4cba09d49e","placeholder":"​","style":"IPY_MODEL_26d484dd4def4c4a9f1a65324192c407","tabbable":null,"tooltip":null,"value":"Map: 100%"}},"4a1c63799b0f4a6d88a105027d5e0250":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52b84b3fc31546dd89020d5b80a0ca92":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0e46c6f41fa49fdb61164326e749e20","IPY_MODEL_134a5e18b95e4a528b7837760dabb51b","IPY_MODEL_dade9d7286264cb190179f866dae6e73"],"layout":"IPY_MODEL_c594b868efaa4764a63ad4dddadc9972","tabbable":null,"tooltip":null}},"52fced92663b42478396609b0a03a653":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"552af5586a934f2e838c26f272877c27":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"597249046002474290eb48d187e8eeda":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_02efe895751844dab170c3467b76cd19","placeholder":"​","style":"IPY_MODEL_a72737e8f66243dba326884c515a6b65","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"5d9b7685646946829378bb8985355487":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61725a5627f94104a7e10fcde739ed9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f527be401f846d89a4cb4eb0c9983de","IPY_MODEL_d12544ff102343c7bee199509884eb8d","IPY_MODEL_329ae44614704447b313dba0c369c275"],"layout":"IPY_MODEL_66dbce1fb13e4796a146c8db97edff6e","tabbable":null,"tooltip":null}},"6523946b193b4df48aae1d4d8d58265e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6661e4bc557a44858eebc245c51d22f1":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66dbce1fb13e4796a146c8db97edff6e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cdbc87391d7424292130288f988c765":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3d535a23d4884a8dadf7aeb76b631b1d","placeholder":"​","style":"IPY_MODEL_d85b230591f5423baec52dd250df882f","tabbable":null,"tooltip":null,"value":" 456k/456k [00:00&lt;00:00, 10.7MB/s]"}},"6d5ec840777a4def927068d523f12a79":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ecef513d654432a8d53410d35dadea2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_26fd4da2583b4f85a3f9a48579292c3a","placeholder":"​","style":"IPY_MODEL_29616f1438774fc0af6be2f0d35117f2","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"6fd3478c3a2b459da81508677f15b22b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"766bb63f183b40a79db566f74df27c1e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a761f68de4f4c2cad249cbd04fadde4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a7b8600f71341479de4ee4670716f6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_30577ab7a8764c21a4f8ba1695cfd59d","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e97f175265c042b49ceb288583a5adc1","tabbable":null,"tooltip":null,"value":1716}},"7c02453cd0814dbd8d4608a3aec9f9e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"82515762bad3457babbc7e18a3c3a74a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"83c5541ae46f48349b5e467faa626802":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e45f40f159184a5e8f91e843cc83bb4d","placeholder":"​","style":"IPY_MODEL_89c6967bc1aa4409b9b6c3eef188ced5","tabbable":null,"tooltip":null,"value":" 558M/558M [00:02&lt;00:00, 229MB/s]"}},"89c6967bc1aa4409b9b6c3eef188ced5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8c6edad9181540d89ec08c3b53a55895":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"957df319edff4e29a12775309db547e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b605f465b2614ec6984a28b4815407a7","IPY_MODEL_f56f2dc5c23241cda98622428e89b7bc","IPY_MODEL_d8509e7d8315455d8ef53925777d9eaf"],"layout":"IPY_MODEL_2a4ec45e5de145ea9dce779a4cf5d0b8","tabbable":null,"tooltip":null}},"987f463fa54144bc9c9421067c743390":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d168829da64442ab9644b31c26bd071":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a72737e8f66243dba326884c515a6b65":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a7ca2e0913944598bb5e0c57584b7575":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"ab60fcef05a942afb6c90ddc3b97dd2e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae958e51405c40d0b5b015cc467717fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b605f465b2614ec6984a28b4815407a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_52fced92663b42478396609b0a03a653","placeholder":"​","style":"IPY_MODEL_ede6a0c04a0545718948ae24618a9f09","tabbable":null,"tooltip":null,"value":"Map: 100%"}},"ba479d5dcd744118b7c90c358f99f9db":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_6661e4bc557a44858eebc245c51d22f1","placeholder":"​","style":"IPY_MODEL_e75c3917365644869a2e598c9a7cbc2c","tabbable":null,"tooltip":null,"value":"merges.txt: 100%"}},"c594b868efaa4764a63ad4dddadc9972":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce8f31bfbc4d460bacc30861609cfb82":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d12544ff102343c7bee199509884eb8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_16a1958995ed497b98904cb5be0d7ece","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7bbe3fca8994bd9b38578e1734db469","tabbable":null,"tooltip":null,"value":1355863}},"d1d0d85b6c754a90b1b5ecc2c2b9e8f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_ec4c28c80e744a4a9e53d134e4c31967","max":557709915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db18b661127b44c484ade66bf6d1877a","tabbable":null,"tooltip":null,"value":557709915}},"d3bdb2b6fe4a43c89430deecbc86dc6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_39aef897a86446bcbb52275a8390851a","placeholder":"​","style":"IPY_MODEL_a7ca2e0913944598bb5e0c57584b7575","tabbable":null,"tooltip":null,"value":" 1.72k/1.72k [00:00&lt;00:00, 180kB/s]"}},"d65ac38dd5cd423cab0becd6ed84947f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45d5eac619404684937407d60feb6c53","IPY_MODEL_fe60b2c800624518bf0c3a2b4fb31100","IPY_MODEL_3c5a7019d13047b4b4d5ce775061c2ab"],"layout":"IPY_MODEL_f3b5d0c4932d4243a0e881d66eb7eecf","tabbable":null,"tooltip":null}},"d678ca01c48143b582f86e1de9c7e5e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d8509e7d8315455d8ef53925777d9eaf":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_ab60fcef05a942afb6c90ddc3b97dd2e","placeholder":"​","style":"IPY_MODEL_f88dee27bee84944934b09dae74840f4","tabbable":null,"tooltip":null,"value":" 1047/1047 [00:00&lt;00:00, 2572.99 examples/s]"}},"d85b230591f5423baec52dd250df882f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"da55914d0437483588539885873abc56":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dade9d7286264cb190179f866dae6e73":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_987f463fa54144bc9c9421067c743390","placeholder":"​","style":"IPY_MODEL_ce8f31bfbc4d460bacc30861609cfb82","tabbable":null,"tooltip":null,"value":" 558M/558M [00:15&lt;00:00, 37.3MB/s]"}},"db18b661127b44c484ade66bf6d1877a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0e46c6f41fa49fdb61164326e749e20":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_da55914d0437483588539885873abc56","placeholder":"​","style":"IPY_MODEL_7c02453cd0814dbd8d4608a3aec9f9e2","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"e0f32f4ac7fa44daade73e6ee3aff060":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e45f40f159184a5e8f91e843cc83bb4d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e75c3917365644869a2e598c9a7cbc2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e7bbe3fca8994bd9b38578e1734db469":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8e2685ccba74e6682a52e996de5b8dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f464ff9ae7a9492799e09514d4c35ec2","placeholder":"​","style":"IPY_MODEL_03879d6253a74052815d19f4ca776aa2","tabbable":null,"tooltip":null,"value":" 899k/899k [00:00&lt;00:00, 12.4MB/s]"}},"e97f175265c042b49ceb288583a5adc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec4c28c80e744a4a9e53d134e4c31967":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ede6a0c04a0545718948ae24618a9f09":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f231a90435b34d6ba99d1ffdb9bd9f49":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_38ae831ccf0a40cf8981b298d75e0d83","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6523946b193b4df48aae1d4d8d58265e","tabbable":null,"tooltip":null,"value":898823}},"f3b5d0c4932d4243a0e881d66eb7eecf":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f464ff9ae7a9492799e09514d4c35ec2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4a33ab174e24bccb94198835507d488":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f56f2dc5c23241cda98622428e89b7bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_0101cd357c1949bda2f882c2b0e74c57","max":1047,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a1c63799b0f4a6d88a105027d5e0250","tabbable":null,"tooltip":null,"value":1047}},"f6a97f5a184d4c23b1745c35d318456f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e0f32f4ac7fa44daade73e6ee3aff060","placeholder":"​","style":"IPY_MODEL_82515762bad3457babbc7e18a3c3a74a","tabbable":null,"tooltip":null,"value":"vocab.json: 100%"}},"f88dee27bee84944934b09dae74840f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"fe60b2c800624518bf0c3a2b4fb31100":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_f4a33ab174e24bccb94198835507d488","max":10280,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c3b058d772941998c82eccb8908439e","tabbable":null,"tooltip":null,"value":10280}},"ff5fb79dcb54424ab8dfc5eff9a89a72":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_597249046002474290eb48d187e8eeda","IPY_MODEL_d1d0d85b6c754a90b1b5ecc2c2b9e8f6","IPY_MODEL_83c5541ae46f48349b5e467faa626802"],"layout":"IPY_MODEL_5d9b7685646946829378bb8985355487","tabbable":null,"tooltip":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/archismancoder/fb-bartforcondgen-lv3-batch4-grad2-hftrainer?scriptVersionId=226112644\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"id":"21f17950","cell_type":"code","source":"!pip install transformers pandas openpyxl torch peft bs4 emoji joblib scikit-learn ray huggingface_hub datasets optuna lxml optim","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:50:56.421925Z","iopub.status.busy":"2025-03-05T11:50:56.421719Z","iopub.status.idle":"2025-03-05T11:51:03.551205Z","shell.execute_reply":"2025-03-05T11:51:03.55011Z"},"papermill":{"duration":7.138236,"end_time":"2025-03-05T11:51:03.552835","exception":false,"start_time":"2025-03-05T11:50:56.414599","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\r\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\r\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\r\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\r\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\r\n","Collecting bs4\r\n","  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\r\n","Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.14.1)\r\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\r\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\r\n","Requirement already satisfied: ray in /usr/local/lib/python3.10/dist-packages (2.42.1)\r\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.0)\r\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\r\n","Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.2.1)\r\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (5.3.0)\r\n","Collecting optim\r\n","  Downloading optim-0.1.0.tar.gz (4.1 kB)\r\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\r\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\r\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\r\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\r\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\r\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\r\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\r\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\r\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\r\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\r\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\r\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\r\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\r\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\r\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\r\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\r\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\r\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\r\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\r\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\r\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\r\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\r\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\r\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\r\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.1.0)\r\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\r\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.2)\r\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.5.0)\r\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\r\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\r\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\r\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\r\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\r\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.1)\r\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\r\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\r\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\r\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\r\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\r\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\r\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\r\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\r\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\r\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\r\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\r\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\r\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2024.10.1)\r\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\r\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.22.3)\r\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\r\n","Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\r\n","Building wheels for collected packages: optim\r\n","  Building wheel for optim (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n","  Created wheel for optim: filename=optim-0.1.0-py2.py3-none-any.whl size=2707 sha256=388979e3976dd640173dc1888a63394953d037d0fab3a0e45f021a4614aef9ac\r\n","  Stored in directory: /root/.cache/pip/wheels/63/cd/16/e7762fdd7862a4f618fa7ca62119fac2112de90041cee77227\r\n","Successfully built optim\r\n","Installing collected packages: optim, bs4\r\n","Successfully installed bs4-0.0.2 optim-0.1.0\r\n"]}],"execution_count":1},{"id":"5f5a20c9","cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-03-05T11:51:03.567963Z","iopub.status.busy":"2025-03-05T11:51:03.567706Z","iopub.status.idle":"2025-03-05T11:51:04.362134Z","shell.execute_reply":"2025-03-05T11:51:04.361153Z"},"papermill":{"duration":0.803194,"end_time":"2025-03-05T11:51:04.36345","exception":false,"start_time":"2025-03-05T11:51:03.560256","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/tachygraphy-dataset/tweet_emotion_dataset.csv\n","/kaggle/input/tachygraphy-dataset/output-2.xlsx\n","/kaggle/input/tachygraphy-dataset/Tachygraphy_MicroText-AIO-V3.xlsx\n","/kaggle/input/tachygraphy-dataset/Tachygraphy_MicroText-AIO-Emotion_Mood_Tags-V3.xlsx\n","/kaggle/input/tachygraphy-dataset/Tachygraphy_dataset_main.csv\n","/kaggle/input/tachygraphy-dataset/Tachygraphy_MicroText-AIO-Sentiment_Polarities_3_Label-V3.xlsx\n","/kaggle/input/tachygraphy-dataset/Tachygraphy_MicroText-AIO-Sentiment_Polarities_2_Label-V3 (Neutral Omitted).xlsx\n"]}],"execution_count":2},{"id":"cd6695e1","cell_type":"code","source":"dataset = pd.read_excel('/kaggle/input/dataset-tachygraphy/Tachygraphy_MicroText-AIO-V3.xlsx')","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:04.37826Z","iopub.status.busy":"2025-03-05T11:51:04.377931Z","iopub.status.idle":"2025-03-05T11:51:05.402252Z","shell.execute_reply":"2025-03-05T11:51:05.401594Z"},"papermill":{"duration":1.033001,"end_time":"2025-03-05T11:51:05.403684","exception":false,"start_time":"2025-03-05T11:51:04.370683","status":"completed"},"tags":[]},"outputs":[],"execution_count":3},{"id":"22974347","cell_type":"code","source":"df = dataset","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:05.418144Z","iopub.status.busy":"2025-03-05T11:51:05.41784Z","iopub.status.idle":"2025-03-05T11:51:05.420775Z","shell.execute_reply":"2025-03-05T11:51:05.420174Z"},"papermill":{"duration":0.011162,"end_time":"2025-03-05T11:51:05.421909","exception":false,"start_time":"2025-03-05T11:51:05.410747","status":"completed"},"tags":[]},"outputs":[],"execution_count":4},{"id":"bbfb2a8e","cell_type":"code","source":"df.rename(columns={'Informal Text':'input', 'Expanded Meaning':'target'}, inplace = True)","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:05.436012Z","iopub.status.busy":"2025-03-05T11:51:05.43578Z","iopub.status.idle":"2025-03-05T11:51:05.441512Z","shell.execute_reply":"2025-03-05T11:51:05.440923Z"},"papermill":{"duration":0.014249,"end_time":"2025-03-05T11:51:05.442775","exception":false,"start_time":"2025-03-05T11:51:05.428526","status":"completed"},"tags":[]},"outputs":[],"execution_count":5},{"id":"425afae2","cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:05.456968Z","iopub.status.busy":"2025-03-05T11:51:05.45677Z","iopub.status.idle":"2025-03-05T11:51:05.475394Z","shell.execute_reply":"2025-03-05T11:51:05.474703Z"},"papermill":{"duration":0.027065,"end_time":"2025-03-05T11:51:05.476631","exception":false,"start_time":"2025-03-05T11:51:05.449566","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>omg, JEE prep is killing me rn</td>\n","      <td>Oh my god, Joint Entrance Examination preparat...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>u up 4 a break b4 UPSC revision?</td>\n","      <td>Are you up for a break before Union Public Ser...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ttyl, finishing da CAT mock</td>\n","      <td>Talk to you later, finishing the Common Admiss...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>nah, dat GATE paper was brutal af</td>\n","      <td>No, that Graduate Aptitude Test in Engineering...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sup? u done w/ ur IIT assignment?</td>\n","      <td>What's up? Are you done with your Indian Insti...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                               input  \\\n","0     omg, JEE prep is killing me rn   \n","1   u up 4 a break b4 UPSC revision?   \n","2        ttyl, finishing da CAT mock   \n","3  nah, dat GATE paper was brutal af   \n","4  sup? u done w/ ur IIT assignment?   \n","\n","                                              target  \n","0  Oh my god, Joint Entrance Examination preparat...  \n","1  Are you up for a break before Union Public Ser...  \n","2  Talk to you later, finishing the Common Admiss...  \n","3  No, that Graduate Aptitude Test in Engineering...  \n","4  What's up? Are you done with your Indian Insti...  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"execution_count":6},{"id":"7cd13c63","cell_type":"code","source":"df['input'] = df['input'].astype(str)\ndf['target'] = df['target'].astype(str)","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:05.491329Z","iopub.status.busy":"2025-03-05T11:51:05.491125Z","iopub.status.idle":"2025-03-05T11:51:05.49537Z","shell.execute_reply":"2025-03-05T11:51:05.49482Z"},"papermill":{"duration":0.0128,"end_time":"2025-03-05T11:51:05.49657","exception":false,"start_time":"2025-03-05T11:51:05.48377","status":"completed"},"tags":[]},"outputs":[],"execution_count":7},{"id":"b801b0e3","cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BertModel, BertTokenizer\n# from torch.cuda.amp import autocast, GradScaler\nfrom datasets import load_dataset\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport ray\nfrom ray import tune\nimport torch.nn as nn\n\nfrom torch.optim import AdamW\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import RobertaTokenizer, RobertaModel\nfrom sklearn.model_selection import train_test_split\nimport optuna\n# from optuna.integration import PyTorchLightningPruner\nfrom ray import tune\nimport ray\nfrom ray import tune\nfrom ray.tune import CLIReporter\nfrom ray.tune import CLIReporter\nfrom ray.tune.schedulers import ASHAScheduler\nfrom ray.tune.schedulers import ASHAScheduler\n# from ray.tune.integration.pytorch import TuneReportCallback\nfrom torch.amp import GradScaler, autocast\n# from ray.tune.integration.optuna import OptunaSearch\nfrom ray.tune.search.optuna import OptunaSearch\nfrom ray import tune\nfrom ray.tune.search.hyperopt import HyperOptSearch\nfrom torch import autocast\n# from ray import tune\n# from ray.tune.integration.tensorboard import TensorBoardReporter\nfrom ray.tune.logger import TBXLogger\n# from torch.utils.tensorboard import SummaryWriter\nfrom ray.train import report\n# from ray.tune.integration.jupyter import JupyterNotebookReporter\nfrom ray.tune import JupyterNotebookReporter\n# from torch.cuda.amp import GradScaler, autocast\nfrom torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\nfrom ray.tune.schedulers import HyperBandScheduler, AsyncHyperBandScheduler\n\n\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\n\n\nimport emoji\nfrom bs4 import BeautifulSoup\nimport os\nimport re\nimport string\nimport json\n\n\nimport argparse # CPMP\n\nimport scipy as sp\n\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:05.510852Z","iopub.status.busy":"2025-03-05T11:51:05.510408Z","iopub.status.idle":"2025-03-05T11:51:32.683657Z","shell.execute_reply":"2025-03-05T11:51:32.682922Z"},"papermill":{"duration":27.18197,"end_time":"2025-03-05T11:51:32.685181","exception":false,"start_time":"2025-03-05T11:51:05.503211","status":"completed"},"tags":[]},"outputs":[],"execution_count":8},{"id":"be778426","cell_type":"code","source":"contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \n                       \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n                       \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \n                       \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\",\n                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \n                       \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\n                       \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\n                       \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \n                       \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n                       \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \n                       \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n                       \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\",\n                       \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\",\n                       \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n                       \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \n                       \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\",\n                       \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \n                       \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \n                       \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n                       \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\",\n                       \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'u.s':'america', 'e.g':'for example'}\n\npunct = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n\npunct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\",\n                 \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', \n                 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '!':' '}\n\nmispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater',\n                'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ',\n                'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can',\n                'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', \n                'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', \n                'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', \n                'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization',\n                'demonetisation': 'demonetization'}\n\ndef clean_text(text):\n    '''Clean emoji, Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n#     text = emoji.demojize(text)\n#     text = re.sub(r'\\:(.*?)\\:','',text)\n#     text = str(text).lower()    #Making Text Lowercase\n#     text = re.sub('\\[.*?\\]', '', text)\n    #The next 2 lines remove html text\n    text = BeautifulSoup(text, 'lxml').get_text()\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('\\n', '', text)\n#     text = re.sub('\\w*\\d\\w*', '', text)\n    # replacing everything with space except (a-z, A-Z, 0-9, \"%\", \".\", \"&\", \",\", \"'\", \"?\", \"!\", \",\", \"'\", \";\", \"-\")\n    text = re.sub(r\"[^a-zA-Z0-9?.!,¿'%&,';-]+\", \" \", text)\n    return text\n\ndef clean_contractions(text, mapping):\n    '''Clean contraction using contraction mapping'''    \n    specials = [\"’\", \"‘\", \"´\", \"`\"]\n    for s in specials:\n        text = text.replace(s, \"'\")\n    for word in mapping.keys():\n        if \"\"+word+\"\" in text:\n            text = text.replace(\"\"+word+\"\", \"\"+mapping[word]+\"\")\n    #Remove Punctuations\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    # creating a space between a word and the punctuation following it\n    # eg: \"he is a boy.\" => \"he is a boy .\"\n    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n    text = re.sub(r'[\" \"]+', \" \", text)\n    return text\n\ndef clean_special_chars(text, punct, mapping):\n    '''Cleans special characters present(if any)'''   \n    for p in mapping:\n        text = text.replace(p, mapping[p])\n    \n    for p in punct:\n        text = text.replace(p, f' {p} ')\n    \n    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}  \n    for s in specials:\n        text = text.replace(s, specials[s])\n    \n    return text\n\ndef correct_spelling(x, dic):\n    '''Corrects common spelling errors'''   \n    for word in dic.keys():\n        x = x.replace(word, dic[word])\n    return x\n\ndef remove_space(text):\n    '''Removes awkward spaces'''   \n    #Removes awkward spaces \n    text = text.strip()\n    text = text.split()\n    return \" \".join(text)\n\ndef text_preprocessing_pipeline(text):\n    '''Cleaning and parsing the text.'''\n#     text = clean_contractions(text, contraction_mapping)\n    text = clean_text(text)\n#     text = clean_contractions(text, contraction_mapping)\n#     text = clean_special_chars(text, punct, punct_mapping)\n#     text = correct_spelling(text, mispell_dict)\n    text = remove_space(text)\n    return text","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:32.701424Z","iopub.status.busy":"2025-03-05T11:51:32.70081Z","iopub.status.idle":"2025-03-05T11:51:32.719314Z","shell.execute_reply":"2025-03-05T11:51:32.718521Z"},"papermill":{"duration":0.027751,"end_time":"2025-03-05T11:51:32.720535","exception":false,"start_time":"2025-03-05T11:51:32.692784","status":"completed"},"tags":[]},"outputs":[],"execution_count":9},{"id":"ac0739f5","cell_type":"code","source":"df['input'] = df['input'].apply(lambda x: text_preprocessing_pipeline(x))\ndf['target'] = df['target'].apply(lambda x: text_preprocessing_pipeline(x))","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:32.73526Z","iopub.status.busy":"2025-03-05T11:51:32.735043Z","iopub.status.idle":"2025-03-05T11:51:35.985694Z","shell.execute_reply":"2025-03-05T11:51:35.984993Z"},"papermill":{"duration":3.259317,"end_time":"2025-03-05T11:51:35.987226","exception":false,"start_time":"2025-03-05T11:51:32.727909","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-9-93bb6d8e489f>:51: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  text = BeautifulSoup(text, 'lxml').get_text()\n"]}],"execution_count":10},{"id":"d94225cf","cell_type":"code","source":"df['input'] = df['input'].astype(str)\ndf['target'] = df['target'].astype(str)","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:36.002188Z","iopub.status.busy":"2025-03-05T11:51:36.001925Z","iopub.status.idle":"2025-03-05T11:51:36.006882Z","shell.execute_reply":"2025-03-05T11:51:36.00606Z"},"papermill":{"duration":0.013466,"end_time":"2025-03-05T11:51:36.008054","exception":false,"start_time":"2025-03-05T11:51:35.994588","status":"completed"},"tags":[]},"outputs":[],"execution_count":11},{"id":"a9248397","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:36.022367Z","iopub.status.busy":"2025-03-05T11:51:36.022129Z","iopub.status.idle":"2025-03-05T11:51:36.105702Z","shell.execute_reply":"2025-03-05T11:51:36.104792Z"},"papermill":{"duration":0.092172,"end_time":"2025-03-05T11:51:36.107046","exception":false,"start_time":"2025-03-05T11:51:36.014874","status":"completed"},"tags":[]},"outputs":[],"execution_count":12},{"id":"475de530","cell_type":"code","source":"import torch\nimport transformers\nfrom datasets import Dataset\nfrom transformers import LlamaForCausalLM, LlamaTokenizer, TrainingArguments, Trainer, AutoTokenizer, BartForConditionalGeneration","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:36.121959Z","iopub.status.busy":"2025-03-05T11:51:36.121719Z","iopub.status.idle":"2025-03-05T11:51:37.686851Z","shell.execute_reply":"2025-03-05T11:51:37.686144Z"},"papermill":{"duration":1.574087,"end_time":"2025-03-05T11:51:37.688368","exception":false,"start_time":"2025-03-05T11:51:36.114281","status":"completed"},"tags":[]},"outputs":[],"execution_count":13},{"id":"5d1a299f","cell_type":"code","source":"MODEL_NAME = 'facebook/bart-base'","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:37.704028Z","iopub.status.busy":"2025-03-05T11:51:37.703792Z","iopub.status.idle":"2025-03-05T11:51:37.706708Z","shell.execute_reply":"2025-03-05T11:51:37.706098Z"},"papermill":{"duration":0.011853,"end_time":"2025-03-05T11:51:37.707887","exception":false,"start_time":"2025-03-05T11:51:37.696034","status":"completed"},"tags":[]},"outputs":[],"execution_count":14},{"id":"956787c0","cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:37.722298Z","iopub.status.busy":"2025-03-05T11:51:37.722095Z","iopub.status.idle":"2025-03-05T11:51:39.271851Z","shell.execute_reply":"2025-03-05T11:51:39.271067Z"},"papermill":{"duration":1.558434,"end_time":"2025-03-05T11:51:39.273392","exception":false,"start_time":"2025-03-05T11:51:37.714958","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00038f3926de4721994cf9b7e9aa9657","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0794ea0d3f954088a764a5ea961043c9","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25d77e5225f24943926422f5f47ffdd3","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61725a5627f94104a7e10fcde739ed9b","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"execution_count":15},{"id":"903c9406","cell_type":"code","source":"def test_train_split(dataset, test_ratio=0.1):\n  test_indices = np.random.rand(len(dataset)) < test_ratio\n  return dataset[~test_indices], dataset[test_indices]","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:39.289938Z","iopub.status.busy":"2025-03-05T11:51:39.289684Z","iopub.status.idle":"2025-03-05T11:51:39.293384Z","shell.execute_reply":"2025-03-05T11:51:39.292676Z"},"papermill":{"duration":0.013339,"end_time":"2025-03-05T11:51:39.294725","exception":false,"start_time":"2025-03-05T11:51:39.281386","status":"completed"},"tags":[]},"outputs":[],"execution_count":16},{"id":"b0768cb9","cell_type":"code","source":"train_ds_pd, validation_ds_pd = test_train_split(df)\nprint(\"{} examples in training, {} examples in testing.\".format(\n    len(train_ds_pd), len(validation_ds_pd)))","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:39.310211Z","iopub.status.busy":"2025-03-05T11:51:39.309993Z","iopub.status.idle":"2025-03-05T11:51:39.318803Z","shell.execute_reply":"2025-03-05T11:51:39.317943Z"},"papermill":{"duration":0.017922,"end_time":"2025-03-05T11:51:39.319972","exception":false,"start_time":"2025-03-05T11:51:39.30205","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["9233 examples in training, 1047 examples in testing.\n"]}],"execution_count":17},{"id":"f88b6fff","cell_type":"code","source":"train_ds_pd = df","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:39.335046Z","iopub.status.busy":"2025-03-05T11:51:39.334833Z","iopub.status.idle":"2025-03-05T11:51:39.337846Z","shell.execute_reply":"2025-03-05T11:51:39.337218Z"},"papermill":{"duration":0.011747,"end_time":"2025-03-05T11:51:39.338968","exception":false,"start_time":"2025-03-05T11:51:39.327221","status":"completed"},"tags":[]},"outputs":[],"execution_count":18},{"id":"473e2144","cell_type":"code","source":"def tokenize_function(batch):\n    model_inputs = tokenizer(batch[\"input\"], padding=\"longest\", truncation=False)\n    labels = tokenizer(batch[\"target\"], padding=\"longest\", truncation=False)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:39.354169Z","iopub.status.busy":"2025-03-05T11:51:39.353935Z","iopub.status.idle":"2025-03-05T11:51:39.357184Z","shell.execute_reply":"2025-03-05T11:51:39.356598Z"},"papermill":{"duration":0.012075,"end_time":"2025-03-05T11:51:39.358334","exception":false,"start_time":"2025-03-05T11:51:39.346259","status":"completed"},"tags":[]},"outputs":[],"execution_count":19},{"id":"33f2a821","cell_type":"code","source":"dataset1 = Dataset.from_pandas(train_ds_pd)\ndataset2 = Dataset.from_pandas(validation_ds_pd)","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:39.373421Z","iopub.status.busy":"2025-03-05T11:51:39.373208Z","iopub.status.idle":"2025-03-05T11:51:39.399149Z","shell.execute_reply":"2025-03-05T11:51:39.398544Z"},"papermill":{"duration":0.034742,"end_time":"2025-03-05T11:51:39.400364","exception":false,"start_time":"2025-03-05T11:51:39.365622","status":"completed"},"tags":[]},"outputs":[],"execution_count":20},{"id":"d417437f","cell_type":"code","source":"tokenized_dataset = dataset1.map(tokenize_function)\ntokenized_dataset2 = dataset2.map(tokenize_function)","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:39.415644Z","iopub.status.busy":"2025-03-05T11:51:39.415378Z","iopub.status.idle":"2025-03-05T11:51:43.748639Z","shell.execute_reply":"2025-03-05T11:51:43.747803Z"},"papermill":{"duration":4.342201,"end_time":"2025-03-05T11:51:43.749998","exception":false,"start_time":"2025-03-05T11:51:39.407797","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d65ac38dd5cd423cab0becd6ed84947f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/10280 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"957df319edff4e29a12775309db547e2","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1047 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"execution_count":21},{"id":"5c471a77","cell_type":"code","source":"model = BartForConditionalGeneration.from_pretrained(\n    MODEL_NAME,  # BF16 for H100\n    device_map=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Auto GPU allocation\n)","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:43.76615Z","iopub.status.busy":"2025-03-05T11:51:43.765919Z","iopub.status.idle":"2025-03-05T11:51:47.983459Z","shell.execute_reply":"2025-03-05T11:51:47.982789Z"},"papermill":{"duration":4.226974,"end_time":"2025-03-05T11:51:47.98498","exception":false,"start_time":"2025-03-05T11:51:43.758006","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff5fb79dcb54424ab8dfc5eff9a89a72","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"execution_count":22},{"id":"0edbf0c2","cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=\"longest\")\n","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:48.001419Z","iopub.status.busy":"2025-03-05T11:51:48.001163Z","iopub.status.idle":"2025-03-05T11:51:48.004604Z","shell.execute_reply":"2025-03-05T11:51:48.00381Z"},"papermill":{"duration":0.012814,"end_time":"2025-03-05T11:51:48.005791","exception":false,"start_time":"2025-03-05T11:51:47.992977","status":"completed"},"tags":[]},"outputs":[],"execution_count":23},{"id":"22092421","cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"./bart-checkpoints\",\n    evaluation_strategy=\"steps\",  # Evaluate at regular intervals\n    save_strategy=\"steps\",  # Save model checkpoints at regular steps\n    logging_strategy=\"steps\",  # Log at regular steps\n    logging_dir=\"/kaggle/working/logs\",  # Directory for TensorBoard logs\n    logging_steps=50,  # Log loss/metrics every 50 steps\n    log_level=\"debug\",\n    save_total_limit=2,  # Keep only the 2 latest checkpoints\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    gradient_accumulation_steps=2,\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    num_train_epochs=15,\n    lr_scheduler_type=\"linear\",\n    warmup_steps=50,\n    fp16=True,  # Mixed precision for efficiency\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    report_to=[\"tensorboard\"],\n)\n","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:48.021531Z","iopub.status.busy":"2025-03-05T11:51:48.021273Z","iopub.status.idle":"2025-03-05T11:51:48.055646Z","shell.execute_reply":"2025-03-05T11:51:48.054725Z"},"papermill":{"duration":0.043599,"end_time":"2025-03-05T11:51:48.056939","exception":false,"start_time":"2025-03-05T11:51:48.01334","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"execution_count":24},{"id":"bf3709bc","cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    eval_dataset=tokenized_dataset2,\n    tokenizer=tokenizer,\n    data_collator=data_collator  # Ensures dynamic padding\n)\n\n\ntrainer.train()","metadata":{"execution":{"iopub.execute_input":"2025-03-05T11:51:48.07334Z","iopub.status.busy":"2025-03-05T11:51:48.073101Z","iopub.status.idle":"2025-03-05T12:25:52.733636Z","shell.execute_reply":"2025-03-05T12:25:52.732683Z"},"papermill":{"duration":2044.670185,"end_time":"2025-03-05T12:25:52.73514","exception":false,"start_time":"2025-03-05T11:51:48.064955","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-25-abe393457df6>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n","Using auto half precision backend\n","Currently training with a batch size of: 8\n","The following columns in the training set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target. If input, target are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running training *****\n","  Num examples = 10,280\n","  Num Epochs = 15\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 2\n","  Total optimization steps = 9,630\n","  Number of trainable parameters = 139,420,416\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='9630' max='9630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9630/9630 34:03, Epoch 14/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>1.805400</td>\n","      <td>0.976648</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.978800</td>\n","      <td>0.752814</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.858500</td>\n","      <td>0.660764</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.768000</td>\n","      <td>0.564100</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.715100</td>\n","      <td>0.532724</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.696300</td>\n","      <td>0.490166</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.601500</td>\n","      <td>0.432624</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.652700</td>\n","      <td>0.401194</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.641300</td>\n","      <td>0.395186</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.551800</td>\n","      <td>0.371030</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.614300</td>\n","      <td>0.338883</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.530000</td>\n","      <td>0.331101</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.508400</td>\n","      <td>0.321658</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.418400</td>\n","      <td>0.305855</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.407500</td>\n","      <td>0.295583</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.433100</td>\n","      <td>0.278719</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.415000</td>\n","      <td>0.271142</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.394800</td>\n","      <td>0.255937</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.383400</td>\n","      <td>0.254654</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.380200</td>\n","      <td>0.244631</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.406300</td>\n","      <td>0.229893</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.403700</td>\n","      <td>0.220586</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.389500</td>\n","      <td>0.214885</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.376800</td>\n","      <td>0.210632</td>\n","    </tr>\n","    <tr>\n","      <td>1250</td>\n","      <td>0.412500</td>\n","      <td>0.199815</td>\n","    </tr>\n","    <tr>\n","      <td>1300</td>\n","      <td>0.336300</td>\n","      <td>0.198904</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.278600</td>\n","      <td>0.203714</td>\n","    </tr>\n","    <tr>\n","      <td>1400</td>\n","      <td>0.264500</td>\n","      <td>0.183365</td>\n","    </tr>\n","    <tr>\n","      <td>1450</td>\n","      <td>0.250600</td>\n","      <td>0.188913</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.306800</td>\n","      <td>0.178814</td>\n","    </tr>\n","    <tr>\n","      <td>1550</td>\n","      <td>0.277500</td>\n","      <td>0.176656</td>\n","    </tr>\n","    <tr>\n","      <td>1600</td>\n","      <td>0.298900</td>\n","      <td>0.164292</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.291300</td>\n","      <td>0.161276</td>\n","    </tr>\n","    <tr>\n","      <td>1700</td>\n","      <td>0.269700</td>\n","      <td>0.148547</td>\n","    </tr>\n","    <tr>\n","      <td>1750</td>\n","      <td>0.275800</td>\n","      <td>0.143129</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.264000</td>\n","      <td>0.139644</td>\n","    </tr>\n","    <tr>\n","      <td>1850</td>\n","      <td>0.255400</td>\n","      <td>0.139631</td>\n","    </tr>\n","    <tr>\n","      <td>1900</td>\n","      <td>0.291700</td>\n","      <td>0.134194</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.249800</td>\n","      <td>0.134836</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.197400</td>\n","      <td>0.128607</td>\n","    </tr>\n","    <tr>\n","      <td>2050</td>\n","      <td>0.220200</td>\n","      <td>0.124219</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.210000</td>\n","      <td>0.126541</td>\n","    </tr>\n","    <tr>\n","      <td>2150</td>\n","      <td>0.209100</td>\n","      <td>0.123047</td>\n","    </tr>\n","    <tr>\n","      <td>2200</td>\n","      <td>0.197200</td>\n","      <td>0.117926</td>\n","    </tr>\n","    <tr>\n","      <td>2250</td>\n","      <td>0.201000</td>\n","      <td>0.113990</td>\n","    </tr>\n","    <tr>\n","      <td>2300</td>\n","      <td>0.220400</td>\n","      <td>0.109584</td>\n","    </tr>\n","    <tr>\n","      <td>2350</td>\n","      <td>0.195100</td>\n","      <td>0.111227</td>\n","    </tr>\n","    <tr>\n","      <td>2400</td>\n","      <td>0.217300</td>\n","      <td>0.110492</td>\n","    </tr>\n","    <tr>\n","      <td>2450</td>\n","      <td>0.223200</td>\n","      <td>0.098123</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.221400</td>\n","      <td>0.093651</td>\n","    </tr>\n","    <tr>\n","      <td>2550</td>\n","      <td>0.202000</td>\n","      <td>0.089542</td>\n","    </tr>\n","    <tr>\n","      <td>2600</td>\n","      <td>0.160400</td>\n","      <td>0.085942</td>\n","    </tr>\n","    <tr>\n","      <td>2650</td>\n","      <td>0.144500</td>\n","      <td>0.086800</td>\n","    </tr>\n","    <tr>\n","      <td>2700</td>\n","      <td>0.151900</td>\n","      <td>0.083380</td>\n","    </tr>\n","    <tr>\n","      <td>2750</td>\n","      <td>0.146800</td>\n","      <td>0.082434</td>\n","    </tr>\n","    <tr>\n","      <td>2800</td>\n","      <td>0.156800</td>\n","      <td>0.080570</td>\n","    </tr>\n","    <tr>\n","      <td>2850</td>\n","      <td>0.155100</td>\n","      <td>0.084106</td>\n","    </tr>\n","    <tr>\n","      <td>2900</td>\n","      <td>0.164000</td>\n","      <td>0.076008</td>\n","    </tr>\n","    <tr>\n","      <td>2950</td>\n","      <td>0.160400</td>\n","      <td>0.074448</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.155500</td>\n","      <td>0.079530</td>\n","    </tr>\n","    <tr>\n","      <td>3050</td>\n","      <td>0.157200</td>\n","      <td>0.070880</td>\n","    </tr>\n","    <tr>\n","      <td>3100</td>\n","      <td>0.170900</td>\n","      <td>0.071075</td>\n","    </tr>\n","    <tr>\n","      <td>3150</td>\n","      <td>0.166000</td>\n","      <td>0.068063</td>\n","    </tr>\n","    <tr>\n","      <td>3200</td>\n","      <td>0.155200</td>\n","      <td>0.065234</td>\n","    </tr>\n","    <tr>\n","      <td>3250</td>\n","      <td>0.124400</td>\n","      <td>0.064100</td>\n","    </tr>\n","    <tr>\n","      <td>3300</td>\n","      <td>0.116600</td>\n","      <td>0.057205</td>\n","    </tr>\n","    <tr>\n","      <td>3350</td>\n","      <td>0.125700</td>\n","      <td>0.057457</td>\n","    </tr>\n","    <tr>\n","      <td>3400</td>\n","      <td>0.120500</td>\n","      <td>0.057064</td>\n","    </tr>\n","    <tr>\n","      <td>3450</td>\n","      <td>0.115700</td>\n","      <td>0.056633</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.120500</td>\n","      <td>0.053714</td>\n","    </tr>\n","    <tr>\n","      <td>3550</td>\n","      <td>0.120000</td>\n","      <td>0.053248</td>\n","    </tr>\n","    <tr>\n","      <td>3600</td>\n","      <td>0.129400</td>\n","      <td>0.053810</td>\n","    </tr>\n","    <tr>\n","      <td>3650</td>\n","      <td>0.120500</td>\n","      <td>0.049691</td>\n","    </tr>\n","    <tr>\n","      <td>3700</td>\n","      <td>0.111600</td>\n","      <td>0.051815</td>\n","    </tr>\n","    <tr>\n","      <td>3750</td>\n","      <td>0.127200</td>\n","      <td>0.052275</td>\n","    </tr>\n","    <tr>\n","      <td>3800</td>\n","      <td>0.109600</td>\n","      <td>0.050749</td>\n","    </tr>\n","    <tr>\n","      <td>3850</td>\n","      <td>0.108000</td>\n","      <td>0.047775</td>\n","    </tr>\n","    <tr>\n","      <td>3900</td>\n","      <td>0.093100</td>\n","      <td>0.046531</td>\n","    </tr>\n","    <tr>\n","      <td>3950</td>\n","      <td>0.092100</td>\n","      <td>0.042238</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.095900</td>\n","      <td>0.045287</td>\n","    </tr>\n","    <tr>\n","      <td>4050</td>\n","      <td>0.086100</td>\n","      <td>0.044475</td>\n","    </tr>\n","    <tr>\n","      <td>4100</td>\n","      <td>0.087400</td>\n","      <td>0.041574</td>\n","    </tr>\n","    <tr>\n","      <td>4150</td>\n","      <td>0.083600</td>\n","      <td>0.040476</td>\n","    </tr>\n","    <tr>\n","      <td>4200</td>\n","      <td>0.101700</td>\n","      <td>0.040829</td>\n","    </tr>\n","    <tr>\n","      <td>4250</td>\n","      <td>0.087100</td>\n","      <td>0.039537</td>\n","    </tr>\n","    <tr>\n","      <td>4300</td>\n","      <td>0.094500</td>\n","      <td>0.038770</td>\n","    </tr>\n","    <tr>\n","      <td>4350</td>\n","      <td>0.092400</td>\n","      <td>0.035917</td>\n","    </tr>\n","    <tr>\n","      <td>4400</td>\n","      <td>0.093600</td>\n","      <td>0.035473</td>\n","    </tr>\n","    <tr>\n","      <td>4450</td>\n","      <td>0.097900</td>\n","      <td>0.035746</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.103500</td>\n","      <td>0.031156</td>\n","    </tr>\n","    <tr>\n","      <td>4550</td>\n","      <td>0.064900</td>\n","      <td>0.030944</td>\n","    </tr>\n","    <tr>\n","      <td>4600</td>\n","      <td>0.074500</td>\n","      <td>0.031459</td>\n","    </tr>\n","    <tr>\n","      <td>4650</td>\n","      <td>0.067000</td>\n","      <td>0.032013</td>\n","    </tr>\n","    <tr>\n","      <td>4700</td>\n","      <td>0.075500</td>\n","      <td>0.031500</td>\n","    </tr>\n","    <tr>\n","      <td>4750</td>\n","      <td>0.067100</td>\n","      <td>0.031910</td>\n","    </tr>\n","    <tr>\n","      <td>4800</td>\n","      <td>0.073200</td>\n","      <td>0.031822</td>\n","    </tr>\n","    <tr>\n","      <td>4850</td>\n","      <td>0.079600</td>\n","      <td>0.032796</td>\n","    </tr>\n","    <tr>\n","      <td>4900</td>\n","      <td>0.081600</td>\n","      <td>0.027146</td>\n","    </tr>\n","    <tr>\n","      <td>4950</td>\n","      <td>0.068900</td>\n","      <td>0.025133</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.079900</td>\n","      <td>0.028067</td>\n","    </tr>\n","    <tr>\n","      <td>5050</td>\n","      <td>0.075200</td>\n","      <td>0.026031</td>\n","    </tr>\n","    <tr>\n","      <td>5100</td>\n","      <td>0.077100</td>\n","      <td>0.021395</td>\n","    </tr>\n","    <tr>\n","      <td>5150</td>\n","      <td>0.074900</td>\n","      <td>0.021723</td>\n","    </tr>\n","    <tr>\n","      <td>5200</td>\n","      <td>0.055800</td>\n","      <td>0.023748</td>\n","    </tr>\n","    <tr>\n","      <td>5250</td>\n","      <td>0.061400</td>\n","      <td>0.023115</td>\n","    </tr>\n","    <tr>\n","      <td>5300</td>\n","      <td>0.050600</td>\n","      <td>0.020433</td>\n","    </tr>\n","    <tr>\n","      <td>5350</td>\n","      <td>0.057900</td>\n","      <td>0.021523</td>\n","    </tr>\n","    <tr>\n","      <td>5400</td>\n","      <td>0.061200</td>\n","      <td>0.022390</td>\n","    </tr>\n","    <tr>\n","      <td>5450</td>\n","      <td>0.059400</td>\n","      <td>0.019192</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.053900</td>\n","      <td>0.018295</td>\n","    </tr>\n","    <tr>\n","      <td>5550</td>\n","      <td>0.056200</td>\n","      <td>0.020029</td>\n","    </tr>\n","    <tr>\n","      <td>5600</td>\n","      <td>0.064800</td>\n","      <td>0.017640</td>\n","    </tr>\n","    <tr>\n","      <td>5650</td>\n","      <td>0.056500</td>\n","      <td>0.016970</td>\n","    </tr>\n","    <tr>\n","      <td>5700</td>\n","      <td>0.061500</td>\n","      <td>0.016348</td>\n","    </tr>\n","    <tr>\n","      <td>5750</td>\n","      <td>0.058400</td>\n","      <td>0.015681</td>\n","    </tr>\n","    <tr>\n","      <td>5800</td>\n","      <td>0.058600</td>\n","      <td>0.015257</td>\n","    </tr>\n","    <tr>\n","      <td>5850</td>\n","      <td>0.046200</td>\n","      <td>0.014135</td>\n","    </tr>\n","    <tr>\n","      <td>5900</td>\n","      <td>0.041600</td>\n","      <td>0.015473</td>\n","    </tr>\n","    <tr>\n","      <td>5950</td>\n","      <td>0.046500</td>\n","      <td>0.015422</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.052900</td>\n","      <td>0.015949</td>\n","    </tr>\n","    <tr>\n","      <td>6050</td>\n","      <td>0.051800</td>\n","      <td>0.016306</td>\n","    </tr>\n","    <tr>\n","      <td>6100</td>\n","      <td>0.042900</td>\n","      <td>0.015502</td>\n","    </tr>\n","    <tr>\n","      <td>6150</td>\n","      <td>0.049600</td>\n","      <td>0.014005</td>\n","    </tr>\n","    <tr>\n","      <td>6200</td>\n","      <td>0.059500</td>\n","      <td>0.013462</td>\n","    </tr>\n","    <tr>\n","      <td>6250</td>\n","      <td>0.057400</td>\n","      <td>0.012090</td>\n","    </tr>\n","    <tr>\n","      <td>6300</td>\n","      <td>0.049800</td>\n","      <td>0.012940</td>\n","    </tr>\n","    <tr>\n","      <td>6350</td>\n","      <td>0.045900</td>\n","      <td>0.011973</td>\n","    </tr>\n","    <tr>\n","      <td>6400</td>\n","      <td>0.046500</td>\n","      <td>0.010548</td>\n","    </tr>\n","    <tr>\n","      <td>6450</td>\n","      <td>0.039100</td>\n","      <td>0.011331</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.040500</td>\n","      <td>0.012695</td>\n","    </tr>\n","    <tr>\n","      <td>6550</td>\n","      <td>0.035200</td>\n","      <td>0.012102</td>\n","    </tr>\n","    <tr>\n","      <td>6600</td>\n","      <td>0.037700</td>\n","      <td>0.010959</td>\n","    </tr>\n","    <tr>\n","      <td>6650</td>\n","      <td>0.033800</td>\n","      <td>0.013106</td>\n","    </tr>\n","    <tr>\n","      <td>6700</td>\n","      <td>0.042700</td>\n","      <td>0.011085</td>\n","    </tr>\n","    <tr>\n","      <td>6750</td>\n","      <td>0.038000</td>\n","      <td>0.010364</td>\n","    </tr>\n","    <tr>\n","      <td>6800</td>\n","      <td>0.039100</td>\n","      <td>0.010612</td>\n","    </tr>\n","    <tr>\n","      <td>6850</td>\n","      <td>0.039400</td>\n","      <td>0.010227</td>\n","    </tr>\n","    <tr>\n","      <td>6900</td>\n","      <td>0.041700</td>\n","      <td>0.009384</td>\n","    </tr>\n","    <tr>\n","      <td>6950</td>\n","      <td>0.037600</td>\n","      <td>0.010847</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.039700</td>\n","      <td>0.008962</td>\n","    </tr>\n","    <tr>\n","      <td>7050</td>\n","      <td>0.037600</td>\n","      <td>0.010157</td>\n","    </tr>\n","    <tr>\n","      <td>7100</td>\n","      <td>0.030400</td>\n","      <td>0.008994</td>\n","    </tr>\n","    <tr>\n","      <td>7150</td>\n","      <td>0.030700</td>\n","      <td>0.010032</td>\n","    </tr>\n","    <tr>\n","      <td>7200</td>\n","      <td>0.031200</td>\n","      <td>0.009280</td>\n","    </tr>\n","    <tr>\n","      <td>7250</td>\n","      <td>0.032300</td>\n","      <td>0.010416</td>\n","    </tr>\n","    <tr>\n","      <td>7300</td>\n","      <td>0.031600</td>\n","      <td>0.010299</td>\n","    </tr>\n","    <tr>\n","      <td>7350</td>\n","      <td>0.036100</td>\n","      <td>0.008828</td>\n","    </tr>\n","    <tr>\n","      <td>7400</td>\n","      <td>0.033400</td>\n","      <td>0.009374</td>\n","    </tr>\n","    <tr>\n","      <td>7450</td>\n","      <td>0.033800</td>\n","      <td>0.008755</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.035100</td>\n","      <td>0.008945</td>\n","    </tr>\n","    <tr>\n","      <td>7550</td>\n","      <td>0.032700</td>\n","      <td>0.009244</td>\n","    </tr>\n","    <tr>\n","      <td>7600</td>\n","      <td>0.032600</td>\n","      <td>0.008008</td>\n","    </tr>\n","    <tr>\n","      <td>7650</td>\n","      <td>0.032300</td>\n","      <td>0.008584</td>\n","    </tr>\n","    <tr>\n","      <td>7700</td>\n","      <td>0.031300</td>\n","      <td>0.007103</td>\n","    </tr>\n","    <tr>\n","      <td>7750</td>\n","      <td>0.025900</td>\n","      <td>0.007440</td>\n","    </tr>\n","    <tr>\n","      <td>7800</td>\n","      <td>0.026700</td>\n","      <td>0.008510</td>\n","    </tr>\n","    <tr>\n","      <td>7850</td>\n","      <td>0.026300</td>\n","      <td>0.007937</td>\n","    </tr>\n","    <tr>\n","      <td>7900</td>\n","      <td>0.029000</td>\n","      <td>0.006829</td>\n","    </tr>\n","    <tr>\n","      <td>7950</td>\n","      <td>0.025500</td>\n","      <td>0.006938</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.027200</td>\n","      <td>0.007104</td>\n","    </tr>\n","    <tr>\n","      <td>8050</td>\n","      <td>0.025400</td>\n","      <td>0.006004</td>\n","    </tr>\n","    <tr>\n","      <td>8100</td>\n","      <td>0.029500</td>\n","      <td>0.005909</td>\n","    </tr>\n","    <tr>\n","      <td>8150</td>\n","      <td>0.023800</td>\n","      <td>0.006212</td>\n","    </tr>\n","    <tr>\n","      <td>8200</td>\n","      <td>0.026900</td>\n","      <td>0.006761</td>\n","    </tr>\n","    <tr>\n","      <td>8250</td>\n","      <td>0.030800</td>\n","      <td>0.005990</td>\n","    </tr>\n","    <tr>\n","      <td>8300</td>\n","      <td>0.026300</td>\n","      <td>0.006498</td>\n","    </tr>\n","    <tr>\n","      <td>8350</td>\n","      <td>0.026700</td>\n","      <td>0.006580</td>\n","    </tr>\n","    <tr>\n","      <td>8400</td>\n","      <td>0.023400</td>\n","      <td>0.006429</td>\n","    </tr>\n","    <tr>\n","      <td>8450</td>\n","      <td>0.024300</td>\n","      <td>0.006601</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.024900</td>\n","      <td>0.006075</td>\n","    </tr>\n","    <tr>\n","      <td>8550</td>\n","      <td>0.023100</td>\n","      <td>0.005759</td>\n","    </tr>\n","    <tr>\n","      <td>8600</td>\n","      <td>0.019800</td>\n","      <td>0.005783</td>\n","    </tr>\n","    <tr>\n","      <td>8650</td>\n","      <td>0.022300</td>\n","      <td>0.006265</td>\n","    </tr>\n","    <tr>\n","      <td>8700</td>\n","      <td>0.025000</td>\n","      <td>0.005954</td>\n","    </tr>\n","    <tr>\n","      <td>8750</td>\n","      <td>0.019400</td>\n","      <td>0.005828</td>\n","    </tr>\n","    <tr>\n","      <td>8800</td>\n","      <td>0.022500</td>\n","      <td>0.005554</td>\n","    </tr>\n","    <tr>\n","      <td>8850</td>\n","      <td>0.020200</td>\n","      <td>0.005342</td>\n","    </tr>\n","    <tr>\n","      <td>8900</td>\n","      <td>0.023000</td>\n","      <td>0.005701</td>\n","    </tr>\n","    <tr>\n","      <td>8950</td>\n","      <td>0.024200</td>\n","      <td>0.004850</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.023900</td>\n","      <td>0.004826</td>\n","    </tr>\n","    <tr>\n","      <td>9050</td>\n","      <td>0.019300</td>\n","      <td>0.005152</td>\n","    </tr>\n","    <tr>\n","      <td>9100</td>\n","      <td>0.018100</td>\n","      <td>0.004925</td>\n","    </tr>\n","    <tr>\n","      <td>9150</td>\n","      <td>0.016500</td>\n","      <td>0.004908</td>\n","    </tr>\n","    <tr>\n","      <td>9200</td>\n","      <td>0.020900</td>\n","      <td>0.004922</td>\n","    </tr>\n","    <tr>\n","      <td>9250</td>\n","      <td>0.018000</td>\n","      <td>0.005018</td>\n","    </tr>\n","    <tr>\n","      <td>9300</td>\n","      <td>0.017400</td>\n","      <td>0.004685</td>\n","    </tr>\n","    <tr>\n","      <td>9350</td>\n","      <td>0.018300</td>\n","      <td>0.004649</td>\n","    </tr>\n","    <tr>\n","      <td>9400</td>\n","      <td>0.019700</td>\n","      <td>0.004604</td>\n","    </tr>\n","    <tr>\n","      <td>9450</td>\n","      <td>0.019400</td>\n","      <td>0.004583</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.018500</td>\n","      <td>0.004580</td>\n","    </tr>\n","    <tr>\n","      <td>9550</td>\n","      <td>0.015400</td>\n","      <td>0.004552</td>\n","    </tr>\n","    <tr>\n","      <td>9600</td>\n","      <td>0.016700</td>\n","      <td>0.004550</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","Configuration saved in ./bart-checkpoints/checkpoint-500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-500/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-1000\n","Configuration saved in ./bart-checkpoints/checkpoint-1000/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-1000/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-1000/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-1000/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-1500\n","Configuration saved in ./bart-checkpoints/checkpoint-1500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-1500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-1500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-500] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-2000\n","Configuration saved in ./bart-checkpoints/checkpoint-2000/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-2000/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-2000/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-1000] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-2500\n","Configuration saved in ./bart-checkpoints/checkpoint-2500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-2500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-2500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-1500] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-3000\n","Configuration saved in ./bart-checkpoints/checkpoint-3000/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-3000/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-3000/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-2000] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-3500\n","Configuration saved in ./bart-checkpoints/checkpoint-3500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-3500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-3500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-2500] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-4000\n","Configuration saved in ./bart-checkpoints/checkpoint-4000/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-4000/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-4000/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-4000/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-4000/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-3000] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-4500\n","Configuration saved in ./bart-checkpoints/checkpoint-4500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-4500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-4500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-4500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-4500/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-3500] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-5000\n","Configuration saved in ./bart-checkpoints/checkpoint-5000/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-5000/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-5000/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-5000/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-5000/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-4000] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-5500\n","Configuration saved in ./bart-checkpoints/checkpoint-5500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-5500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-5500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-5500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-5500/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-4500] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-6000\n","Configuration saved in ./bart-checkpoints/checkpoint-6000/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-6000/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-6000/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-6000/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-6000/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-5000] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-6500\n","Configuration saved in ./bart-checkpoints/checkpoint-6500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-6500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-6500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-6500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-6500/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-5500] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-7000\n","Configuration saved in ./bart-checkpoints/checkpoint-7000/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-7000/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-7000/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-7000/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-7000/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-6000] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-7500\n","Configuration saved in ./bart-checkpoints/checkpoint-7500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-7500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-7500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-7500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-7500/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-6500] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-8000\n","Configuration saved in ./bart-checkpoints/checkpoint-8000/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-8000/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-8000/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-8000/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-8000/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-7000] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-8500\n","Configuration saved in ./bart-checkpoints/checkpoint-8500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-8500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-8500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-8500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-8500/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-7500] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-9000\n","Configuration saved in ./bart-checkpoints/checkpoint-9000/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-9000/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-9000/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-9000/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-9000/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-8000] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-9500\n","Configuration saved in ./bart-checkpoints/checkpoint-9500/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-9500/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-9500/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-9500/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-9500/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-8500] due to args.save_total_limit\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","The following columns in the evaluation set don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: input, target, __index_level_0__. If input, target, __index_level_0__ are not expected by `BartForConditionalGeneration.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 1047\n","  Batch size = 8\n","Saving model checkpoint to ./bart-checkpoints/checkpoint-9630\n","Configuration saved in ./bart-checkpoints/checkpoint-9630/config.json\n","Configuration saved in ./bart-checkpoints/checkpoint-9630/generation_config.json\n","Model weights saved in ./bart-checkpoints/checkpoint-9630/model.safetensors\n","tokenizer config file saved in ./bart-checkpoints/checkpoint-9630/tokenizer_config.json\n","Special tokens file saved in ./bart-checkpoints/checkpoint-9630/special_tokens_map.json\n","Deleting older checkpoint [bart-checkpoints/checkpoint-9000] due to args.save_total_limit\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./bart-checkpoints/checkpoint-9600 (score: 0.004549740813672543).\n","Could not locate the best model at ./bart-checkpoints/checkpoint-9600/pytorch_model.bin, if you are running a distributed training on multiple nodes, you should activate `--save_on_each_node`.\n"]},{"data":{"text/plain":["TrainOutput(global_step=9630, training_loss=0.15617886960568333, metrics={'train_runtime': 2044.063, 'train_samples_per_second': 75.438, 'train_steps_per_second': 4.711, 'total_flos': 2493574408765440.0, 'train_loss': 0.15617886960568333, 'epoch': 14.977431906614786})"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"execution_count":25},{"id":"0b0f6a61","cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained(\"/kaggle/working/bartbase_finetuned\")\ntokenizer.save_pretrained(\"/kaggle/working/bartbase_finetuned\")\nprint(\"Model saved successfully!\")","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:25:52.83415Z","iopub.status.busy":"2025-03-05T12:25:52.833859Z","iopub.status.idle":"2025-03-05T12:25:54.13025Z","shell.execute_reply":"2025-03-05T12:25:54.129467Z"},"papermill":{"duration":1.34624,"end_time":"2025-03-05T12:25:54.131544","exception":false,"start_time":"2025-03-05T12:25:52.785304","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Configuration saved in /kaggle/working/bartbase_finetuned/config.json\n","Configuration saved in /kaggle/working/bartbase_finetuned/generation_config.json\n","Model weights saved in /kaggle/working/bartbase_finetuned/model.safetensors\n","tokenizer config file saved in /kaggle/working/bartbase_finetuned/tokenizer_config.json\n","Special tokens file saved in /kaggle/working/bartbase_finetuned/special_tokens_map.json\n"]},{"name":"stdout","output_type":"stream","text":["Model saved successfully!\n"]}],"execution_count":26},{"id":"40e4c23e-7d99-4840-a55f-d3ed61a23661","cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n# secret_value_0 = user_secrets.get_secret(\"HF_READ_TOKEN\")\n# secret_value_1 = user_secrets.get_secret(\"HF_READ_WRITE_TOKEN\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6f5e2c11","cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=user_secrets.get_secret(\"HF_READ_TOKEN\"))","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:25:54.234839Z","iopub.status.busy":"2025-03-05T12:25:54.234475Z","iopub.status.idle":"2025-03-05T12:25:54.401834Z","shell.execute_reply":"2025-03-05T12:25:54.400863Z"},"papermill":{"duration":0.222705,"end_time":"2025-03-05T12:25:54.403555","exception":false,"start_time":"2025-03-05T12:25:54.18085","status":"completed"},"tags":[]},"outputs":[],"execution_count":27},{"id":"4e704306","cell_type":"code","source":"from huggingface_hub import login\n\n# Replace 'your_hf_token' with your actual Hugging Face API token\nlogin(token=user_secrets.get_secret(\"HF_READ_WRITE_TOKEN\"))","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:25:54.50203Z","iopub.status.busy":"2025-03-05T12:25:54.501766Z","iopub.status.idle":"2025-03-05T12:25:54.6222Z","shell.execute_reply":"2025-03-05T12:25:54.621483Z"},"papermill":{"duration":0.170708,"end_time":"2025-03-05T12:25:54.623494","exception":false,"start_time":"2025-03-05T12:25:54.452786","status":"completed"},"tags":[]},"outputs":[],"execution_count":28},{"id":"6e9cc2dc","cell_type":"code","source":"from huggingface_hub import HfApi, create_repo, upload_folder\n\n# Define your Hugging Face repo ID\nrepo_id = \"tachygraphy-microtrext-norm-org/BART-base-HF-Trainer-GradAccumStep2\"  # Example\n\n# Local directory where all your model files are stored\nlocal_model_dir = \"/kaggle/working/bartbase_finetuned\"\n\n# Initialize API instance\napi = HfApi()\n\n# Create the repo if it doesn't exist\ncreate_repo(repo_id, exist_ok=True)\n\n# Upload all the files from the local directory to the Hugging Face Hub\nupload_folder(\n    folder_path=local_model_dir,  # Path to the folder to upload\n    repo_id=repo_id,              # Repo ID on Hugging Face\n    repo_type=\"model\"             # Specify it's a model repo\n)\n\nprint(f\"All files uploaded to Hugging Face under {repo_id}\")","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:25:54.719738Z","iopub.status.busy":"2025-03-05T12:25:54.719442Z","iopub.status.idle":"2025-03-05T12:26:14.148278Z","shell.execute_reply":"2025-03-05T12:26:14.14739Z"},"papermill":{"duration":19.47822,"end_time":"2025-03-05T12:26:14.14975","exception":false,"start_time":"2025-03-05T12:25:54.67153","status":"completed"},"tags":[]},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52b84b3fc31546dd89020d5b80a0ca92","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["All files uploaded to Hugging Face under tachygraphy-microtrext-norm-org/BART-base-HF-Trainer-GradAccumStep2\n"]}],"execution_count":29},{"id":"788cfde6","cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:26:14.249081Z","iopub.status.busy":"2025-03-05T12:26:14.248775Z","iopub.status.idle":"2025-03-05T12:26:14.252462Z","shell.execute_reply":"2025-03-05T12:26:14.25166Z"},"papermill":{"duration":0.054706,"end_time":"2025-03-05T12:26:14.253879","exception":false,"start_time":"2025-03-05T12:26:14.199173","status":"completed"},"tags":[]},"outputs":[],"execution_count":30},{"id":"4072546e","cell_type":"code","source":"def predict(model, tokenizer, input_texts, device):\n#     model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n#     model.load_state_dict(torch.load(model_path)['model_state_dict'])\n    model.to(device)\n#     model.eval()\n\n    predictions = []\n    with torch.no_grad():\n#         for text in input_texts:\n        text = input_texts\n        padded = tokenizer(text, return_tensors='pt', truncation=False, padding=\"longest\").to(device)\n        \n        input_ids = padded['input_ids'].to(device)\n        attention_mask = padded['attention_mask'].to(device)\n\n        # max_new_tokens = min(input_ids.shape[1] * 2, 1024)\n        max_new_tokens = 1024 # default since we are not sure about the word expansions, like brb -> be right back there can short form\n                              # of very large length words\n            \n        preds = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=max_new_tokens, temperature=0.4, do_sample=True)\n        # preds = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=max_new_tokens)\n        pred_text = tokenizer.decode(preds[0], skip_special_tokens=True)\n        predictions.append(pred_text)\n    \n    return predictions","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:26:14.353592Z","iopub.status.busy":"2025-03-05T12:26:14.353239Z","iopub.status.idle":"2025-03-05T12:26:14.358604Z","shell.execute_reply":"2025-03-05T12:26:14.357868Z"},"papermill":{"duration":0.056242,"end_time":"2025-03-05T12:26:14.359805","exception":false,"start_time":"2025-03-05T12:26:14.303563","status":"completed"},"tags":[]},"outputs":[],"execution_count":31},{"id":"b428fa45","cell_type":"code","source":"# Test prediction on random input\nrandom_input = \"thx 4 the tip. will let u no. btw gotta use smpl things 4 now. tbh i'm tired, iykyk\"\npredicted_text = predict(model, tokenizer, random_input, device)\nprint(f\"Input: {random_input}\")\nprint(f\"Predicted Meaning: {predicted_text}\")","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:26:14.458664Z","iopub.status.busy":"2025-03-05T12:26:14.458343Z","iopub.status.idle":"2025-03-05T12:26:15.464355Z","shell.execute_reply":"2025-03-05T12:26:15.463568Z"},"papermill":{"duration":1.055737,"end_time":"2025-03-05T12:26:15.465607","exception":false,"start_time":"2025-03-05T12:26:14.40987","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: thx 4 the tip. will let u no. btw gotta use smpl things 4 now. tbh i'm tired, iykyk\n","Predicted Meaning: [\"Thanks for the tip. I'll let you no. I've got to use some things for now. To be honest, I'm tired, I don't know.\"]\n"]}],"execution_count":32},{"id":"2472d5aa","cell_type":"code","source":"# Test prediction on random input\nrandom_input = \"pls hlp, idk wht 2 do\"\npredicted_text = predict(model, tokenizer, random_input, device)\nprint(f\"Input: {random_input}\")\nprint(f\"Predicted Meaning: {predicted_text}\")","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:26:15.564291Z","iopub.status.busy":"2025-03-05T12:26:15.564028Z","iopub.status.idle":"2025-03-05T12:26:15.768737Z","shell.execute_reply":"2025-03-05T12:26:15.76773Z"},"papermill":{"duration":0.2546,"end_time":"2025-03-05T12:26:15.77","exception":false,"start_time":"2025-03-05T12:26:15.5154","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: pls hlp, idk wht 2 do\n","Predicted Meaning: [\"Please help, I don't know what to do.\"]\n"]}],"execution_count":33},{"id":"579b9c56","cell_type":"code","source":"# Test prediction on random input\nrandom_input = \"i don8 no fr y hes soooo sad\"\npredicted_text = predict(model, tokenizer, random_input, device)\nprint(f\"Input: {random_input}\")\nprint(f\"Predicted Meaning: {predicted_text}\")","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:26:15.868382Z","iopub.status.busy":"2025-03-05T12:26:15.868125Z","iopub.status.idle":"2025-03-05T12:26:16.047307Z","shell.execute_reply":"2025-03-05T12:26:16.046611Z"},"papermill":{"duration":0.228791,"end_time":"2025-03-05T12:26:16.048582","exception":false,"start_time":"2025-03-05T12:26:15.819791","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: i don8 no fr y hes soooo sad\n","Predicted Meaning: [\"i don't know no friend why he is so sad\"]\n"]}],"execution_count":34},{"id":"6ea8192d-8a3b-42a2-97c2-6725a9f469e0","cell_type":"markdown","source":"The output sentences might vary, try to generate 2-3 samples and take the best one. Below one is a good example where this model might get confused.","metadata":{}},{"id":"ca7d0569","cell_type":"code","source":"!zip -r ./logs.zip /kaggle/working/logs\n\n","metadata":{"execution":{"iopub.execute_input":"2025-03-05T12:26:16.145488Z","iopub.status.busy":"2025-03-05T12:26:16.145226Z","iopub.status.idle":"2025-03-05T12:26:16.348922Z","shell.execute_reply":"2025-03-05T12:26:16.347779Z"},"papermill":{"duration":0.25308,"end_time":"2025-03-05T12:26:16.350245","exception":false,"start_time":"2025-03-05T12:26:16.097165","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/logs/ (stored 0%)\r\n","  adding: kaggle/working/logs/events.out.tfevents.1741175508.64f39dcdd706.17.0 (deflated 70%)\r\n"]}],"execution_count":35},{"id":"eb26636d","cell_type":"code","source":"","metadata":{"papermill":{"duration":0.068439,"end_time":"2025-03-05T12:26:16.481496","exception":false,"start_time":"2025-03-05T12:26:16.413057","status":"completed"},"tags":[]},"outputs":[],"execution_count":null}]}